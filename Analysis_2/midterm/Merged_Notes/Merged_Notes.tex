\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{fancyhdr, lipsum}
\usepackage{ulem}
\usepackage{fontspec}
\usepackage{xeCJK}
% \setCJKmainfont[Path = ./fonts/, AutoFakeBold]{edukai-5.0.ttf}
% \setCJKmainfont[Path = ../../fonts/, AutoFakeBold]{NotoSansTC-Regular.otf}
% set your own font :
% \setCJKmainfont[Path = <Path to font folder>, AutoFakeBold]{<fontfile>}
\usepackage{physics}
% \setCJKmainfont{AR PL KaitiM Big5}
% \setmainfont{Times New Roman}
\usepackage{multicol}
\usepackage{zhnumber}
% \usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage[
	a4paper,
	top=2cm, 
	bottom=2cm,
	left=2cm,
	right=2cm,
	includehead, includefoot,
	heightrounded
]{geometry}
% \usepackage{geometry}
\usepackage{graphicx}
\usepackage{xltxtra}
\usepackage{biblatex} % 引用
\usepackage{caption} % 調整caption位置: \captionsetup{width = .x \linewidth}
\usepackage{subcaption}
% Multiple figures in same horizontal placement
% \begin{figure}[H]
%      \centering
%      \begin{subfigure}[H]{0.4\textwidth}
%          \centering
%          \includegraphics[width=\textwidth]{}
%          \caption{subCaption}
%          \label{fig:my_label}
%      \end{subfigure}
%      \hfill
%      \begin{subfigure}[H]{0.4\textwidth}
%          \centering
%          \includegraphics[width=\textwidth]{}
%          \caption{subCaption}
%          \label{fig:my_label}
%      \end{subfigure}
%         \caption{Caption}
%         \label{fig:my_label}
% \end{figure}
\usepackage{wrapfig}
% Figure beside text
% \begin{wrapfigure}{l}{0.25\textwidth}
%     \includegraphics[width=0.9\linewidth]{overleaf-logo} 
%     \caption{Caption1}
%     \label{fig:wrapfig}
% \end{wrapfigure}
\usepackage{float}
%% 
\usepackage{calligra}
\usepackage{hyperref}
\usepackage{url}
\usepackage{gensymb}
% Citing a website:
% @misc{name,
%   title = {title},
%   howpublished = {\url{website}},
%   note = {}
% }
\usepackage{framed}
% \begin{framed}
%     Text in a box
% \end{framed}
%%

\usepackage{array}
\newcolumntype{F}{>{$}c<{$}} % math-mode version of "c" column type
\newcolumntype{M}{>{$}l<{$}} % math-mode version of "l" column type
\newcolumntype{E}{>{$}r<{$}} % math-mode version of "r" column type
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}p{#1}} % Centered, length-customizable environment
\newcolumntype{R}[1]{>{\PreserveBackslash\raggedleft}p{#1}} % Left-aligned, length-customizable environment
\newcolumntype{L}[1]{>{\PreserveBackslash\raggedright}p{#1}} % Right-aligned, length-customizable environment

% \begin{center}
% \begin{tabular}{|C{3em}|c|l|}
%     \hline
%     a & b \\
%     \hline
%     c & d \\
%     \hline
% \end{tabular}
% \end{center}    



\usepackage{bm}
% \boldmath{**greek letters**}
\usepackage{tikz}
\usepackage{titlesec}
% standard classes:
% http://tug.ctan.org/macros/latex/contrib/titlesec/titlesec.pdf#subsection.8.2
 % \titleformat{<command>}[<shape>]{<format>}{<label>}{<sep>}{<before-code>}[<after-code>]
% Set title format
% \titleformat{\subsection}{\large\bfseries}{ \arabic{section}.(\alph{subsection})}{1em}{}
\usepackage{amsthm}
\usetikzlibrary{shapes.geometric, arrows}
% https://www.overleaf.com/learn/latex/LaTeX_Graphics_using_TikZ%3A_A_Tutorial_for_Beginners_(Part_3)%E2%80%94Creating_Flowcharts

% \tikzstyle{typename} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=red!30]
% \tikzstyle{io} = [trapezium, trapezium left angle=70, trapezium right angle=110, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=blue!30]
% \tikzstyle{decision} = [diamond, minimum width=3cm, minimum height=1cm, text centered, draw=black, fill=green!30]
% \tikzstyle{arrow} = [thick,->,>=stealth]

% \begin{tikzpicture}[node distance = 2cm]

% \node (name) [type, position] {text};
% \node (in1) [io, below of=start, yshift = -0.5cm] {Input};

% draw (node1) -- (node2)
% \draw (node1) -- \node[adjustpos]{text} (node2);

% \end{tikzpicture}

%%

\DeclareMathAlphabet{\mathcalligra}{T1}{calligra}{m}{n}
\DeclareFontShape{T1}{calligra}{m}{n}{<->s*[2.2]callig15}{}

%%
%%
% A very large matrix
% \left(
% \begin{array}{ccccc}
% V(0) & 0 & 0 & \hdots & 0\\
% 0 & V(a) & 0 & \hdots & 0\\
% 0 & 0 & V(2a) & \hdots & 0\\
% \vdots & \vdots & \vdots & \ddots & \vdots\\
% 0 & 0 & 0 & \hdots & V(na)
% \end{array}
% \right)
%%

% amsthm font style 
% https://www.overleaf.com/learn/latex/Theorems_and_proofs#Reference_guide

% 
%\theoremstyle{definition}
%\newtheorem{thy}{Theory}[section]
%\newtheorem{thm}{Theorem}[section]
%\newtheorem{ex}{Example}[section]
%\newtheorem{prob}{Problem}[section]
%\newtheorem{lem}{Lemma}[section]
%\newtheorem{dfn}{Definition}[section]
%\newtheorem{rem}{Remark}[section]
%\newtheorem{cor}{Corollary}[section]
%\newtheorem{prop}{Proposition}[section]
%\newtheorem*{clm}{Claim}
%%\theoremstyle{remark}
%\newtheorem*{sol}{Solution}



\theoremstyle{definition}
\newtheorem{thy}{Theory}
\newtheorem{thm}{Theorem}
\newtheorem{ex}{Example}
\newtheorem{prob}{Problem}
\newtheorem{lem}{Lemma}
\newtheorem{dfn}{Definition}
\newtheorem{rem}{Remark}
\newtheorem{cor}{Corollary}
\newtheorem{prop}{Proposition}
\newtheorem*{clm}{Claim}
%\theoremstyle{remark}
\newtheorem*{sol}{Solution}

% Proofs with first line indent
\newenvironment{proofs}[1][\proofname]{%
  \begin{proof}[#1]$ $\par\nobreak\ignorespaces
}{%
  \end{proof}
}
\newenvironment{sols}[1][]{%
  \begin{sol}[#1]$ $\par\nobreak\ignorespaces
}{%
  \end{sol}
}
\newenvironment{exs}[1][]{%
  \begin{ex}[#1]$ $\par\nobreak\ignorespaces
}{%
  \end{ex}
}
\newenvironment{rems}[1][]{%
  \begin{rem}[#1]$ $\par\nobreak\ignorespaces
}{%
  \end{rem}
}
%%%%
%Lists
%\begin{itemize}
%  \item ... 
%  \item ... 
%\end{itemize}

%Indexed Lists
%\begin{enumerate}
%  \item ...
%  \item ...

%Customize Index
%\begin{enumerate}
%  \item ... 
%  \item[$\blackbox$]
%\end{enumerate}
%%%%
% \usepackage{mathabx}
% Defining a command
% \newcommand{**name**}[**number of parameters**]{**\command{#the parameter number}*}
% Ex: \newcommand{\kv}[1]{\ket{\vec{#1}}}
% Ex: \newcommand{\bl}{\boldsymbol{\lambda}}
\newcommand{\scripty}[1]{\ensuremath{\mathcalligra{#1}}}
% \renewcommand{\figurename}{圖}
\newcommand{\sfa}{\text{  } \forall}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\ceil}[1]{\lceil #1 \rceil}


\usepackage{xfrac}
%\usepackage{faktor}
%% The command \faktor could not run properly in the pc because of the non-existence of the 
%% command \diagup which sould be properly included in the amsmath package. For some reason 
%% that command just didn't work for this pc 
\newcommand*\quot[2]{{^{\textstyle #1}\big/_{\textstyle #2}}}
\newcommand{\bracket}[1]{\langle #1 \rangle}


\makeatletter
\newcommand{\opnorm}{\@ifstar\@opnorms\@opnorm}
\newcommand{\@opnorms}[1]{%
	\left|\mkern-1.5mu\left|\mkern-1.5mu\left|
	#1
	\right|\mkern-1.5mu\right|\mkern-1.5mu\right|
}
\newcommand{\@opnorm}[2][]{%
	\mathopen{#1|\mkern-1.5mu#1|\mkern-1.5mu#1|}
	#2
	\mathclose{#1|\mkern-1.5mu#1|\mkern-1.5mu#1|}
}
\makeatother
% \opnorm{a}        % normal size
% \opnorm[\big]{a}  % slightly larger
% \opnorm[\Bigg]{a} % largest
% \opnorm*{a}       % \left and \right


\newcommand{\A}{\mathcal A}
\renewcommand{\AA}{\mathbb A}
\newcommand{\B}{\mathcal B}
\newcommand{\BB}{\mathbb B}
\newcommand{\C}{\mathcal C}
\newcommand{\CC}{\mathbb C}
\newcommand{\D}{\mathcal D}
\newcommand{\DD}{\mathbb D}
\newcommand{\E}{\mathcal E}
\newcommand{\EE}{\mathbb E}
\newcommand{\F}{\mathcal F}
\newcommand{\FF}{\mathbb F}
\newcommand{\G}{\mathcal G}
\newcommand{\GG}{\mathbb G}
\renewcommand{\H}{\mathcal H}
\newcommand{\HH}{\mathbb H}
\newcommand{\I}{\mathcal I}
\newcommand{\II}{\mathbb I}
\newcommand{\J}{\mathcal J}
\newcommand{\JJ}{\mathbb J}
\newcommand{\K}{\mathcal K}
\newcommand{\KK}{\mathbb K}
\renewcommand{\L}{\mathcal L}
\newcommand{\LL}{\mathbb L}
\newcommand{\M}{\mathcal M}
\newcommand{\MM}{\mathbb M}
\newcommand{\N}{\mathcal N}
\newcommand{\NN}{\mathbb N}
\renewcommand{\O}{\mathcal O}
\newcommand{\OO}{\mathbb O}
\renewcommand{\P}{\mathcal P}
\newcommand{\PP}{\mathbb P}
\newcommand{\Q}{\mathcal Q}
\newcommand{\QQ}{\mathbb Q}
\newcommand{\R}{\mathcal R}
\newcommand{\RR}{\mathbb R}
\renewcommand{\S}{\mathcal S}
\renewcommand{\SS}{\mathbb S}
\newcommand{\T}{\mathcal T}
\newcommand{\TT}{\mathbb T}
\newcommand{\U}{\mathcal U}
\newcommand{\UU}{\mathbb U}
\newcommand{\V}{\mathcal V}
\newcommand{\VV}{\mathbb V}
\newcommand{\W}{\mathcal W}
\newcommand{\WW}{\mathbb W}
\newcommand{\X}{\mathcal X}
\newcommand{\XX}{\mathbb X}
\newcommand{\Y}{\mathcal Y}
\newcommand{\YY}{\mathbb Y}
\newcommand{\Z}{\mathcal Z}
\newcommand{\ZZ}{\mathbb Z}

\newcommand{\ra}{\rightarrow}
\newcommand{\la}{\leftarrow}
\newcommand{\Ra}{\Rightarrow}
\newcommand{\La}{\Leftarrow}
\newcommand{\Lra}{\Leftrightarrow}
\newcommand{\lra}{\leftrightarrow}
\newcommand{\ru}{\rightharpoonup}
\newcommand{\lu}{\leftharpoonup}
\newcommand{\rd}{\rightharpoondown}
\newcommand{\ld}{\leftharpoondown}
\newcommand{\Gal}{\text{Gal}\,}
\newcommand{\dist}{\text{dist}\,}

\linespread{1.0}
\pagestyle{fancy}
\title{Analysis II}
\author{fat}
% \date{\today}
\date{}
\begin{document}
\maketitle
\thispagestyle{fancy}
\renewcommand{\footrulewidth}{0.4pt}
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\fancyhead[L]{Analysis II}

\section{Differentiation and Integration}

\par Recall that if $f$ is continuous, then $F(x)=\int_a^x f(t)dt$ is differentiable. $f$ Lebesgue integrable?

\par The derivative of $F$ is the limit

\begin{equation}
  \lim_{h \to 0} \frac{F(x+h) - F(x)}{h} = \lim_{h \to 0} \frac{1}{h} \int_{x}^{x+h} f(t) dt
\end{equation}

\begin{equation}
  =\frac{1}{|I|} \int_{I} f(t)dt
\end{equation}

\par where $I=(x, x+h)$. The average should $\to f(x)$ as $|I| \to 0$. But this would not hold ofr all $x$ if $f$ is just Lebesgue integrable. ($f$ is just defined a.e.).

\par Want: Understand the set of $x$ s.t. the convergence holds. 

\par Problem: Given $f$ in $L^1 (\mathbb{R}^d)$, for which $x$ one has 

$$ \lim_{m(B) \to 0, x \in B} \frac{1}{m(B)} \int_B f(y) dy = f(x)$$

\par If $f$ is continuous, this holds for all $x \in \mathbb{R}^d$. In general, need to understand how the averages of $f$ behave. 

\section{Hardy-Littlewood maximal function}

\begin{dfn}
	If $f \in L^1(\mathbb{R}^d)$, we define its \textbf{maximal function} $f^*$ by 

  \begin{equation}
    f^*(x) = \sup_{B \ni x} \frac{1}{m(B)} \int_B |f(y)| dy
  \end{equation}
\end{dfn}
\begin{clm} 
    $f^*$ is measurable. 
\end{clm}

  \begin{proof}
    Wil show $\{f^*>\alpha\}$ is open. Let $y \in \{f^* > \alpha \}$. Then exists ball $B \in y$ s.t. 
    $$\frac{1}{m(B)} \int _B |f(t)|dt > \alpha$$
    If $x$ is sufficiently close to $y$, then $x \in B$. $\Rightarrow f^*(x) > \alpha$. $\Rightarrow \{ f^* > \alpha \}$ is open. 
    \begin{thm}
      For all $\alpha > 0$, 
      $$m(\{x \in \mathbb{R}^d: f^*(x) > \alpha \} ) \leq \frac{3^d}{\alpha} ||f||_{L^1(\mathbb{R}^d)}$$

    \end{thm}
    Some discussions:\\
    \begin{itemize}
      \item We have $f^*(x) < \infty$ for a.e. $x$:\\
        Let $\alpha \to \infty$ on both sides. $RHS \to 0$, $LHS \to m(\{x: f^*(x) = \infty\})$.\\
      \item For any $f \in L^1(\mathbb{R}^d)$, for any $\alpha > 0$, 
    \begin{equation}
      m(\{x \in \mathbb{R}^d: |f(x)| > \alpha \}) \leq \frac{1}{\alpha} ||f||_{L^1}
    \end{equation}
    \begin{proof}
      Chebyshev/Markov inequality
      $$\int_{\mathbb{R}^d} |f| = \int_{\{|f|>\alpha\}} |f| + \int_{\{|f| < \alpha\}} |f| \leq \int_{\{|f| > \alpha\}} \alpha = \alpha m(\{|f|>\alpha\})$$
    \end{proof}
    Will show later that $f^*(x) \leq |f(x)|$ for a.e. $x$. So the inequality in Theorem is sharper in general. In fact, $f^*(x) \notin L^1$ in general.\\
  \item $f^*$ is of weak $L^1$. \\
    \end{itemize}
  \end{proof}

    \begin{dfn}
		A function $g$ is of \textbf{weak $L^1$} if 
      $$\sup_{\alpha > 0} \alpha m(\{x \in \mathbb{R}^d : |g(x)| > \alpha\}) < \infty$$
      $L^1 \Rightarrow $ weak $L^1$, converse does not hold. 
    \end{dfn}
Notation: If $B = B(x, r)$ is a ball and if $c>0$, we write $cB = B(x, cr)$. 
\begin{lem}[Vitali]
  Suppose that $\mathcal{B} = \{B_1, ..., B_N\}$ is a finite collection of open balls in $\mathbb{R}^d$, exists a disjoint subcollection $\{B_{i_1}, ..., B_{i_k}\}$ of $\mathcal{B}$ s.t. 
  $$\bigcup_{l = 1}^N B_l \in \bigcup_{j = 1}^k 3 B_{i_j}$$
  and hence 
  $$m(\bigcup_{l = 1}^N B_l) \leq 3^d \sum_{j = 1}^k m(B_{i_j})$$
\end{lem}
\begin{proof}
  Observation: if $B$ and $B'$ are balls that intersect, and if $B' \leq $ radius of $B$, then $B' \subset 3B$. Pick a ball $B_{i_1}$ in $\mathcal{B}$ with maximal radius. Remove the ball $B_{i_1}$ and any ball that intersects $B_{i_1}$ from $\mathcal{B}$. All balls we removed are contained in $3B_{i_1}$.In the remaining collection of balls, pick $B_{i_2}$ with maximal radius. Repeat the same procedure.   
\end{proof}
\begin{proof}[Proof of Theorem] 
  Write $E_\alpha = \{x \in \mathbb{R}^d: f^*(x) > \alpha\}$. If $x \in E_{\alpha}$, $\exists$ a ball $B_x \ni x$ s.t. 
  $$\frac{1}{m(B_x)} \int_{B_x} |f(y)| dy > \alpha$$
  $$\Leftrightarrow m(B_x) < \frac{1}{\alpha} \int_{B_x} |f(y)| dy$$
  Let $K \subset E_{\alpha}$ be compact. Since $K \subset \bigcup_{x \in E_{\alpha}}B_x$, exists a finite subcover of $K$, say $K \subset \bigcup_{l = 1}^N B_l$. By Vitali's covering lemma, exists a disjoint subcollection of balls $B_{i_1}, ..., B_{i_k}$ s.t. 
  $$m(\bigcup_{l = 1}^N B_l) \leq 3^d \sum_{i = 1}^k m(B_{i_j})$$
  $$ \Rightarrow m(K) \leq m(\bigcup_{l =1}^N B_l)  \leq 3^d \sum_{j = 1}^{k} m(B_{i_j}) \leq \frac{3^d}{\alpha} \sum_{j = 1}^k \int_{B_{i_j}} |f(y)| dy$$ 
  $$\stackrel{\text{disjointness}}{=} \frac{3^d}{\alpha} \int_{\bigcup_{j = 1}^{k} B_{i_j}} |f(y)| dy \leq \frac{3^d}{\alpha} \int_{\mathbb{R}^d} |f(y)| dy = \frac{3^d}{\alpha} ||f||_{L^1} $$
  
  So $m(K) \leq \frac{3^d}{\alpha} ||f||_{L^1}$ for all compact $K \subset E_{\alpha}$. \\
  Fact: $m(E_{\alpha}) = \sup \{m(K):K\subset E_{\alpha}  \text{compact} \}$. (inner regularity). So $m(E_\alpha) \leq \frac{3^d}{\alpha} ||f||_{L^1}$. 
\end{proof}



\begin{thm}[Lebesgue differentiation]
  If $f \in L^1(\mathbb{R}^d)$, then for a.e. $x$, 
  $$\lim_{m(B) \to 0, B \ni x} \frac{1}{m(B)} \int_{B} f(y) dy = f(x)$$
\end{thm}
\begin{proof}
  For $\alpha > 0$, define 
  $$E_\alpha = \{x: \limsup_{m(B) \to 0, x \in B} |\frac{1}{m(B)} \int_{B} f(y)dy - f(x)| > \alpha \}$$
  Will show $m(E_\alpha) = 0 \forall \alpha > 0$
  If this holds, $\bigcup_{n = 1}^{\infty} E_{\frac{1}{n}}$ has measure zero. This implies the theorem. Fix $\alpha > 0$. Recall for each $\epsilon > 0$, exists a continuous $g$ of compact support s.t. $||f-g||_{L^1} < \epsilon$. Continuity of $g$ 
  $$\Rightarrow \lim_{m(B) \to 0, x \in B} \frac{1}{m(B)} \int_{B} g(y)dy = g(x) \forall x$$
  $$ \frac{1}{m(B)} \int_{b} f(y) dy - f(x) = [\frac{1}{m(B)} \int_B (f(y) - g(y)) dy ] + [\frac{1}{m(B)} \int_{B} g(y) dy - g(x) ]+ [g(x) - f(x)]$$

  Where the first term is $(f-g)^*(x)$ and the second term goes to 0 since $g$ is continuous. 

  $$\Rightarrow \limsup_{m(B) \to 0, x \in B} |\frac{1}{m(B)} \int_{B} f(y) dy - f(x)| \leq (f-g)*(x) + |g(x) - f(x)|$$ 
  Let $F_\alpha = \{x: (f-g)^*(x) > \frac{\alpha}{2}\}, G_\alpha = \{x: |g(x)-f(x)| > \frac{\alpha}{2}\}$. Observe: $E_\alpha \subset F_\alpha \bigcup G_{\alpha}$. 
  $$m(G_\alpha) \leq \frac{2}{\alpha} ||g-f||_{L^1} \leq \frac{2 \epsilon}{\alpha}$$
  $$m(F_\alpha) \leq \frac{2\cdot 3^d}{\alpha} ||f-g||_{L^1} \leq \frac{2 \cdot 3^d \epsilon}{\alpha}$$
  Observe: $E_\alpha \subset F_\alpha \bigcup G_\alpha$. 
  $$ m(G_\alpha) \leq \frac{2}{\alpha} ||g-f||_{L^1} \leq \frac{2 \epsilon}{\alpha} \text{(Chebyshev)}$$
  $$ m(F_\alpha) \leq \frac{2 \cdot 3^d}{\alpha} ||f-g||_{L^1} \leq \frac{2 \cdot 3^d} \alpha \epsilon \text{(Theorem)}$$


  $$\Rightarrow m(E_\alpha) \leq C \epsilon$$
  Let $\epsilon \to 0$, we get $m(E_\alpha) = 0$.
\end{proof}
\begin{cor}
  One has $f^*(x) \leq |f(x)|$ for a.e. $x$. 
\end{cor}
  \begin{proof}
    Apply the Lebesgue diff theorem to $|f|$. 
  \end{proof}
  We cam weaken the assumption a bit. 
  \begin{dfn}
	  A measurable function $f$ on $\mathbb{R}^d$ is \textbf{locally integrable} if for every ball B, the function $f \chi_B$ is integrable.
    $$L_{loc}^1 (\mathbb{R}^d) = \{  \text{locally integrable functions}  \}$$
  \end{dfn}
  The Lebesgue differentiation theorem holds for locally integrable functions. $f(x) = x$ is locally integrable but not integrable. 

\begin{dfn}
	If $E \subset \mathbb{R}^d$ is measurable and $x \in \mathbb{R}^d$, we say that $x$ is a \textbf{density point} of $E$ if 
  $$\lim_{m(B) \to 0, x \in B} \frac{m(B \bigcap E)}{m(B)} = 1$$
  Intuition: If $x$ is a density point, then $m(B \bigcap E) \sim m(B)$. $E$ covers a large portion of $B$. 
  \begin{cor}[Lebesgue density theorem] 
    Suppose that $E \subset \mathbb{R}^d$ is measurable. Then a.e. $x \in E$ is a density point of $E$, a.e. $x \notin E$ is not a density point of $E$. 
  \end{cor}
\end{dfn}
  \begin{proof}
    Apply the Lebesgue diff theorem to $\chi_E$.
  \end{proof}
\begin{dfn}
	Let $f \in L_{loc}^1 (\mathbb{R}^d)$. The \textbf{Lebesgue set} of $f$ is the set of all points $x \in \mathbb{R}^d$ s.t. $|f(x) < \infty$ and 
  $$\lim_{m(B) \to 0, x \in B} \frac{1}{m(B)} \int_{B} |f(y) - f(x)| dy = 0$$
  Write the set $Leb(f)$. 
\end{dfn}
\begin{cor}
  If $f \in L_{loc}^1 (\mathbb{R}^d)$, then $x \in Leb(f)$ for a.e. $x$.
\end{cor}
\begin{proof}
  For each $r \in \mathbb{Q}$, there exists $E_r$ of measure zero s.t. 
  $$\frac{1}{m(B)} \int_B |f(y) - r| dy = |f(x) - r|$$

  for all $x \notin E_r$. Then $E \equiv \bigcup_{r \in \mathbb{Q}} E_r$ is also of measure zero. Suppose that $x \notin E$ and $|f(x)| < \infty$. Let $\epsilon > 0$ be given. Then $\exists r \in \mathbb{Q}$ s.t. $|f(x) - r| < \frac{\epsilon}{2}$. 

  $$\frac{1}{m(B)} \int_B |f(y) - f(x)| dx \leq \frac{1}{m(B)} \int_B |f(y) - r| dy + \frac{1}{m(B)} \int_B |r - f(x)| dy $$

  $$\Rightarrow \limsup_{m(B) \to 0, x \in B} \int_B |f(y) - f(x)| dx \leq 2 |f(x) - r| < \epsilon$$

  $$\Rightarrow x \in Leb(f)$$ 
  $E^c \subset Leb(f)$, $E$ has measure zero. So a.e. point $x \in Leb(f)$. 
\end{proof}
\begin{rem}
  $f \in L^1(\mathbb{R}^d) $ are equivalence classes. But the set of points where the limit\\ 
  $\lim_{m(B) \to 0, x \in B} \frac{1}{m(B)} \int_B f(y) dy$ exists is independent of the representation of $f$ chosen. But $Leb(f)$ depends on the representation function $f$. 
\end{rem}
\section{Approximations to the identity}
\begin{dfn}
	A family of functions $(K_\delta)_{\delta>0}$ is called an \textbf{approximation to the identity} if they are integrable and $\exists A \in \mathbb{R}$ s.t.
  \begin{itemize}
    \item[(a)]$\int K_{\delta} = 1$, 
    \item[(b)]$|K_{\delta}(x)| \leq A \delta^{-d}$ for all $\delta > 0$ and all $x \in \mathbb{R}^d$, 
    \item[(c)]$|K_{\delta}(x)| \leq \frac{A\delta}{|x|^{d+1}}$ for all $\delta > 0$ and all $x \in \mathbb{R}^d$. 
  \end{itemize}
\end{dfn}
Observations: \\
$\int |K_\delta| \leq A'$. 
\begin{proof}
  Recall: $\exists c > 0$ s.t. $\forall \epsilon > 0$, 
  $$\int_{\{|x| \geq \epsilon\}} \frac{dx}{|x|^{d+1}} \leq \frac{C}{\epsilon}$$

  $$|K_\delta| = \int_{\{|x| < \delta\}} |K_\delta| + \int_{\{|x| \geq \delta\}} |K_{\delta}|$$

  $$\leq A \delta^{-d} \int_{\{|x| < \delta\}} 1 + A \delta \int_{\{|x| \geq \delta\}} \frac{dx}{|x|^{d+1}} = A'$$ 
\end{proof}
For every $\eta > 0$, 
$$\lim_{\delta \to 0} \int_{\{|x| \geq \eta\}} |K_{\delta}| = 0$$
\begin{proof}
  $$\int_{\{|x| \geq \eta\}} |K_\delta| \leq A \delta \int_{\{|x| \geq \eta\}} \frac{dx}{|x|^{d+1}} \leq \frac{C \delta}{\eta} \stackrel{\delta \to 0}{\to} 0$$
\end{proof}
An example:
$$K_\delta(x) = \frac{1}{\delta^d} \phi(\frac{x}{\delta})$$
$\phi$ is a nonnegative bounded function in $\mathbb{R}^d$ s.t. $\int \phi = 1$. \\
The mapping $$f \rightarrow f * K_{\delta}$$ converges to the identity map $f \rightarrow f$ as $\delta \to 0$ in various senses. As $\delta \to 0$, $K_\delta$ converges to the "Dirac delta function" $D$, informally defined by 
$$
D(x) = 
\left\{
  \begin{array}{ccc}
    \infty & \text{if} & x = 0\\
    0 & \text{if} & x \neq 0 
  \end{array}
  \right. 
$$
and $\int D(x) dx = 1$. Doesn't make sense when we think of $D$ as an integrable function. Can think of 
$$f*D = \int f(x - y) D(y) dy = 0 (y \neq 0)$$
The mass of $D$ is concentrated at 0. Intuitively, $(f*D)(x) = f(x)$. (Think of $D$ as the identity element for convolutions. ) Can be rigorously defined, but we need abstract measure theory and functional analysis.

\begin{thm}
  If $(K_\delta)_{\delta > 0}$ is an approximation to the identity and $f \in L^1(\mathbb{R}^d)$, then

  $$(f * K_\delta)(x) \to f(x) \forall x \in Leb(f)$$

  In particular, the convergence holds for a.e. $x$. 
\end{thm}

\begin{lem}
  Suppose that $f \in L^1(\mathbb{R}^d)$ and $x \in Leb(f)$. For $r > 0$, define 

  $$A(r) = \frac{1}{r^d} \int_{\{|y| < r\}} |f(x - y) - f(x)| dy$$

  then $A$ is continuous in $r$ and $A(r) \to 0$ as $r \to 0$. Moreover, $\exists M > 0$ s.t. $A(r) \leq M \text{ } \forall r > 0$. 

\end{lem}

\begin{proofs}
  Recall: If $f \in L^1(\mathbb{R}^d)$, then $\forall \epsilon > 0$, $\exists \delta > 0$ s.t. $m(E) < \delta \Rightarrow \int_E |f| < \epsilon$. (Absolute continuity). Check that $A$ is continuous by using this. If $x \in Leb(f)$, 

  $$\lim_{m(b) \to 0, x \in B} \frac{1}{m(B)} \int_B |f(y) - f(x)| dy = \lim_{r \to 0} \frac{1}{c_d r^d} \int_{\{|y - x| \leq r \}} |f(y) - f(x)| dy$$

  $$= \lim_{r \to 0} \frac{1}{c_dr^d} \int_{\{|z| \leq r\}} |f(x - z) - f(x)| dz = 0$$

  This, together with continuity, shows that $A$ is bounded for $0 < r \leq 1$. Why is $A$ bounded for $r > 1$?

  $$A(r) = \frac{1}{r^d} \int_{\{|y| < r\}} |f(x - y) - f(x)|dy$$

  $$\leq \frac{1}{r^d} \int_{\{|y| < r\}} |f(x - y)| dy + \frac{1}{r^d} m(\{|y| < r\}) |f(x)| \leq \frac{1}{r^d} ||f||_{L^1} + c_d |f(x)|$$

  So $A(r)$ is bounded. 

\end{proofs}

\begin{thm}
  If $(K_\delta)$ is an approximation to the identity and $f \in L^1(\mathbb{R}^d)$ then

  $$(f * K_\delta) (x) \rightarrow f(x) \text{ as } \delta \rightarrow 0 \forall x \in Leb(f)$$
\end{thm}

\begin{proofs}
  $$(f * K_\delta)(x) - f(x) = \int f(x - y) K_\delta (y) dy - \int f(x) K_\delta (y) dy$$

  $$ = \int (f(x - y) - f(x)) K_\delta(y) dy$$

  $$\Rightarrow |(f* K_\delta)(x) - f(x)| \leq \int |f(x - y) - f(x)| |K_\delta(y)| \mathrm{d}y$$

  $$\int_{|y| \leq \delta} |f(x - y) - f(x)| |K_\delta(y)| dy \stackrel{(b)}{\leq} \frac{C}{\delta^d} \int_{|y| \leq \delta} |f(x - y) - f(x)| dy = CA(\delta) $$

  $$\int_{2^k \delta < |y| \leq 2^{k +1 } \delta} |f(x - y) - f(x)| |K_\delta (y)| dy \leq C \delta \int_{2^k  \delta < |y| \leq 2^{k + 1} \delta} |f(x - y) - f(x)| \frac{1}{|y|^{d+1}} dy$$

  $$\leq \frac{D \delta}{(2^k \delta)^{d + 1}} \int_{|y| \leq 2^{k+1} \delta} |f(x - y) - f(x)| dy$$

  $$\leq C' 2^{-k} A(2^{k + 1} \delta)$$

  $$\Rightarrow |(f*K_\delta)(x) - f(x)| \leq CA(\delta) + C' \sum_{k = 0}^\infty 2^{-k} A(2^{k+1} \delta)$$

  Given $\epsilon > 0$, choose $N$ large s.t. $\sum_{k \geq N} 2^{-k} < \epsilon$. By the Lemma, we can choose $\delta > 0$ small s.t. 

  $$A(2^{k +1} \delta) < \frac{\epsilon}{N} \text{ for } k= 0, 1, \hdots, N - 1$$

  Also, $A$ is bounded.

  $$\Rightarrow |(f*K_\delta)(x) - f(x)| \leq C'' \epsilon$$

  This proves the theorem. 

  \par So $f * K_\delta \rightarrow f$ a.e. as $\delta \rightarrow 0$. We also have $L^1$-convergence.


\end{proofs}

\begin{thm}
  $f \in L^1(\mathbb{R}^d)$, $(K_\delta)_{\delta > 0}$ approximation to the identity. Then $f(K_\delta) \in L^1(\mathbb{R}^d)$ and 

  $$||f*K_\delta - f||_{L^1} \rightarrow 0 \text{ as } \delta \rightarrow 0$$
\end{thm}

\begin{proof}
  $f*K_\delta \in L^1(\mathbb{R}^d)$ follows from  Fubini (check!)

  $$|f*K_\delta(x) - f(x)| \leq \int |f(x - y) - f(x)| |K_\delta(y)| dy$$

  $$||f*K_\delta - f||_{L^1} \leq \int \int |f(x - y) - f(x)| |K_\delta(y)|dydx$$

  Write $f_y(x) = f(x - y)$.

  $$\Rightarrow ||f*K_\delta - f||_{L^1} \leq \int ||f_y - f||_{L^1} |K_\delta(y)| dy$$

  Recall: Given $\epsilon > 0$, $\exists \eta > 0$ s.t. if $|y| < \eta$, then $||f_y - f||_{L^1} < \epsilon$.

  $$\Rightarrow ||f*K_\delta - f||_{L^1} \leq C\epsilon + \int_{|y| \geq \eta} ||f_y - f||_{L^1} |K_\delta(y)|dy$$

  $$\leq C \epsilon + 2||f||_{L^1} \int_{|y| \geq \eta} |K_\delta(y)|dy$$

  Where the second term converges to 0 as $\delta \rightarrow 0$.

  $\Rightarrow f*K_\delta \rightarrow f$ in $L^1$. 
\end{proof}

For which class of $F$ we have 

$$F(b) - F(a) = \int_a^b F'(x) dy \text{?}$$

If $F$ is an indefinite integral then this must be true. When can a function be written as an indefinite integral? Will study a wider class of functions. 

\begin{dfn}
  Let $F:[a, b] \rightarrow \mathbb{C}$ be a function, and let $a = t_0 < t_1 < \hdots < t_N = b$ be a partition of $[a, b]$. The variation of $F$ on this partition is defined by 

  $$\sum_{j = 1}^N  |F(t_j) - F(t_{j - 1})|$$

  F is said to be of \textbf{bounded variation} if 

  $$\sup_{\text{all partitions of }[a ,b]} \sum_{j = 1}^N |F(t_j) - F(t_{j - 1})| < \infty $$

\end{dfn}

\begin{ex}
  \begin{itemize}
    \item If $F: [a, b] \rightarrow \mathbb{R}$ is monotone, then $F$ is of bounded variation.

    \item If $F$ is Lipschitz, then $F$ is of bounded variation.
  \end{itemize}
\end{ex}

\begin{rem}
  If $\mathcal{P}$ is a partition of $[a, b]$ and if $\mathcal{P}'$ is a refinement of $\mathcal{P} (\mathcal{P} \subset \mathcal{P}')$ then the variation of $F$ on $\mathcal{P}'$ is at least the variation of $F$ on $\mathcal{P}$. 
\end{rem}

\begin{dfn}
  Let $F:[a, b] \rightarrow \mathbb{C}$ be a function of bounded variation. Let $x \in [a, b]$. The \textbf{total variation} of $F$ on $[a, x]$ is 

  $$T_F(a, x) = \sup_{\text{all partitions of } [a, x]} \sum_{j = 1}^N |F(t_j) - F(t_{j - 1})|$$

  If $F$ is real-valued, the positive variation of $F$ on $[a,x]$ is 

  $$P_F (a, x) = \sup \sum_{(+)} F(t_j) - F(t_{j - 1})$$

  Where the $(+)$ means summing over all $j$ s.t. $F(t_j) \leq F(t_{j - 1})$. The negative variation of $F$ on $[a, x]$ is

  $$N_F (a, x) = \sup \sum_{(-)} - (F(t_j) - F(t_{j - 1}))$$

  Where $(-)$ means summing over all $j$ s.t. $F(t_j) \leq F(t_{j - 1})$. 
\end{dfn}

\begin{lem}
  Suppose $F:[a, b] \rightarrow \mathbb{R}$ is of bounded variation. Then $\forall x \in [a, b]$ one has

  $$F(x) - F(a) = P_F (a, x) - N_F(a, x)$$

  $$T_F(a, x) = P_F(a, x) + N_F(a, x)$$
\end{lem}

\begin{proofs}
  Let $\epsilon > 0$. $\exists$ a partition $a = t_0 < \hdots < t_N = b$ s.t. 

  $$|P_F(a, x) - \sum_{(+)} (F(t_j) - F(t_{j - 1}))| < \frac{\epsilon}{2}$$

  
  $$|N_F(a, x) - \sum_{(-)} - (F(t_j) - F(t_{j - 1}))| < \frac{\epsilon}{2}$$

  Observe 

  $$F(x) - F(a) = \sum_{j = 1}^N (F(t_j) - F(t_{j - 1}))$$

  $$ = \sum_{(+)} F(t_j) - F(t_{j - 1}) - \sum_{(-)} -(F(t_j) - F(t_{j - 1}))$$

  $$\Rightarrow  |F(x) - F(a) - (P_F(a, x) - N_F(a, x))| < \epsilon$$

  For any partition $a = t_0 < \hdots < t_N = x$, 

  $$\sum_{j = 1}^N |F(t_j) - F(t_{j - 1})| = \sum_{(+)} F(t_j) - F(t_{j - 1}) + \sum_{(-)} -(F(t_j) - F(t_{j - 1}))$$

  $$\Rightarrow T_F(a, x) = P_F(a, x) + N_F(a, x)$$

  where one should verify this line carefully.
  

\end{proofs}


\begin{thm}
  $F:[a, b] \rightarrow \mathbb{R}$ is of bounded variation $\Leftrightarrow$ $F$ is a difference of two increasing bounded functions. 
\end{thm}

\begin{proofs}
  If $F = F_1 - F_2$, where $F_1, F_2$ are increasing and bounded, then $T_F(a, x) \leq T_{F_1}(a, x) + T_{F_2}(a ,x) < \infty$. On the other hand, if $F$ is of bounded variation, take 

  $$F_1(x) = P_F(a, x) + F(a) \text{, } F_2(x) = N_F(a, x)$$

  where both the functions are increasing and bounded. Clearly $F(x) = F_1(x) - F_2(x)$. 
\end{proofs}

Consequence: Any complex-valued function of bounded variation is a linear combination of 4 increasing function. 

\begin{thm}
  If $F$ is of bounded variation on $[a, b]$, then $F$ is differentiable a.e.
\end{thm}

\begin{proofs}

	It suffices to show that increasing functions are differentiable a.e. We will first consider the case that the function is continuous. 

	\begin{lem}
	  Suppose that $G$ is real-valued and continuous on $\mathbb{R}$. Let $E = \{x \in \mathbb{R}: G(x + h) > G(x) \text{ for some } h = h_x > 0 \}$. If $E \neq \phi$, then $E$ is open, and we can write $E = \bigcup_k (a_k, b_k)$ where the intervals are disjoint. If $(a_k, b_k)$ is a finite interval in the union, then $G(b_k) - G(a_k) = 0$.  
	\end{lem}

	\begin{proofs}
	  Suppose that $(a_k, b_k)$ is a finite interval in the union. $a_k \notin E \Rightarrow $ we cannot have $G(b_k) > G(a_k)$. Suppose that $G(b_k) < G(a_k)$. By continuity, $\exists c \in (a_k, b_k)$ s.t. 

	  $$G(c) = \frac{G(a_k) + G(b_k)}{2}$$

	  We may choose $c$ to be the rightmost such point in $(a_k, b_k)$. Then $c \in E$. So $\exists d > c$ s.t. $G(d) > G(c)$. Also, $b_k \notin E$. So $G(x) \leq G(b_k) \forall x \leq b_k$. 

	  $$G(d) > G(c) > G(b_k) \Rightarrow d < b_k$$

	  By continuity again, $\exists c' \in (d, b_k)$ s.t. $G(c') = G(c)$, contradicting that $c$ is the rightmost point. So $G(a_k) = G(b_k)$. 
	\end{proofs}

	\begin{rem}
	  If $G:[a, b] \rightarrow \mathbb{R}$ is continuous, and if we define $E = \{ x \in (a, b): G(x + h) > G(x) \text{ for some } h = h_x > 0 \}$, then the above result still holds, except possibly when $a_k = a$. In this case we only have $G(a_k) \leq G(b_k)$. 
	\end{rem}

	Define 

	$$\Delta_h (F)(x) = \frac{F(x + h) - F(x)}{h}$$

	The Dini derivatives of $F$ at $x$ are

	$$D^+(F)(x) = \limsup_{h \to 0^+} \Delta_h (F)(x)$$

	$$D_+(F)(x) = \liminf_{h \to 0^+} \Delta_h (F)(x)$$

	$$D^-(F)(x) = \limsup_{h \to 0^-} \Delta_h (F)(x)$$

	$$D_-(F)(x) = \liminf_{h \to 0^-} \Delta_h (F)(x)$$

	Want: $D^+ = D_+ = D^- = D_- < \infty$ a.e. clearly, $D_+ \leq D^+$ and $D_- \leq D_-$. It suffices to verify that for all increasing and continuous $F$, 

	\begin{itemize}
	  \item[(a)] $D^+(F)(x) < \infty$ for a.e. $x$
	  \item[(b)] $D^+(F)(x) \leq D_-(F)(x)$ for a.e. $x$. 
	\end{itemize}

	If (a) and (b) hold for all increasing and continuous $F$, we apply (b) to $-F(-x)$ (increasing and continuous) on the interval $[-b, -a]$.

	$$\Rightarrow D^+(-F)(-x) \leq D_-(-F)(-x) (\text{write } \tilde{F}(x) = -F(-x))$$

	while

	$$\text{L.H.S.} = \limsup_{h \to 0^+} (-\frac{\tilde{F}(x+h) - \tilde{F}(x)}{h}) = \limsup_{h \to 0^+}  (-\frac{F(-x-h) - F(-x)}{-h})$$

	$$ = \limsup_{h \to 0^+} (\frac{F(-x-h) - F(-x)}{-h}) = \limsup_{h \to 0^-} (\frac{F(-x+h)- F(-x)}{h})$$


	$$ = D^-(F)(-x) = D^-(F)(y)$$

	$$D_-(-F)(y) = D_+(F)(y)$$

	$$\Rightarrow D_- \leq D_+$$

	$$\Rightarrow D^+ \stackrel{(b)}{\leq} D_- \leq D^- \leq D_+ \leq D_+ \stackrel{(a)}{<} \infty$$

	So all are equal and finite. $\Rightarrow F'$ exists a.e. Remains to verify (a) and (b). For $\gamma > 0$, define 

	$$E_\gamma = \{x: D^+ (F)(x) > \gamma\}$$

	$E_\gamma$ is measurable. Apply the remark to $G(x) = F(x) - \gamma_x$

	$$E = \{x \in (a, b): G(x + h) > G(x) \text{ for some } h > 0\}$$

	$$\Rightarrow E_\gamma \\ {a} \subset E = \bigcup_k (a_k, b_k)$$

	By Remark, $G(a_k) \leq G(b_k)$

	$$\Rightarrow F(a_k) - \gamma a_k \leq F(b_k) - \gamma b_k$$

	$$\Rightarrow F(b_k) - F(a_k) \leq \gamma (b_k - a_k)$$

	$$m(E_\gamma) \leq m(E) \leq \sum_k m((a_k, b_k)) \leq \frac{1}{\gamma} \sum_k (F(b_k) - F(a_k))$$

	$$\stackrel{\text{F increasing}}{\leq} \frac{1}{\gamma} (F(b) - F(a))$$

	$$\Rightarrow \lim_{\gamma \to \infty} m(E_\gamma) = 0$$

	$$\Rightarrow \{ x : D^+ = \infty\} \text{ has measure zero }$$

	\[
	  D^+(F)(x) \leq D_-(F)(x) \text{ for a.e. x }
	\]
	Fix $r < R$ rationals. Define 
	\[
	  E = \{x \in [a, b]: D^+(F)(x) < r < R < D_-(F)(x)\}
	\]
	If we can show $m(E) = 0$ then we are done (Take union over $r < R$). Assume that $m(E) > 0$. Recall: $\forall \epsilon > 0, \exists \text{ open } \mathcal{U} \supset E$ s.t. $m(\mathcal{U} < m(E) + \epsilon$. $R/r > 1 \Rightarrow$ take $\epsilon = (R/r - 1) m(E) > 0$. Find an open set $E \subset \mathcal{U} \subset (a, b)$ s.t. 
	\[
	  m(\mathcal{U}) < \frac{R}{r} m(E)
	\]
	Write $\mathcal{U} = \cup_{n} I_n$ where $I_n$ are disjoint open intervals (may assume $I_n \cup E \neq \phi \sfa n$). 
	\par Recall: $G:[a, b] \to \mathbb{R}$ continuous. 
	\[
	E = \{x \in (a, b) : G(x + h) > G(x) \text{ for some } h > 0\}
	\]
	If $E \neq \phi$, write $E = \cup_k(a_k, b_k)$. We have $G(a_k) \leq G(b_k)$. We apply the above to $G(x) = F(-x) + rx$ on $-I_n$. 
	\[
	  E_n = \{x \in -I_n: G(x + h) > G(x) \text{ for some }h > 0\}
	\]
	$E_n \neq \phi$? Now 
	\[
	  G(x + h) > G(x) \Leftrightarrow F(-x - h)+ r(x + h) > F(-x) + rx
	\]
	\[
	  \Leftrightarrow F(-x - h) - F(-x) > -rh
	\]
	\[
	  \Leftrightarrow \frac{F(-x - h) - F(-x)}{-h} < r
	\]
	If $x \in (-E) \cap (-I_n)$ then $x \in E_n$. So $E_n \neq \phi$. Write $E_n = \cap_k (-b_k, -a_k)$. Then we have $G(-b_k) \leq G(-a_k)$. 
	\[
	  \Leftrightarrow F(b_k) - F(a_k) \leq r (b_k - a_k)
	\]
	On each $(a_k, b_k)$, we can apply the recall to 
	\[
	  G(x) = F(x) - Rx
	\]
	By a similar argument, we obtain an open set $E_n' = \cup_{k, j} (a_{k, j}, b_{k, j})$ s.t. $(a_{k, j}, b_{k, j}) \subset (a_k, b_k) \sfa j$ and $F(b_{k, j}) - F(a_{k, j}) \geq R(b_{k, j} - a_{k, j})$. 
	\[
	  m(E_n') = \sum_{k, j} ( b_{k, j} - a_{k, j})
	\]
	\[
	  \leq \frac{1}{R} \sum_{k, j} (F(b_{k, j}) - F(a_{k, j}))
	\]
	\[
	  \stackrel{\text{F increasing}}{\leq} \frac{1}{R} \sum_{k} (F(b_k) - F(a_k))
	\]
	\[
	  \leq \frac{r}{R} \sum_k (b_k - a_k)
	\]
	\[
	  \leq \frac{r}{R} m(I_n)
	\]
	We can show similarly that $I_n \cap E \subset E_n'$. 
	\[
	  m(E) = \sum_n m(E \cap I_n) \leq \sum_n m(E_n')
	\]
	\[
	  \leq \frac{r}{R} \sum_n m(I_n) = \frac{r}{R} m(\mathcal{U}) < m(E)
	\]
	A contradiction!!!!! So $m(E) = 0$. 
\end{proofs}

\begin{rem}
  If $p = \infty$
  \[
    \|f\|_{\infty} = \text{esssup} (|f|)
  \]
  where
  \[
    \text{esssup} (f) \equiv \inf \{y > 0: m(|f| > y) = 0\}
  \]
\end{rem}

\begin{cor}
  If $F$ is increasing and continuous, the $F'$ exists a.e. Moreover, $F'$ is measurable, nonnegative, and 
  \[
    \int_a^b F'(x) \mathrm{d} x \leq F(b) - F(a)
  \]
  In particular, if $F$ is bounded on $\mathbb{R}$, then $F'$ is integrable on $\mathbb{R}$. 
\end{cor}

\begin{proofs}
  We only prove the statement in the middle. 
  \[
    F'(x) = \lim_{n \to \infty} n (F(x +  \frac{1}{n}) - F(x))
  \]
  exists a.e. So $F'$ is measurable. 
  \[
    \int_a^b F'(x) \mathrm{d}x \leq \liminf_{n \to \infty} n\int_a^b (F(x + \frac{1}{n}) - F(x)) \mathrm{d} x
  \]
  \[
    \Rightarrow \int_a^b F'(x) \mathrm{d}x \leq n \int_b^{b + \frac{1}{n}} F(x) \mathrm{d} x - n \int_a^{a + \frac{1}{n}} F(x) \mathrm{d} x = F(b) - F(a)
  \]
  where the last line comes from continuity. We do not expect equality holds for all increasing and continuous $F$. Counterexapmle: Cantor function. 

\end{proofs}

\section{Absolutely continuous functions}

\begin{dfn}
	A function $F:[a, b] \to \mathbb{R}$ is said to be \textbf{absolutely continuous} if $\forall \epsilon > 0, \exists \delta > 0$ s.t.
  \[
    \sum_{k =1}^N |F(b_k ) - F(a_k)| < \epsilon \text{ whenever } \sum_{k = 1}^N (b_k - a_k) < \delta
  \]
  where $(a_k, b_k), k = 1, ..., N$ are disjoint intervals. 
\end{dfn}

Observations:

\begin{itemize}
  \item Absolute continuity $\Rightarrow$ Uniform continuity
  \item Absolute continuity $\Rightarrow$ bounded variation. In this case, the total variation is also absolutely continuous. 
\end{itemize}

So every absolutely continuous function can be written as a difference of two increasing functions. 

\begin{ex}
  
  \begin{itemize}
    \item Lipschitz functions.
    \item $F(x) = \int_a^x f(x) \mathrm{d} x$, where $f$ integrable. $F$ is absolutely continuous. Recall: $\forall \epsilon > 0, \exists \delta > 0$ s.t. $m(E) < \delta \Rightarrow \int_E |f| < \epsilon$. ($f$ is integrable) 
  \end{itemize}

\end{ex}

From the second example, if  we want $F(b) - F(a) = \int_a^b F'(x) \mathrm{d} x$, then $F$ has to be absolutely continuous. It turns out that absolute continuity is sufficient!

\begin{dfn}
	A collection $\mathcal{B}$ is said to be a \textbf{Vitali covering} of a set $E$ if $\forall x \in E$ and $\forall \eta > 0$, exists a ball $B \in \mathcal{B}$ s.t. $x \in B$ and $m(B) < \eta$. 
\end{dfn}

\begin{lem}
  Suppose that $m(E) < \infty$, and $\mathcal{B}$ is a Vitali covering of $E$. For any $\delta > 0$, we can find finitely many balls $B_1, ...,B_n \in \mathcal{B}$ that are disjoint and s.t.
  \[
    m(E) < \sum_{i = 1}^N m(B_i) + \delta
  \]
\end{lem}

\begin{proofs}
  May assume $m(E) > \delta$. Take any compact $E' \subset E$ s.t. $m(E') \geq \delta$. We can cover $E'$ by finitely many balls in $\mathcal{B}$. Recall: if $\{B_1, ..., B_k\}$ are open balls, we can find a disjoint collection $B_{i_1}, ..., B_{i_j}$ of balls s.t.
  \[
    m\left(\bigcup_{i = 1}^k B_i\right) \leq 3^d \sum_{l = 1}^j m(B_{i_l})
  \]
  So we obtain disjoint balls from $\mathcal{B}$, say $B_1, ..., B_{N_1}$, s.t.
  \[
    \delta \leq 3^d \sum_{i = 1}^{N_1} m(B_i)
  \]
  Two cases:
  \begin{enumerate}
    \item $m(E) \leq \sum_{i = 1}^{N_1} m(B_i) + \delta$. Then done.
    \item $m(E) > \sum_{i = 1}^{N_1} m(B_i) + \delta$. Consider $E_2 = E \setminus \cup_{i = 1}^{N_1} \overline{B_i}$. Then $m(E_2) > \delta$. Moreover, the balls in $\mathcal{B}$ that are disjoint from $\cup_{i = 1}^{N_1} \overline{B_i}$ is a Vitali covering for $E_2$. Therefore from this remaining collection of balls we can find disjoint balls, say
      \[
        B_{N_1 + 1}, ..., B_{N_2}
      \]
      s.t.
      \[
        \delta \leq 3^d \sum_{i = N_1 + 1}^{N_2} m(B_i)
      \]
      Again two cases:
      
      \begin{enumerate}
        \item $m(E) < \delta + \sum_{i =1}^{N_2} m(B_i)$ Then done.
        \item $m(E) > \delta + \sum_{i = 1}^{N_2} m(B_i) \geq 2 \delta 3^{-d}$. 
      \end{enumerate}

      At each step we increase by a factor of $\delta \cdot 3^{-d}$. $m(E) < \infty$, this procedure must stop at some point. 
  \end{enumerate}
\end{proofs}

\begin{thm}
  If $F$ is absolutely continuous on $[a, b]$, then $F'$ exists almost everywhere. Moreover, if $F'(x) = 0$ for a.e. $x$, then $F$ is a constant. 
\end{thm} 

\begin{proofs}
  To prove the second statement, we just need to show that $F(b) = F(a)$ (can apply the argument to subintervals). Let 
  \[
    E = \{ s \in (a, b): F'(x) \text{ exists and } F'(x) = 0\}
  \]
  Then $m(E) = b - a$. Fix $\epsilon > 0$. For each $x \in E$, we have 
  \[
    \lim_{h \to 0} \left|\frac{F(x + h) - F(x)}{h}\right| = 0
  \]
  So for each $\eta > 0$, $\exists $ open interval $I = (a_x, b_x) \subset [a, b]$ containing $x$ s.t.
  \[
    |F(b_x) - F(a_x)| \leq \epsilon (b_x - a_x) \text{ and } (b_x - a_x) < \eta
  \]
  These intervals form a Vitali covering of $E$. By the previous lemma, $\forall \delta >0 $, we can find finitely many intervals $I_1, ..., I_N$ s.t. they are disjoint and 
  \[
    b - a = m(E) \leq \sum_{i = 1}^N m(I_i) + \delta
  \]
  \[
    m \left( \bigcup_{i = 1}^N I_i \right) = \sum_{i = 1}^N m(I_i) \geq (b - a) - \delta 
  \]
  Write $I_i = (a_i, b_i)$. The complement of $\cup_{i = 1}^N I_i$ in $[a, b]$ has measure $\leq \delta$. Also, it is a union of finitely many closed interals $\cup_{k = 1}^M [\alpha_k \beta_k]$. By absolute continuity, we can choose $\delta > 0$ small s.t.
  \[
    \sum_{k = 1}^M |F(\beta_k) - F(\alpha_k)| < \epsilon
  \]
  On the other hand, 
  \[
    |F(b_i) - F(a_i)| \leq \epsilon (b_i - a_i)
  \]
  \[
    \Rightarrow \sum_{i = 1}^N |F(b_i) - F(a_i)| \leq \epsilon (b - a)
  \]
  Combine everything, 
  \[
    |F(b) - F(a)| \leq \sum_{k = 1}^M |F(\beta_k) - F(\alpha_k)| + \sum_{i = 1}^N |F(b_i) - F(a_i)| \leq \epsilon(b - a + 1)
  \]
  $\epsilon > 0$ is arbitrary, so $F(b) = F(a)$. 

\end{proofs}

\begin{cor}
  Suppose $F$ is absolutely continuous on $[a, b]$. Then $F'$ exists a.e. and is integrable. Moreover 
  \[
    F(x) - F(a) = \int_a^x F'(y) \mathrm{d} y \sfa x \in [a, b]
  \]
  Conversely, if $f$ is integrable on $[a, b]$, then $\exists$ absolutely continuous function $F$ s.t. $F' = f$ a.e.
\end{cor}

\begin{proofs}
  $F'$ integrable because 
  \[
    \int_a^b G'(x) \mathrm{d} x \leq G(b) - G(a)
  \]
  if $G$ is increasing and continuous. To prove the equality, let $G(x) = \int_a^x F'(y) \mathrm{d} y$. So $G$ is absolutely continuous, and so is $G - F$.  By the Lebesgue differentiation theorem, $G'(x) = F'(x)$ for a.e. $x$. So $(G - F)' = 0$ a.e. $\Rightarrow G - F$ is a constant. 
  \[
    \Rightarrow \int_a^x F'(y) \mathrm{d} y = F(x) - F(a)
  \]
  For the converse part, take $F(x) = \int_a^x f(y) \mathrm{d} y$. 
\end{proofs}

\section{Differentiability of jump functions}

Recall: We haven't finished if $F$ is of bounded variation on $[a, b]$ then it is differentiable a.e.
\par Let $F:[a, b] \to \mathbb{R}$ be increasing and bounded. Write $(x_n)$ for the points at which $F$ is discontinuous. Let
\[
  \alpha_n = F(x_n^+) - F(x_n^-)
\]
which is the jump of $F$ at $x_n$. $\exists \theta_n \in [0,1]$ s.t. $F(x_n) = F(x_n^-) + \theta_n \alpha_n$. Define 
\[
  j_n(x) = 
  \begin{cases}
    0 & \text{if } x < x_n\\
    \theta_n & \text{if } x = x_n\\
    1 & \text{if } x > x_n
  \end{cases}
\]
Finally, define the jump function associated to $F$ by 
\[
  J_F(x) = \sum_{n - 1}^\infty \alpha_n j_n(x)
\]
Observe:
\[
  \sum_{n = 1}^\infty \alpha_n \leq F(b) - F(a) < \infty
\]
So the series defining $J_F$ converges absolutely and uniformly. 
\begin{lem}
  Suppose that $F$ is increasing and bounded on $[a, b]$. Then $J_F$ is dscontinuous precisely at $(x_n)$, and has jump at $x_n$ equal to that of $F$. Moreover, $F - J_F$ is increasing and continuous. 
\end{lem}

\par Recall: $(x_n)$: discontinuities of $F$. $\alpha_n = F(x_n^+) - F(x_n^-)$. $\exists \theta_n \in [0, 1]$ s.t. $F(x_n) = F(x_n^-) + \theta_n \alpha_n$

\[
  j_n(x) = 
  \begin{cases}
    0 & \text{if } x < x_n\\
    \theta_n & \text{if } x = x_n\\
    1 & \text{if } x > x_n
  \end{cases}
\]
\[
  J_F(x) = \sum_{n = 1}^\infty \alpha_n j_n(x) 
\]
where the series converges absolutely and uniformly.

\begin{lem}
  Suppose that $F$ is increasing and bounded on $[a, b]$. Then $J_F$ is discontinuous preccisely at $(c_n)$, and has jump at $x_n$ equal to that of $F$. Moreover, $F - J_F$ is increasing and continuous. 
\end{lem}

\begin{proofs}
  If $x \neq x_n \sfa n$, each $j_n$ is continuous at $x$. By uniform convergence, $J_n$ is continuous at $x$. If $x = x_k$ for some $k$, write 
  \[
    J_F(x) = \sum_{n = 1}^k \alpha_n j_n(x) + \sum_{n = k + 1}^{\infty} \alpha j_n(x)
  \]
  where the first part has a jump discontinuity at $x_k$ of size $\alpha_k$ and the second part is continuous. Alse, the jump size of $J_F$ is the same as that of $F$. $\Rightarrow F - J_F$ is continuous. Let $x < y$. 
  \[
    J_F(y) - J_F(x) \leq \sum_{n: x < x_n \leq y} \alpha_n \leq F(y) - F(x)
  \]
  \[
    \Rightarrow F(x) - J_F(x) \leq F(y) - J_F(y) \Rightarrow F - J_F \text{ increasing}
  \]
\end{proofs}

\[
  F = (F - J_F) + J_F
\]
where $F - J_F$ is differentiable a.e.

\begin{clm}
  $J_F$ is differentiable a.e.
\end{clm}

\begin{proofs}
  Fix $\epsilon > 0$. 
  \[
    E = \{x: \limsup_{h \to 0} \frac{J_F(x + h) - J_F(x)}{h} > \epsilon\}
  \]
  Check: $E$ is measurable. Let $\delta = m(E)$. Want: $\delta = 0$.
  \[
    \sum_{n = 1}^\infty \alpha_n < \infty \Rightarrow \forall \eta > 0, \exists N \text{ s.t. } \sum_{n > N} \alpha_n < \eta
  \]
  Consider
  \[
    J_0(x) = \sum_{n > N} \alpha_nj_n(x)
  \]
  \[
    \Rightarrow J_0(b) - J_0(a) < \eta
  \]
  $J_F - J_0$ is just a finite sum of $\alpha_n j_n(x)$.
  \[
    E_0 = \{x: \limsup_{h \to 0} \frac{J_0(x + h) - J_0(x)}{h} > \epsilon\}
  \]
  $E_0$ differs from $E$ by at most a finite set (which is $\{x_1, ..., x_n\}$). $\Rightarrow m(E_0) = \delta$. By inner regularitty, find compact $K \subset E_0$ s.t. $m(K) \geq \delta/2$. By definition, 
  \[
    \limsup_{h \to 0} \frac{J_0(x + h) - J_0(x)}{h} > \epsilon \sfa x \in K
  \]
  So for any $x \in K, \exists $interval $(a_x, b_x) \ni x$ s.t.
  \[
    J_0(b_x) - J_0(a_x) > \epsilon(b_x - a_x)
  \]
  $K$ compact $\Rightarrow $ a finite collection of these intervals covers $K$. By Vitali's covering lemma, find disjoint intervals $I_1, ..., I_n$ s.t. $m(K) \leq 3 \sum_{i = 1}^n m(I_i)$. Write $I_i = (a_i, b_i)$. 
  \[
    \eta > J_0(b) - J_0(a) \stackrel{J_0 \text{ increasing}}{\geq} \sum_{j = 1}^n (J_0(b_j) - J_0(a_j)) 
  \]
  \[
    > \epsilon \sum_{j = 1}^n (b_j - a_j) \geq \frac{\epsilon}{3} m(K) \geq \frac{\epsilon \delta}{6}
  \]
  Let $\eta \to 0$, we have $\delta = 0$. 
\end{proofs}

\section{Rectifiable curves}

\begin{dfn}
	Let $\gamma$ be a parametrized curve in the plane by $z(t) = (x(t), y(t))$, where $a \leq t \leq b, x, y$ are continuous real-valued on $[a, b]$. (Will assume $\forall x \in \gamma, z^{-1}(\{x\})$ is a closed interval or a singleton). $\gamma$ is said to be \textbf{rectifiable} if $\exists M > 0$ s.t. $\forall$ partition $a = t_0 < t_1 < \hdots < t_N = b$ of $[a, b]$, 
  \[
    \sum_{j = 1}^N |z(t_j) - z(t_{j - 1})| \leq M
  \]
\end{dfn}
We define the length $L(\gamma)$ of $\gamma$ fo be the sup of L.H.S. (so $L(\gamma) = T_z(a, b)$). What conditions on $x$ and $y$ will guarantee that $\gamma$ is rectifiable? If $x, y$ are differentiable a.e., is it true that
\[
  L(\gamma) = \int_a^b \sqrt{(x'(t))^2 + (y'(t))^2} \mathrm{d} t \text{?}
\]

\begin{prop}
  $\gamma$ is rectifiable $\iff x, y$ are of bounded variation. 
\end{prop}

\begin{proof}
  Easy.
\end{proof}

The answer to the second question is \textbf{no} in general. Let $x, y$ be the Cantor function. $z(t) = (x(t), y(t))$ parametrizes $\gamma$. 

\begin{thm}
  If $x$ and $y$ are absolutely continuous, then $\gamma$ is rectifiable. Moreover, 
  \[
    L(\gamma) = \int_a^b \sqrt{(x'(t))^2 + (y'(t))^2} \mathrm{d} t
  \]
\end{thm}

We prove something more general:

\begin{prop}
  If $F$ is complex-valued and absolutely continuous on $[a, b]$, then 
  \[
    T_F(a, b) = \int_a^b |F'(t)| \mathrm{d} t
  \]
\end{prop}

\begin{proofs}
  By absolute continuity, for any partition $a = t_1 < \hdots < t_N = b$ of $[a, b]$, 
  \[
    \sum_{j = 1}^N |F(t_j) - F(t_{j - 1})| = \sum_{j = 1}^N |\int_{t_{j - 1}}^{t_j} F'(t) \mathrm{d} t| \leq \sum_{j = 1}^N \int_{t_{j - 1}}^{t_j} |F'(t) \mathrm{d} t = \int_a^b |F'(t)| \mathrm{d} t
  \]
  Take sup over all partitions
  \[
    \Rightarrow T_F(a, b) \leq \int_a^b |F'(t)| \mathrm{d} t
  \]
  Fix $\epsilon > 0$. $F$ absolutely continuous $\Rightarrow F$ integrable on $[a, b]$. $\exists $ a step function $G$ on $[a, b]$ s.t.
  \[
    \|F' - g\|_{L^1} < \epsilon
  \]
  Let 
  \[
	h(x) = F'(x) - g(x)
  \]
  Set 
  \[
    G(x) = \int_a^x g(t) \mathrm{d} t, H(x) = \int_a^x h(t) \mathrm{d} t
  \]
  \[
    F' = g + h \Rightarrow F(x) - F(a) = G(x) + H(x)
  \]
  \[
    \stackrel{\Delta \text{-ineq}}{\Rightarrow } T_F(a, b) \geq T_G(a, b) - T_H(a, b)
  \]
  $H$ is absolute continuous. From "$\leq$": 
  \[
    T_H(a, b) \leq \int_a^b |H'(t)| \mathrm{d} t = \int_a^b |h(t)| \mathrm{d} t < \epsilon
  \]
  \[
    \Rightarrow T_F(a, b) \geq T_G(a, b) - \epsilon
  \]
  Choose a partition $a = t_0 < \hdots < t_N = b$ s.t. $g$ is a constant on each $(t_{j - 1}, t_j)$ (since $g$ is a step function!). 
  \[
    T_G(a, b) \geq \sum_{j = 1}^N |G(t_j) - G(t_{j - 1})| = \sum_{j = 1}^N \left|\int_{t_{j - 1}}^{t_j} g(t) \mathrm{d} t \right|
  \]
  since $g$ is a constant
  \[
    \text{R.H.S. }= \sum_{j - 1}^N \int_{t_{j - 1}}^{t_j} |g(t)| \mathrm{d} t = \int_a^b |g(t)| \mathrm{d} t \geq \int_a^b |F'(t)| \mathrm{d} t - \epsilon
  \]
  \[
    T_F(a, b) \geq \int_a^b |F'(t)| \mathrm{d} t - 2 \epsilon
  \]
\end{proofs}

A curve can be realized by many different parametrizations. Is there a good/natural one? Suppose that $\gamma$ is parametrized by $t \to z(t)$. Write $s(t)$ for the length of the segment of $\gamma$ that arises as the image of $z([a, t])$. 

\par Check: $s$ is a continuous increasing function from $[a, b]$ to $[0, L]$. 

\par The arc length (re)parametrization of $\gamma$ is given by $\tilde{z}(s)$ where $\tilde{z}(s) = z(t)$ for $s = s(t)$. 

\par Check: $\tilde{z}$ is well-defined. 

\par Note: $|\tilde{z}(s_1) - \tilde{z}(s_2)| \leq |s_1 - s_2| \sfa s_1, s_2 \in [0, L]$ ($\tilde{z}$ is Lipschitz). So $\tilde{z}$ is absolutely continuous. Moreover, $|\tilde{z}'(s)| = 1$ a.e. By the Lipschitz inequality, $|\tilde{z}'(s)| \leq 1$ a.e. By definition, 
\[
  L = T_{\tilde{z}}(a, b) = \int_0^L |\tilde{z}'(s)| \mathrm{d} s
\]
So $|\tilde{z}'(s)| = 1$ a.e. Writing $(\tilde{z}(s)) = (\tilde{x}(s), \tilde{y}(s))$, 
\[
  L = \int_0^L \sqrt{(\tilde{x}(s))^2 + (\tilde{y}(s))^2} \mathrm{d} s
\]

\section{Banach spaces}

\par Complete normed vector spaces. 

\par Fix $1 \leq p \leq \infty$. 
\[
  l^p = \{(x_n): \sum_{n = 1}^\infty |x_n|^p < \infty \}
\]
Define $\|(x_n)\|_{p} = (\sum_{n = 1}^\infty |x_n|^p)^{1/p}$. 
\[
  l^\infty = \{(x_n): \sup_{n \geq 1} |x_n| = \|(x_n)\|_{\infty} < \infty\}
\]

\par Check: $l^p$ are Banach spaces.

\begin{rem}
  When observing a unknown space, considering the functions building on it gives some interesting information. For example, if one wants to examine the topological structure on $\mathbb{R}$, we could consider continuous functions. If we want to study the algebraic structure, we could consider linear functions, etc. 
\end{rem}

\subsection{Linear functionals and dual space}

\begin{dfn}
	Let $X$ be a vector space. A \textbf{linear functional} is a linear function from $X$ to $\mathbb{C}$. 
  \[
    L(X, \mathbb{C}) = \{\text{linear functionals from }X \text{ to } \mathbb{C}\}
  \]
\end{dfn}

$X$ infinite dimensional $\Rightarrow L(X, \mathbb{C})$ infinite dimensional (Check!). A linar functional may not capture the norm structure of $X$ if $X$ is a normed vector space. 

\begin{dfn}
	Let $X$ be a normed space. We say that $\Lambda \in L(X, \mathbb{C})$ is \textbf{bounded} if it maps any bounded set in $X$ to a bounded set in $\mathbb{C}$. 
\end{dfn}

If $\Lambda$ is bounded then for any bounded set $A \subset X, \exists C > 0$ s.t. $|\Lambda x| \leq C \sfa x \in A$.

\begin{prop}
  Let $\Lambda \in L(X, \mathbb{C})$, where $X$ is a normed space. 
  \begin{enumerate}
    \item[(a)] $\Lambda$ is bounded $\Lra \exists C > 0$ s.t.
      \[
        |\Lambda x| \leq C \| x \| \sfa x \in X
      \]
    \item[(b)] $\Lambda$ is continuous $\Lra \Lambda$ is continous at one point. 
    \item[(c)] $\Lambda$ is continuity $\Lra \Lambda$ is bounded. 
  \end{enumerate}
\end{prop}

\begin{proofs}
  \begin{enumerate}
    \item[(a)] Suppose that $\Lambda$ is bounded. Take $A = \overline{B(0, 1)}$. If $x \in X\setminus \{0\}$, then $x/\|x\| \in A$. $\exists C > 0$ s.t. $|\Lambda y| \leq C \sfa y \in A$. 
      \[
        \Rightarrow \left|\Lambda \left(\frac{x}{\|x\|} \right)\right| \leq C \sfa x \neq 0
      \]
      \[
        \Rightarrow |\Lambda x| \leq C \|x\| \sfa x \in X
      \]
      Converse is easy. 
  \end{enumerate}
\end{proofs}

\par Recall: $X$ a normed space.
$L(X, \mathbb{C}) = \text{ space of all linear functionals from } X \text{ to } \mathbb{C}$.

\begin{prop}
	$\Lambda \in L(X, \mathbb{C})$. 

	\begin{enumerate}
		\item[(a)] $\Lambda$ is bounded $\Leftrightarrow \exists C > 0$ s.t. $|\Lambda x| \leq C\| x \| \sfa x \in X$.

		\item[(b)] $\Lambda$ is continuous $\Leftrightarrow \Lambda$ is continuous at one point.

		\item[(c)] $\Lambda$ is continuous $\Leftrightarrow \Lambda$ is bounded.
	\end{enumerate}
\end{prop}

\begin{proofs}
	We proved (a). 
	\par (b). We only show the other "$\Leftarrow$". 
	Suppose that $\Lambda$ is continuous at $x_0$.
	Fix $x \in X$. 
	Let $(x_n)$ be a sequence in $X$ that converges to $x$.
	Define $y_n = x_n - x + x_0$.
	Then $y_n \to x_0$.
	So $\Lambda y_n \to \Lambda x_0 \Rightarrow \Lambda x_n - \Lambda x \to 0 \Rightarrow \Lambda x_n \to \Lambda x$.
	So $\Lambda$ is continuous at $x$.
	\par (c). Suppose that $\Lambda$ is not bounded. 
	$\exists M > 0$ and a sequence $(x_n)$ in $X$ s.t. $\|x_n\| \leq M$ but $|\Lambda x_n| \to \infty$.
	May assume $\Lambda x_n \neq 0 \sfa n$. 
	Define $y_n = x_n / |\Lambda x_n|$.
	Then $\|y_n \| \to 0$, but $| \Lambda y_n| = 1$ for all $n$. \
	$\Lambda$ is not continuous. 
	On the other hand, suppoes that $\Lambda$ is bounded. By (a), $\Lambda$ is Lipschitz $\Rightarrow \Lambda$ is continuous. 

\end{proofs}

$X^* = $ Set of all bounded linear functionals on $X$, called the Dual space/topological dual.
$X^* \subset L(X, \mathbb{C})$.
If $X$ is finite dimensional, then $X^* = L(X, \mathbb{C})$. 
If $X$ is infinite dimensional, that $X^* \subset L(X, \mathbb{C})$ but $X^* \neq L(X, \mathbb{C}$). 
Why? 
Let $B$ be a Hamel basis for $X$.
Normalize the vectors in $B$ s.t. all have norm 1.
Pick $\{x_1, x_2, x_3, ...\}$ from $B$. 
Define
\[
	\begin{cases}
		\Lambda x_i = i & \forall i\\
		\Lambda x = 0 & \text{ if } x \in B \setminus \{x_1, ...\}
	\end{cases}
\]
Extend $\Lambda$ linearly.($ \forall v \in X, v = a_1 v_1 + \hdots + a_n v_n$ where $v_1, ..., v_n \in B$. $\Lambda v = a_1 \Lambda v_1 + \hdots + a_n \Lambda v_n$.)
Then $\Lambda$ is unbounded.

\begin{prop}
	Let $X$ be a normed space and $\Lambda \in X^*$. 
	Define 
	\[
		\|\Lambda\| = \sup_{x \neq 0} \frac{|\Lambda x|}{\|x\|}
	\]
	Then $\| \cdot \|$ is a norm on $X^*$ called the operator norm. 
\end{prop}

\begin{rem}
	We can define
	\[
		\| \Lambda \| = \sup_{\|x\| = 1} |\Lambda x| = \sup_{\| x \| \leq 1} |\Lambda x|
	\]
	From definition, we have $|\Lambda x| \leq \| \Lambda \| \|x\| \sfa x \in X$. 
	Exercise: Verify this. 
\end{rem}

\begin{proofs}
	We only prove the $\Delta$-ineq. 
	Let $\Lambda_1, \Lambda_2 \in X^*$ and let $x \in X$ with $\|x\| = 1$. 
	Then
	\[
		|(\Lambda_1 + \Lambda_2)(x)| \leq |\Lambda_1 x| + |\Lambda_2 x| \leq \|\Lambda_1 \| + \| \Lambda_2 \|
	\]
	Take sup over all $\|x\| = 1$, done.
\end{proofs}

\begin{prop}
	If $X$ is a normed space, then $X^*$ is a Banach space.
\end{prop}

\begin{proofs}
	Let $(\Lambda_k)$ be a Cauchy sequence in $X^*$.
	Fix $\epsilon > 0$.
	$\exists K$ s.t. $\|\Lambda_k - \Lambda_l\| < \epsilon \sfa k, l \geq K$. 
	For $x \in X$, 
	\[
		|\Lambda_k x- \Lambda_l x| \leq \|\Lambda_k - \Lambda_l \| \|x \| < \epsilon \|x\| \sfa k, l \geq K \hdots (*)
	\]
	So for each $x \in X, (\Lambda_k x)$ is a Cauchy sequence in $\mathbb{C}$.
	$\lim_{k \to \infty} \Lambda_k x$ exists $\forall x \in X$. 
	Define $\Lambda x = \lim_{k \to \infty} \Lambda_k x$.
	Check: $\Lambda$ is linear. 
	Let $l \to \infty$ in $(*)$.
	\[
		|\Lambda_k x - \Lambda x| \leq \epsilon \|x\| \sfa k \geq K \hdots (!)
	\]
	\[
		|\Lambda x| \leq (\epsilon + \|\Lambda_{K}\|) \|x\|
	\]
	This holds for all $x \in X$, so $\Lambda \in X^*$. Finally, we show $\Lambda_k \to \Lambda$ in norm.
	from (!), $\| \Lambda_k - \Lambda\| \leq \epsilon \sfa k \geq K$.
	So $\Lambda_k \to \Lambda$.
\end{proofs}

\begin{ex}
	\begin{prop}
		Let $1 \leq p < \infty$. The dual of $l^p$ is isometrically isomorphic to $l^q$ where $q = \frac{p}{p - 1}$.
	\end{prop}

	\begin{proofs}
		We only prove the case when $p > 1$. 
		Define $e_j = (0, \hdots 0, 1, 0, 0, \hdots)$ where only the $j^{\text{th}}$ position is 1.
		Define $\Phi: (l^p)^* \to l^q$ as follows:
		For $\Lambda \in (l^p)^*$, define 
		\[
			\Phi(\Lambda) = (\Lambda e_1, \Lambda e_2, \hdots )
		\]
		We first verify that $\Phi(\Lambda) \in l^q$.
		Write $\Phi(\Lambda)= (a_1, a_2, ...,)$.
		$\exists \theta_j$ s.t. $a_j = e^{i \theta_j} |a_j|$.
		Define 
		\[
			a^N = (e^{-i \theta_1}|a_1|^{q-1}, ..., e^{-i \theta_N}|a_N|^{q- 1}, 0, 0, ...)
		\]
		Then $a^N \in l^p \sfa N$.
		$(a^N = \sum_{j = 1}^N e^{-i \theta_j} |a_j|^{q - 1} e_j)$.
		\[
			|\Lambda a^N| = \left| \sum_{j = 1}^N e^{-i \theta_j} |a_j|^{q - 1} \Lambda e_j\right|
		\]
		\[
			= \left|\sum_{j =1}^N e^{-i \theta_j} |a_j|^{q - 1} a_j\right| = \sum_{j = 1}^N |a_j|^q
		\]
		\[
			\|a^N\|_{l^p} = \left( \sum_{j = 1}^N \left(|a_j|^{q - 1}\right)^{p} \right)^{\frac{1}{p}} = \left( \sum_{j = 1}^N |a_j|^q \right)^{\frac{1}{p}} 
		\]
		Recall: $|\Lambda x| \leq \|\Lambda \| \|x\|$.
		So we have 
		\[
			\sum_{j = 1}^N |a_j|^q \leq \|\Lambda\|\left(\sum_{j = 1}^N |a_j|^q\right)^{\frac{1}{p}}
		\]
		\[
			\Rightarrow \left( \sum_{j = 1}^N |a_j|^q\right)^{\frac{1}{q}} \leq \|\Lambda\|
		\]
		Let $N \to \infty$, we have
		\[
			\|\Phi(\Lambda)\|_{l^q} \leq \|\Lambda \|
		\]
		That is, $\Phi:(l^p)^* \to l^q$.
		Next, we show that $\Phi$ is onto.
		We will construct the inverse explicitly.
		For each $a \in l^q$, we define $\Psi(a) = \Lambda_a$, where $\Lambda_a \in (l^p)^*$ is given by $\Lambda_a x = \sum_{j = 1}^\infty a_j x_j \sfa x \in l^p$.
		By H\"older's inequality, 
		\[
			|\Lambda_a x| \leq \|a\|_{l^q} \|x\|_{l^p} \sfa x \in l^p
		\]
		So $\Lambda_a x$ is well-defined, and $\Lambda_a \in (l^p)^*$.
		Taking sup over all $x$ with $\|x\|_{l^p} = 1$, we have 
		\[
			\|\Psi(a)\| = \|\Lambda_a\| \leq \|a\|_{l^q}
		\]

		\begin{clm}
			$\Phi(\Psi(a)) = a \sfa a \in l^q$.
		\end{clm}

		\begin{proofs}
			Let $a \in l^q$.
			\[
				\Phi(\Psi(a)) = (\Psi(a) e_1, \Psi(a) e_2, ...) 
			\]
			\[
				= (a_1, a_2, ...) = a
			\]
		\end{proofs}
	Finally, we show $\Phi$ is an isometry.
	Recall: 
	\[
		\|\Phi(\Lambda)\|_{l^q} \leq \|\Lambda\|
	\]
	We also have$\Psi(\Phi(\Lambda)) = \Lambda \sfa \Lambda \in (l^p)^*$. (Why? $\Psi(\Phi(\Lambda)) = \Psi(\Lambda e_1, \Lambda e_2, ...) = \Lambda_{(\Lambda e_1, \Lambda e_2, ...)}$
	\[
		\forall x \in l^p, \Lambda_{(\Lambda e_1, \Lambda e_2, ...)} x = \sum_{j = 1}^\infty \Lambda e_j x_j = \Lambda \left(\sum_{j = 1}^\infty x_j e_j\right) = \Lambda x
	\]
	) Thus, 
	\[
		\| \Lambda \| = \|\Psi(\Phi(\Lambda))\| \leq \|\Phi(\Lambda)\|_{l^q} \leq \|\Lambda\|
	\]
	\[
		\Rightarrow \|\Phi(\Lambda)\|_{l^q} = \|\Lambda\|
	\]
	So $\Phi$ is an isometry.
	\end{proofs}
\end{ex}

Fact:$(L^p)^* = L^q$ is $1 \leq p < \infty, q = \frac{p}{p - 1}$.
What is $(C^0([a , b]))^*$?
We will need the Hahn-Banach theorem.
\begin{dfn}
	Let $X$ be a vector space (over $\mathbb{C}$). A function $p: X \to [0, \infty]$ is called \textbf{subadditive} if $p(x+y) \leq p(x) + p(y) \sfa x, y \in X$.
	$p:X \to [0, \infty]$ is \textbf{positively homogeneous} if 
	\[
		p(\alpha x) = \alpha p(x) \sfa x \in X, \sfa \alpha \geq 0
	\]
	A subadditive, positively homogeneous function is also called a \textbf{gauge} or a \textbf{Minkowski function}.
\end{dfn}

\begin{ex}
	\begin{itemize}
		\item If $X$ is a normed space, then $p(x)= c \|x\|$ ($c > 0$) is a gauge.

		\item Let $C$ be a convex set containing $O$ in $X$. Define 
			\[
				p_C(x) = \inf \{\alpha > 0: x \in \alpha C\}
			\]
			Also, define $p_C(x) = \infty$ if no such $\alpha$ exists.
			\begin{clm}
				$p_C$ is a gauge
			\end{clm}

			\begin{proofs}
				Positive homogenity is easy. 
				Let $x, y \in X$. If $p_C(x) = \infty$ or $p_C(y) = \infty$, there is nothing to prove.
				Assume $p_C(x), p_C(y) < \infty$.
				Fix $\epsilon > 0$.
				$\exists \alpha, \beta > 0$ s.t. $p_C(x) > \alpha - \epsilon$ and $p_C(y) > \beta - \epsilon$ and $\frac{x}{\alpha} \in C, \frac{y}{\beta} \in C$.
				\[
					\frac{x + y}{\alpha + \beta} = \frac{\alpha}{\alpha + \beta} \cdot \frac{x}{\alpha} + \frac{\beta}{\alpha + \beta} \cdot \frac{y}{\beta} \in C
				\]
				Hence, $p_C(x+y) \leq p_C(x) + p_C(y)$.
			\end{proofs}
	\end{itemize}
\end{ex}

\begin{thm}[Hahn-Banach]
	Let $X$ be a vector space and let $p$ be a gauge on $X$. 
	Suppose that $Y$ is a proper subspace of $X$.
	Let $\Lambda \in L(Y, \mathbb{C})$ satisfy
	\[
		Re(\Lambda x) \leq p(x) \sfa x \in Y
	\]
	Then $\exists$ an extension $\tilde{\Lambda}$ of $\Lambda$ to $L(X, \mathbb{C})$ s.t.
	\[
		Re(\tilde{\Lambda} x) \leq p(x) \sfa x \in X
	\]
	We will assume our vector spaces are over $\mathbb{R}$ first.
	The $\mathbb{C}$ case follows from the $\mathbb{R}$ case (we will see).
\end{thm}

\begin{proofs}
	\begin{lem}[One-step extension]
		Let $\Lambda \in L(Y, \mathbb{R})$ s.t. $\Lambda x \leq p(x) \sfa x \in Y$, and let $x_0 \in X \setminus Y$. $\exists$ an extension $\Lambda_1$ of $\Lambda$ on $Y' =$ the space spanned by $x_0$ and $Y$ s.t. $\Lambda_1 x \leq p(x) \sfa x \in Y'$.
	\end{lem}

	\begin{proofs}[Proof of lemma]
		Every $x \in Y'$ is of the form $x = y + c x_0$ for some $y \in Y$ and $c \in \mathbb{R}$. Any linear functional $\Lambda_1$ extending $\Lambda$ satisfies
		\[
			\Lambda_1 x = \Lambda_1 (y + c x_0) = \Lambda_1 y + c \Lambda_1 x_0
		\]
		\[
			= \Lambda y + c \Lambda_1 x_0
		\]
		Conversely, by assigning any value to $\Lambda_1 x_0$, one obtains an extension of $\Lambda$ to $Y'$. However, what we need is to choose an appropriate $\Lambda_1 x_0$ s.t. $\Lambda_1 x \leq p(x) \sfa x \in Y'$. To see such a choice is possible, we focus on the case that $c = \pm 1$.
		Need:
		\[
			\Lambda y \pm \Lambda_1 x_0 = \Lambda_1(y \pm x_0) \leq p(y \pm x_0) 
		\]
		\[
			\Leftrightarrow \Lambda_1 x_0 \leq p(y + x_0) - \Lambda y \text{ and } \Lambda y - p(y - x_0) \leq \Lambda_1 x_0 \sfa y \in Y
		\]
		\[
			\Leftrightarrow \forall y, z \in Y, \Lambda x - p(z - x_0) \leq \Lambda_1 x_0 \leq p(y + x_0) - \Lambda y
		\]
		Let 
		\[
			\alpha = \sup_{z \in Y} (\Lambda z - p(z - x_0))
		\]
		\[
			\beta = \inf_{y \in Y} (p(y + x_0) - \Lambda y)
		\]
		If $\alpha \leq \beta$, we set $\Lambda_1 x_0$ as any value between $\alpha$ and $\beta$
		\begin{clm}
			This gives the desired extension.
		\end{clm}

		\begin{proofs}[Proof of Claim]
			Need $\Lambda_1 x \leq p(x) \sfa x \in Y'$.
			For $c > 0$, 
			\[
				\Lambda_1 (y \pm c x_0) = \Lambda y \pm c \Lambda_1x_0
			\]
			\[
				= c\left( \Lambda \left(\frac{y}{c} \pm \Lambda_1 x_0 \right) \right) = c\left(\Lambda_1 \left(\frac{y}{c} \pm x_0\right) \right) \leq c p\left(\frac{y}{c} \pm x_0\right) = p(y \pm c x_0)
			\]
		\end{proofs}
		Remains to show $\alpha \leq \beta$.
		Only need to show 
		\[
			\Lambda z - p(z - x_0) \leq p(y + x_0) - \Lambda y \sfa y, z \in Y
		\]
		\[
			\Leftrightarrow \Lambda (y + z) \leq p (y + x_0) + p(z - x_0)
		\]
		by definition, $\forall y + z \in Y$, we have
		\[
			\Lambda (y + z) \leq p (y + z) = (y + x_0 + z - x_0) \leq p(y + x_0) + p(z - x_0)
		\]
		which completes the proof. 

	\end{proofs}

	We will first prove the case that $X$ is over $\mathbb{R}$.
	\[
		\mathcal{D} = \{ (Z, T): Y \subseteq Z \subseteq X, T \in L(Z, \mathbb{R}) \text{ extends } \Lambda \text{ and } T_x \leq p(x) \sfa x \in Z \}
	\]
	$(Y, \Lambda) \in \mathcal{D}$, so $\mathcal{D} \neq \phi$.
	Define $\leq$ on $\mathcal{D}$ as follows:
	$(Z_1, T_1) \leq (Z_2, T_2)$ if $Z_1 \subseteq Z_2$ and $T_2$ extends $T_1$.
	Let $\mathcal{C}$ be a chain (totally ordered subset) in $(\mathcal{D}, \leq)$.
	\begin{clm}
		$\mathcal{C}$ has an upper bound in $(\mathcal{D}, \leq)$.
	\end{clm}

	\begin{proofs}[Proof of Claim]
		Define 
		\[
			Z = \bigcup_{\alpha \in \mathcal{C}} Z_\alpha, T_z = T_\alpha z \text{ if } z \in Z_\alpha
		\]
		$Z$ is a vector sapce.
		Let $z_1, z_2 \in Z$. 
		Then $z_1 \in Z_\alpha$ and $z_1 \in Z_\beta$ for some $\alpha, \beta$. 
		Either $Z_\alpha \subseteq Z_\beta$ or the converse.
		Assume the former.
		Then $z_1, z_2 \in Z_\beta$.
		So $\lambda_1 z_1 + \lambda_2 z_2 \in Z_\beta \subseteq Z \sfa \lambda_1, \lambda_2 \in \mathbb{R}$.
		$\Rightarrow Z$ is a vector space.
		Similarly, you can show that $T_\alpha z = T_\beta z$ if $z \in Z_\alpha \cap Z_\beta$. 
		$\Rightarrow T$ is well-defined.
		If $z \in Z$, then $z \in Z_\alpha$ for some $\alpha$.
		\[
			T_z = T_\alpha z \leq p(z)
		\]
		$\Rightarrow (Z, T) \in \mathcal{D}$ is an upper bound for $\mathcal{C}$.
		By Zorn's lemma, $\mathcal{D}$ has a maximal element $(\bar{Z}, \bar{T})$.
		
	\end{proofs}
	
		\begin{clm}
			$\bar{Z} = X$
		\end{clm}

		\begin{proofs}[Proof of Claim]
			Suppose not.
			Pick $x_0 \in X \setminus \bar{Z}$.
			By one-step extension, we can find $T_1$ on $\bar{Z}' = \bar{Z} \bigoplus  span\{x_0\}$ s.t. $T_1$ extends $\bar{T}$ and $T_1(x) \leq p(x) \sfa x \in \bar{Z}$.
			Then $(\bar{Z}, \bar{T}) \leq (\bar{Z}', T_1) \in \mathcal{D}$.
			Impossible but maximal.
			So $\bar{Z} = X$.
		\end{proofs}
		$\tilde{\Lambda} = \bar{T}$ is our desired extension.
		\par What can we do if $X$ is over $\mathbb{C}$?
		A complex linear functional is uniquely determined by its real or imaginary part. 
		
		\begin{lem}
			\begin{enumerate}
				\item[(a)] Let $\Lambda \in L(X, \mathbb{C})$. 
					Then its real part and imaginary part are in $L(X, \mathbb{R})$ when $X$ is regarded as a vector space over $\mathbb{R}$.
					Moreover, 
					\[
						\Lambda x = Re(\Lambda x) - i Re(\Lambda(ix)) \sfa x \in X
					\]

				\item[(b)] Conversely, if $\Lambda_1 \in L(X, \mathbb{R}), \exists ! \Lambda \in L(X, \mathbb{C})$ s.t. $Re(\Lambda) = \Lambda_1$.
			\end{enumerate}
		\end{lem}

		\begin{proofs}[Proof of Lemma]
			\begin{enumerate}
				\item[(a)] $\Lambda x = Re(\Lambda x) + i Im(\Lambda x)= \Lambda_r x + i \Lambda_i x$.
					We claim that $\Lambda_r(ix) = - \Lambda_i x, \Lambda_i(ix) = \Lambda_r x$.
					Clearly, this implies (a).
					To prove this, 
					\[
						\Lambda(ix) = i \Lambda x
					\]
					\[
						\Rightarrow \Lambda_r(ix) + i \Lambda_i(ix) = -\Lambda_i x + i \Lambda_r x
					\]

				\item[(b)] Define $\Lambda x = \Lambda_1 x - i \Lambda_1 (ix)$.
					Then $Re(\Lambda x = \Lambda_1 x$.
					Need to check $\Lambda \in L(X, \mathbb{C})$. 
					Let $x, y \in X$. 
					\[
						\Lambda(x + y) = \lambda_1(x + y) - i \Lambda_1(i(x + y))
					\]
					\[
						 = \Lambda_1 x - i \Lambda_1(ix) + \Lambda_1 y - i \Lambda_1 (iy) = \Lambda x + \Lambda y
					 \]
					Also, let $a, b \in \mathbb{R}$.
					\[
						\Lambda((a + bi) x) = \Lambda_1((a + bi)x) - i \Lambda_1((-b + ai) x)
					\]
					\[
						= \Lambda_1(ax) - i \Lambda_1(iax) + \Lambda_1(ibx) - i \Lambda_1(-bx)
					\]
					\[
						= a \Lambda_1 x - i a \lambda_1(ix) + b \Lambda_1(ix) + ib \Lambda_1 x
					\]
					\[
						= a \Lambda x + ib(\Lambda_1 x - i \Lambda_1 (ix))
					\]
					\[
						= a \Lambda x + ib \Lambda x = (a + bi) \Lambda x
					\]
					So $\Lambda \in L(X, \mathbb{C})$.
					Uniqueness is easy to check.
					
			\end{enumerate}
		\end{proofs}
		Let $\Lambda \in L(Y, \mathbb{C})$ s.t. $Re(\Lambda x) \leq p(x) \sfa x \in Y$.
		$\exists$ a real extension $\Lambda_1$ of $Re(\Lambda)$ s.t. $\Lambda_1 x \leq p(x) \sfa x \in X$.
		By lemma, $\exists \tilde{\Lambda} \in L(X, \mathbb{C})$ s.t. $Re(\tilde{\Lambda}) = \Lambda_1$.
\end{proofs}

\section{Hahn-Banach on normed spaces}

\begin{thm}
	Let $(X, \|\cdot \|)$ be a normed sapce and let $Y \subseteq X$ be a proper subspace. 
	Then any $\Lambda \in Y^*$ admits an extension to some $\tilde{\Lambda} \in X^*$ with $\| \tilde{\Lambda} \| = \|\Lambda \|$.
\end{thm}

\begin{proofs}
	If such an extension exists, then
	\[
		\|\tilde{\Lambda} \| = \sup_{x \in X, x \neq 0} \frac{|\tilde{\Lambda} x|}{\|x\|} \geq \sup_{x \in Y, x \neq 0} \frac{|\tilde{\Lambda} x|}{\|x\|} = \|\Lambda\|
	\]
	It suffices to show $\leq$.
	Consider the real case.
	Take $p(x) = \| \Lambda \| \| x \|$.
	$|\Lambda x| \leq \| \Lambda \| \| x \| \sfa x \in Y = p(x) $.
	By Hahn-Banach, $\exists \tilde{\Lambda} \in L(X, \mathbb{R})$ s.t.
	\[
		\tilde{\Lambda} x \leq p(x) = \| \Lambda \| \|x \| \sfa x \in X 
	\]
	Replace $x$ by $-x$,
	\[
		-\tilde{\Lambda} x \leq \| \Lambda \| \| x \|
	\]
	\[
		\Rightarrow | \tilde{\Lambda} x | \leq \| \Lambda \| \| x \|
	\]
	\[
		\Rightarrow \|\tilde{\Lambda} \| \leq \| \Lambda \|
	\]
	So $\tilde{\Lambda} \in X^*$.
	For the complex case, let $\tilde{\Lambda}$ be an extension of $\Lambda$ s.t.
	\[
		Re(\tilde{\Lambda} x) \leq \| \Lambda \| \|x \| \sfa x \in X
	\]
	For any $x \in X, \exists e^{i \theta}$ s.t.
	\[
		\tilde{\Lambda} x = |\tilde{\Lambda} x| e^{i \theta}
	\]
	Then 
	\[
		|\tilde{\Lambda} x| = e^{-i \theta} \tilde{\Lambda} x = \tilde{\Lambda} (e^{i \theta} x)
	\]
	\[
		= Re(\tilde{\Lambda} (e^{i \theta} x)) \leq \|\Lambda \| \| e^{i \theta} x \| = \| \Lambda \| \|x \|
	\]
	\[
		\Rightarrow \| \tilde{\Lambda} \| \leq  \| \Lambda \|
	\]

\end{proofs}

Consequences:

\begin{prop}
	Let $(X, \|\cdot \|)$ be normed space and let $Y$ be a closed proper subspace of $X$.
	For any $x_0 \in X \setminus Y, \exists \Lambda \in X^*$ s.t. $\| \Lambda \| = 1$.
	\[
		\Lambda x_0 = \dist(x_0, Y), \Lambda y = 0 \sfa y \in Y
	\]
\end{prop}

\begin{proofs}
	Write $d = \dist(x_0, Y)$.
	$d > 0$ because $Y$ is closed and $x_0 \in X \setminus Y$.
	Consider $y' = Y \bigoplus span\{x_0 \}$.
	Define $\Lambda_0$ on $Y'$ by setting 
	\[
		\Lambda_0(y + c x_0) = cd
	\]
	$\Lambda_0$ is linear and vanishes on $Y$.
	\[
		0 < d = \inf_{z \in Y} \|x_0 + z \| \leq \frac{1}{|c|} \|c x_0 + y \| \sfa y \in Y \sfa c \neq 0
	\]
	\[
		\Rightarrow |c| \leq \frac{1}{d} \|c x_0 + y \| \sfa y \in Y , \sfa c \in \mathbb{C}
	\]
	\[
		|\Lambda_0(y + c x_0)| \leq \|c x_0 + y \|
	\]
	\[
		\Rightarrow \|\Lambda_0\| \leq 1
	\]
	$\Lambda_0 \in (Y')^*$.
	\begin{clm}
		$\|\Lambda_0 \| = 1$.
	\end{clm}

	\begin{proofs}
		Pick $y_n \in Y$ s.t. $\|y_n + x_0 \| \to d$.
		Then 
		\[
			d = \Lambda_0 (y_n + x_0) \leq \| \Lambda_0 \| \|y_n + x_0 \| \to d \|\Lambda_0 \|
		\]
		\[
			\| \Lambda_0 \| \geq 1
		\]
	\end{proofs}
	By Hahn-Banach, we obtain $\Lambda \in X^*$ s.t. $\|\Lambda \| = 1$, $\Lambda x_0 = d$, $\Lambda y = 0 \sfa y \in Y$.
\end{proofs}

\begin{cor}
	$\forall x_0 \in X \setminus \{0\}, \exists \Lambda \in X^*$ s.t. $\Lambda x_0 = \|x_0 \|$ and $\|\Lambda\| =1$.
\end{cor}

\begin{proofs}
	Take $Y = \{0\}$.
\end{proofs}
\begin{rem}
	A bounded linear functional with these properties is called a "dual point" of $x_0$.
	Dual points may not be unique.
\end{rem}

\begin{ex}
	$X = \mathbb{R}^2, \|(x, y)\| = |x| + |y|, x_0 = (1, 0)$.
	Check: $\Lambda_1(x, y) = x, \Lambda_2(x, y) = x + y$ are dual points of $x_0$.
\end{ex}

\begin{cor}
	For any $x \in X$, 
	\[
		\|x\| = \sup_{\Lambda \in X^*, \Lambda \neq 0} \frac{|\Lambda x|}{\|\Lambda\|}
	\]
\end{cor}

\begin{proofs}
	Assume $x \neq 0$.
	\[
		|\Lambda x| \leq \| \Lambda \| \|x \|
	\]
	
	\[
		\Rightarrow \|x \| \geq \sup_{\Lambda \in X^*, \Lambda \neq 0} \frac{|\Lambda x|}{\|\Lambda \|}
	\]
	From the previous cor., $\exists \Lambda_0 \in X^*$ s.t. $\Lambda_0 x = \|x\|$ and $\|\Lambda_0\| = 1$.
	\[
		\|x\| = \frac{|\Lambda_0 x|}{\|\Lambda_0\|} \leq \sup_{\Lambda \in X^*, \Lambda \neq 0} \frac{|\Lambda x|}{\|\Lambda\|}
	\]
\end{proofs}

\begin{rem}
	Not only we can recover the norm of a vector from the bounded linear functionals, but the sup can be strengthened to max as it is attained by $\Lambda_0$.
\end{rem}


\section{The dual space of $C^0([a, b])$}


\par Examples: For $x \in [a, b], \Lambda_x f = f(x)$.
Fix $g \in C^0([a, b]), \Lambda_g f = \int_a^b fg$.
Are there any others?
These can be described by the Stieltjes integrals.

\begin{dfn}
	Suppose that $f$ and $\alpha$ are complex-valued function defined on $[a, b]$.
	Suppose that $P, T$ a partition pair of $[a, b]$.
	We define the \textbf{Riemann-Stieltjes sum}
	\[
		R(f, \alpha, P, T) = \sum_{j = 1}^n f(t_j) (\alpha (x_j) - \alpha(x_{j - 1}))
	\]
	We say that $f$ is \textbf{Riemann-Stieltjes integrable} w.r.t. $\alpha$ if the sum converges to a number when $mesh(P) \to 0$.
	Write the integral as $\int_a^b f(x) \mathrm{d} \alpha(x)$ or $\int f \mathrm{d} \alpha$.
	\[
		\mathcal{R}_\alpha([a, b]) = \{\text{R-S integrable functions w.r.t. }\alpha \text{ on } [a, b] \}
	\]
\end{dfn}

\begin{rem}
	You can define Lebesgue-Stieltjes integral, by using the measure $\mu([a, b]) = \alpha (b) - \alpha(a)$.
	Since we are working on $C^0([a, b])$, doesn't matter if it is Lebesgue or Riemann.
\end{rem}

Easy to verify: 
\begin{itemize}
	\item R-S integral is linear in both $f$ and $\alpha$.
		
	\item Every $f \in C^0([a, b])$ is R-S integrable w.r.t a bounded variation function $\alpha$ on $[a, b]$.
		Also
		\[
			\left|\int_a^b f \mathrm{d} \alpha \right| \leq T_\alpha(a, b) \cdot \|f \|_{\infty}
		\]
\end{itemize}

Evaluation function is a R-S integral:\\
Fix $c \in (a, b)$.
Take $\alpha = \chi_{[c, b]}$.
When $c \in P, \exists ! i$ s.t. $c \in (x_{i - 1}, x_i)$.
\[
	\sum_{j =1}^n f(t_j)(\alpha(x_j) - \alpha(x_{j - 1})) = f(t_i)
\]
When $mesh(P) \to 0$, this converges to $f(c)$
\[
	\int f \mathrm{d} \chi_{[c, b]} = f(c)
\]
Similarly, 
\[
	\int f \mathrm{d} \chi_{(c, b]} = f(c)
\]
There should be some correspondence between $(C^0([a, b]))^*$ and R-S integrals.
But the example above shows that it is not 1-1.
Restrict to a smaller class:

\begin{dfn}
	Let $BV_0([a, b])$ be set of all functions $\alpha$ of bounded variation s.t. $\alpha(a) = 0$.
	Define 
	\[
		V([a, b]) = \{\alpha \in BV_0([a, b]): \alpha \text{ is right-continuous on }[a, b) \}
	\]
	Norm on $V([a, b])$: \textbf{Total variation}.

\end{dfn}

Here are some facts:
\begin{itemize}
	\item Every $\alpha \in BV_0([a, b])$ is equal to a unique $\tilde{\alpha} \in V([a, b])$ except at possibly countably many points.
		(Recall that any bounded variation function is a difference of two increasing functions, where each of them has at most countable discontinuity points.)

	\item $\int f \mathrm{d} \alpha = \int f \mathrm{d} \tilde{\alpha} \sfa f \in C^0([a, b])$.

	\item If $\int f \mathrm{d} \alpha_1 = \int f \mathrm{d} \alpha_2 \sfa f \in C^0([a, b])$ and $\alpha_1, \alpha_2 \in V([a, b])$, then $\alpha_1 = \alpha_2$.
\end{itemize}

Using these facts, we see the map $\alpha \to \Lambda_\alpha$, where
\[
	\Lambda_\alpha f = \int f \mathrm{d} \alpha
\]
defines a linear injective map $\Phi:V([a, b]) \to (C^0([a, b]))^*$.
Moreover, 
\[
	|\Phi(\alpha) f| = |\Lambda_\alpha f| \leq T_\alpha(a, b) \|f\|
\]
\[
	\Rightarrow \|\Phi(\alpha)\| \leq T_\alpha(a, b) \sfa \alpha \in V([a, b]).
\]
\begin{thm}[Riesz representation theorem, baby version]
	$\exists$ an isometric isomorphism from $(C^0([a, b]))^*$ to $V([a, b])$.
\end{thm}

\begin{rem}
	$\exists$ a much more general version of Riesz representation.
	$X$ is compact Hausdorff space.
	$(C^0(X))^*$ can be identified with a space of nice Borel measures on $X$.
	For $X = [a, b]$, the integrals can also be represented as R-S integrals.
	($(\alpha(x) = \mu([a, b]), \mu([c, d]) = \alpha(d) - \alpha(c)$)
	(See Rudin's "Real and Complex Analysis", Chapter 2.)
\end{rem}

\begin{proofs}
	Let $\Lambda \in (C^0([a, b]))^*$.
	Want: find $\alpha \in V([a, b])$ s.t. 
	\[
		\Lambda f = \int f \mathrm{d} \alpha \sfa f \in C^0([a, b])
	\]
	We can "extract" $\alpha$ by using characteristic functions:
	\[
		\Lambda(\chi_{[a, x]}) = \int_a^b \chi_{[a, x]} \mathrm{d} \alpha = \int_a^x \mathrm{d} \alpha = \alpha(x)
	\]
	Problem: $\chi_{[a, x]}$ is not continuous!
	We use Hahn-Banach to extend $\Lambda$.
	$C^0([a, b]) \subseteq C_b([a, b])$, where $C_b([a, b])$ is the space of all bounded functions on $[a, b]$.
	$\exists$ an extension $\tilde{\Lambda} \in C_b([a, b])^*$ of $\Lambda$ with $\|\tilde{\Lambda}\| = \| \Lambda \|$.
	Define $\alpha(x) = \tilde{\Lambda}(\chi_{[a, x]})$ for $x \in (a, b]$ where $\alpha(a) = 0$.

	\begin{clm}
		$\alpha$ is of bounded variation and $T_\alpha(a, b) \leq \| \Lambda \|$.
	\end{clm}

	\begin{proofs}
		Let $P = \{x_0, ..., x_n\}$ be a partition of $[a, b]$.
		For each $j, \exists \theta_j$ s.t.
		\[
			|\alpha(x_j) - \alpha(x_{j - 1})| = e^{i \theta_j}(\alpha(x_j) - \alpha(x_{j - 1}))
		\]
		\[
			\Rightarrow \sum_{j = 1}^n |\alpha(x_j) - \alpha(x_{j - 1})| = \sum_{j = 1}^n e^{i \theta_j}(\alpha(x_j) - \alpha(x_{j - 1}))
		\]
		\[
			 = e^{i \theta_1} \alpha(x_1) + \sum_{j = 2}^n e^{i \theta_j} (\alpha(x_j) - \alpha(x_{j - 1}))
		 \]
		\[
			= e^{i \theta_1} \tilde{\Lambda}(\chi_{[a, x_1]}) + \sum_{j = 2}^n e^{i \theta_j}(\tilde{\Lambda}(\chi_{[a, x_j]}) - \tilde{\Lambda}(\chi_{[a, x_{j - 1}]}))
		\]
		\[
			= \tilde{\Lambda}(e^{i \theta_1} \chi_{[a, x_1]}) + \sum_{j = 2}^n \tilde{\Lambda}(e^{i \theta_j} \chi_{(x_{j - 1}, x_j]})
		\]
		\[
			= \tilde{\Lambda}(e^{i \theta_1} \chi_{[a, x_1]} + \sum_{j = 2}^n e^{i \theta_j} \chi_{(x_{j - 1}, x_j]})
		\]
		$\forall x \in [a, b], \exists$ a unique interval $[a,x_i]$ of $(x_{j - 1}, x_j]$ that contains $x$.
		So $h(x) = e^{i \theta_{j_0}}$ for some $j_0$.
		$|h(x)| = 1 \sfa x \in [a, b]$.
		$\Rightarrow \|h\|_{\infty} = 1$.
		\[
			\sum_{j = 1}^n |\alpha(x_j) - \alpha(x_{j - 1})| \leq \|\tilde{\Lambda}\|\|h\|_{\infty} = \|\Lambda\|
		\]
		$\Rightarrow T_\alpha(a, b) \leq \|\Lambda\|$.
		$\Rightarrow \alpha$ is of bounded variation.
	\end{proofs}
	Define $\Psi:(C^0([a, b]))^* \to V([a, b])$ by $\Psi(\Lambda) = \tilde{\alpha}$, where $\tilde{\alpha}$ is the right-continuous modification of $\alpha$ with $\tilde{\alpha(a)} = 0$.
	Then $T_{\tilde{\alpha}}(a, b) = T_\alpha(a, b) \leq \|\Lambda \|$.( The "=" is quite subtle, need to check)
	$\Rightarrow T_{\Psi(\Lambda)}(a, b) \leq \|\Lambda\| \sfa \Lambda \in (C^0([a, b]))^*$.
	\begin{clm}
		$\Lambda f = \Lambda_{\tilde{\alpha}} f := \int f \mathrm{d} \tilde{\alpha} \sfa f \in C^0([a, b])$.
	\end{clm}
	If Claim holds, recalling that we defined 
	\[
		\Phi(\alpha) = \Lambda_\alpha = \int \cdot \mathrm{d} \alpha
	\]
	then
	\[
		\Phi(\Psi(\Lambda)) = \Phi(\tilde{\alpha}) = \Lambda_{\tilde{\alpha}} = \Lambda
	\]
	$\Phi$ is surjective.
	Moreover, $T_\alpha(a, b) \leq \|\Phi(\alpha)\| \leq T_\alpha(a, b)$.
	$\Rightarrow \Phi$ is an isometry.
	$\Psi$ is an isometric linear isomorphism.

	\begin{proofs}[Proof of Claim]
		Let $\epsilon > 0$, and let $f \in C^0([a, b])$.
		$f$ is R-S integrable w.r.t. $\alpha, \exists \delta_1 > 0$ s.t.
		\[
			\left|\int f \mathrm{d} \alpha - \sum_{j = 1}^n f(t_j)(\alpha(x_j) - \alpha(x_{j - 1}))\right| < \epsilon
		\]
		whenever $\text{mesh}(P) < \delta_1$.
		Similarly to above, we can write
		\[
			\sum_{j = 1}^n f(t_j)(\alpha(x_j) - \alpha(x_{j - 1})) = \tilde{\Lambda}\left(f(t_1) \chi_{[a, x_j]} + \sum_{j = 2}^n f(t_j) \chi_{(x_j, x_{j - 1}]}\right) = \tilde{\Lambda} \tilde{f}
		\]
		\[
			\Rightarrow \left|\int f \mathrm{d} \alpha - \tilde{\Lambda}(\tilde{f})\right| < \epsilon ... (*)
		\]
		On the other hand, $f$ is uniformly continuous on $[a ,b]$.
		$\exists \delta_2 > 0$ s.t.
		\[
			|f(x) - f(y) | < \epsilon \sfa x, y \in [a, b] \text{ with }|x - y| < \delta_2
		\]
		Take $\delta = \min\{\delta_1, \delta_2\}$.
		Let $P$ be a partition s.t. $\text{mesh}(P) < \delta$.
		Then
		\[
			f(x) - \tilde{f}(x) =  f(x) \left(\chi_{[a, x_1]}(x) + \sum_{j = 2}^n \chi_{(x_{j - 1}, x_j]}(x)\right) - \tilde{f}(x)
		\]
		\[
			= (f(x) - f(t_1)) \chi_{[a, x_1]}(x) + \sum_{j = 2}^n(f(x) - f(t_j)) \chi_{(x_{j - 1}, x_j]}(x)
		\]
		So $\exists j_0$ s.t.
		\[
			|f(x) - \tilde{f}(x)| = |f(x) - f(t_{j_0})|
		\]
		\[
			\Rightarrow \|f - \tilde{f}\|_{\infty} < \epsilon
		\]
		\[
			|\tilde{\Lambda} f - \tilde{\Lambda}\tilde{f}| \leq \|\tilde{\Lambda}\|\|f - \tilde{f}\|_{\infty} < \epsilon \|\Lambda\|
		\]
		\[
			\left|\int f \mathrm{d} \alpha - \tilde{\Lambda} f\right| \leq \left|\int f \mathrm{d} \alpha - \tilde{\Lambda}(\tilde{f})\right| + |\tilde{\Lambda}(\tilde{f}) - \tilde{\Lambda} f|
		\]
		Taking $\epsilon \to 0$, 
		\[
			\Lambda_{\tilde{\alpha}} f = \Lambda_\alpha f = \int f \mathrm{d} \alpha = \Lambda f
		\]
		This proves the claim.
	\end{proofs}
\end{proofs}

\section*{Reflexive Spaces}

If $X$ is normed space then so is $X^*$.
We can consider $X^{**}$.
$1 < p < \infty, (\ell^p)^{**} \simeq \ell^p$.
$(c_0)^{**} \simeq (\ell^1)^* \simeq \ell^\infty$.
It turns out that any vector in $X$ can be viewed as a vector in $X^{**}$.

\begin{prop}
	For each $x\in X$, we define a function $\tilde{x}$ on $X^*$.
	(that is, $\tilde{x} \in L(X^*, \mathbb{C})$) by 
	\[
		\tilde{x}(\Lambda) = \Lambda x \sfa \Lambda \in X^*
	\]
	Then $\tilde{x} \in X^{**}, \|\tilde{x}\| = \|x\|$.
	The mapping $J:x \mapsto \tilde{x}$ is an isometric linear map from $X$ to $X^{**}$, called the canonical identification.
\end{prop}

\begin{proofs}
	Clearly $J$ is linear.
	\[
		|\tilde{x}(\Lambda)| = |\Lambda x | \leq \|x\| \|\Lambda\|
	\]
	\[
		\Rightarrow \tilde{x} \in X^{**} \text{ and }\|\tilde{x}\| \leq \|x\|
	\]
	If $x = 0$, the equality holds.
	If $x \neq 0$, by Hahn-Banach, $\exists \Lambda_0 \in X^*$ s.t. $\Lambda_0 x = \|x\|$ and $\|\Lambda_0\| = 1$.
	\[
		\Rightarrow \|x\| = \Lambda_0 x = \tilde{x}(\Lambda_0) \leq \|\tilde{x}\|\|\Lambda_0\| = \|\tilde{x}\|
	\]
	So $J$ is an isometry.
\end{proofs}

\begin{dfn}
	A normed space is called \textbf{reflexive} if $J$ is an isometric linear isomorphism.
\end{dfn}

\begin{rem}
	\begin{itemize}
		\item To show a normed space is reflexive we only need to show that $J$ is surjective.

		\item Reflexive $\Rightarrow X \simeq X^{**}$.
			
		\item $"\Leftarrow"$ is  not true in general.
			$\exists$ a nonreflexive Banach space $X$ s.t. $\exists$ an isometric linear isomorphism from $X$ to $X^{**}$.(Of course cannot be $J$.)
	\end{itemize}
\end{rem}

\begin{prop}
	Let $1 < p < \infty$.
	Then $\ell^p$ is reflexive.
\end{prop}

\begin{proofs}
	Recall: For each $\Lambda \in (\ell^p)^*, \exists !y^{\Lambda} \in \ell^q$ s.t.
	\[
		\Lambda x = \sum_{j = 1}^\infty y_j^{\Lambda} x_j \sfa x \in \ell^p
	\]
	Let $\sigma \in (\ell^p)^{**}$.
	Want to find $z \in \ell^p$ s.t. $\tilde{z} = \sigma$.
	Define 
	\[
		\sigma_1 y^{\Lambda} := \sigma \Lambda
	\]
	where $\sigma_1 \in (\ell^q)^*$.
	$\sigma_1$ is bounded.
	Since $(\ell^q)^* \simeq \ell^p, \exists z \in \ell^p$ s.t.
	\[
		\sigma_1 y^{\Lambda} = \sum_{j =1}^\infty y_j^{\Lambda} z_j \sfa y^{\Lambda} \in \ell^q
	\]
	In other words,
	\[
		\sigma \Lambda = \sum_{j = 1}^\infty y_j^{\Lambda} z_j
	\]
	The canonical identification of $z$ is given by 
	\[
		\tilde{z}(\Lambda) = \Lambda z = \sum_{j = 1}^\infty y_j^{\Lambda} z_j
	\]
	$\Rightarrow \tilde{z} = \sigma$
	$\Rightarrow \ell^p$ is reflexive.
\end{proofs}

Similarly, $L^p$ is reflexive for $1< p < \infty$.
$p = 1$?
General Banach spaces?

\begin{prop}
	A reflexive space is a Banach space.
\end{prop}

\begin{proof}
	$X \simeq X^{**}$, which is complete.
\end{proof}

In particular, $(C^0([a, b]), \|\cdot\|_{L^p})$ is not reflexive for $1 \leq p < \infty$.

\begin{prop}
	If $X^*$ is separable, then $X$ is also separable.
\end{prop}

\begin{proofs}
	Since $X^*$ is separable, 
	\[
		\{\Lambda \in X^*: \|\Lambda\| = 1\} \text{ is also separable.}
	\]
	Pick a countable dense subset $\{\Lambda_1, \Lambda_2, ...\}$.
	For each $k, \exists x_k$ with $\|x_k\| = 1$ s.t. $|\Lambda_k x_k| \geq \frac{1}{2}$.
	Let 
	\[
		E = \text{span} \{x_1, ...\}
	\]
	Then $E$ is separable.
	\begin{clm}
		$E = X$.
	\end{clm}

	\begin{proofs}
		Suppose not. 
		Pick $x_0 \in X \setminus E$.
		By Hahn-Banach, $\exists \Lambda_0 \in X^*$ s.t. $\Lambda_0 = 0$ on $E$, $\|\Lambda_0\| = 1$.
		Since $\{\Lambda_1, \Lambda_2, ...\}$ are dense, $\exists k_0$ s.t.
		\[
			\|\Lambda_0 - \Lambda_{k_0}\| < \frac{1}{4}
		\]
		Then 
		\[
			\frac{1}{2} \leq |\Lambda_{k_0} x_{k_0}| = | (\Lambda_{k_0} - \Lambda_0) x_{k_0}| \leq \|\Lambda_{k_0} - \Lambda_0\|\|x_{k_0}\| < \frac{1}{4}
		\]
		A contradiction.
	\end{proofs}
\end{proofs}

$\ell^1$ is not reflexive.
If it was, then $(\ell^1)^{**} = (\ell^\infty)^* \simeq \ell^1$.
$\ell^1$ separable $\Rightarrow (\ell^\infty)^*$ is separable $\Rightarrow \ell^\infty$ separable, a contradiction.

\section*{Bounded linear operators}

Let $X, Y$ be normed spaces over $\mathbb{C}$.
A linear operator $T:X \to Y$ is bounded if it maps a bounded set in $X$ to a bounded set in $Y$.
Check: A linear operator is bounded $\Leftrightarrow$ it is continuous.
\[
	\mathcal{B}(X, Y) = \{\text{bounded linear operators from }X \text{ to }Y \}
\]
$X^* = \mathcal{B}(X, \mathbb{C})$
If $X = Y$, we write $\mathcal{B}(X) = \mathcal{B}(X, X)$.
We can also define a norm on $\mathcal{B}(X, Y)$:
For $T \in \mathcal{B}(X, Y)$, define its operator norm by 
\[
	\|T\| = \sup_{x \neq 0} \frac{\|T x \|_Y}{\|x\|_X} = \sup_{\|x\|_X = 1} \|Tx\|_Y = \sup_{\|x\|_X \leq 1} \|Tx\|_Y
\]
Check: 
\begin{itemize}
	\item $\|\cdot\|$ is a norm.

	\item If $T \in \mathcal{B}(X, Y), S \in \mathcal{B}(Y, Z)$ then $ST \in \mathcal{B}(X, Z)$ and $\|ST\| \leq \|S\|\|T\|$.

\end{itemize}

When $X = Y = Z$, there is a multiplicative structure on $\mathcal{B}(X)$.
$\mathcal{B}(X)$ is an algebra.

\begin{prop}
	Let $T \in \mathcal{B}(X, Y)$. 
	Suppose that $\exists M > 0$ s.t.
	\begin{enumerate}
		\item[(a)] $\|Tx\| \leq M \|x\| \sfa x \in D$, where $D$ is dense in $X$.

		\item[(b)] $\exists$ a nonzero sequence $(x_n)$ in $D$ s.t.
			\[
				\frac{\|T x_k\|}{\|x_k\|} \to M
			\]
			Then $M = \|T\|$.
	\end{enumerate}
\end{prop}

\begin{proofs}
	Clearly(?), $\|T\| \leq M$.
	\[
		M = \lim_{k \to \infty}\frac{\|T x_k\|}{\|x_k\|} \leq \sup_{x \neq 0}\frac{\|Tx\|}{\|x\|} = \|T\|
	\]
\end{proofs}

In linear algebra, we want to solve nonhomogeneous system.
\[
	Ax = b
\]
where $A$ is a $m \times n$ matrix and $b \in \mathbb{R}^m$.
The Fredholm alternative states that either this system is unique solvable, or the homogeneous system
\[
	A^{\dagger} y = 0
\]
has a nonzero solution $y$.
Moreover, the nonhomogeneous system is solvable $\Leftrightarrow b \perp y \sfa$ solutions $y$ of the homogeneous system. 
Question: What happens in infinite dimensional spaces?

\begin{dfn}
	Let $T \in \mathcal{B}(X, Y)$.
	We define the \textbf{transpose} $T^t: Y^* \to X^*$ by 
	\[
		T^t y^*(x) = y^*(Tx) \sfa y^* \in Y^*, \sfa x \in X
	\]
\end{dfn}

Some people write 
\[
	\langle x^*, x\rangle := x^*(x), x^* \in X^*, x \in X
\]
\[
	\langle T^t y^*, x \rangle = \langle y^*, Tx \rangle
\]
Exercises:
\begin{enumerate}
	\item[(a)] $T^t \in \mathcal{B}(Y^*, X^*)$. Furthermore, $\|T^t\| = \|T\|$
		
	\item[(b)] $T \mapsto T^t$ is linear from $\mathcal{B}(X, Y)$ to $\mathcal{B}(Y^*, X^*)$
		
	\item[(c)] If $S \in \mathcal{B}(Y, Z)$, then $(ST)^t = T^t S^t$
\end{enumerate}

This transpose extends the one in finite dimensions.
Let $T:\mathbb{C}^n \to \mathbb{C}^m$ be linear, and let $\{e_j\}, \{f_j\}$ be the canonical basis for $\mathbb{C}^n, \mathbb{C}^m$, respectively.
If $x \in \sum_j \alpha_j e_j$, then $\exists a_{kj}$ s.t. $T x = \sum_{k, j} a_{kj} \alpha_j f_k$.
$T$ is represented by the matrix $(a_{kj})$.
Can also represent $T^t$ as a matrix by using the dual canonical bases $\{f_j^*\}$ and $\{e_j^*\}$.
For $y^* = \sum_{j} \beta_j f_j^*, T^t y^* = \sum b_{lj} \beta_j e_l^*$.
\[
	T^t f_k^*(e_j) = \sum_{l} b_{lk} e_l^*(e_j) = b_{jk}
\]
\[
	T e_j = \sum_l a_{lj} f_l
\]
\[
	f_k^*(T e_j) = a_{kj}
\]
\[
	\Rightarrow a_{kj} = b_{jk}
\]

\begin{dfn}
	$T \in \mathcal{B}(X, Y)$, the \textbf{range} $R(T) = T(X)$, the \textbf{null space} $N(T) = \{x \in X: T x= 0\}$.
\end{dfn}

\begin{dfn}
	For $Y \subseteq X$, we define its \textbf{annihilator} to be 
	\[
		Y^{\perp} = \{x^* \in X^*: x^*(y) = 0 \sfa y \in Y\}
	\]
	For a subspace $G$ of $X^*$, its annihilator is 
	\[
		^\perp G = \{x \in X: x^*(x) = 0 \sfa x^* \in G\}
	\]
\end{dfn}

Check: 
\begin{itemize}
	\item The annihilators in both cases are closed subspaces.	

	\item $Y \subseteq ^\perp (Y^\perp), G \subseteq (^\perp G)^\perp$.
\end{itemize}

\begin{lem}
	Let $X$ be a normed space, and let $Y$ be a closed subspace of $X$.
	Then $Y = ^\perp(Y^\perp)$.
	If $X$ is reflexive and $G$ is a closed subspace of $X^*$, then $G = (^\perp G)^\perp$.
\end{lem}

\begin{proofs}
	It suffices to show $^\perp(Y^\perp) \subseteq Y$.
	Let $x \in ^\perp(Y^\perp)$.
	Then $\Lambda x = 0 \sfa \Lambda \in Y^\perp$.
	Such a $\Lambda$ has to vanish on $Y$.
	If $x \notin Y$, then $\exists \Lambda \in Y^\perp$ s.t. $\Lambda x = \text{dist}(x, Y) \neq 0$.
	So $x \in Y$.
	For the other equality, let $\Lambda \in (^\perp G)^\perp$.
	Then $\Lambda x = 0 \sfa x \in ^\perp G$.
	If $\Lambda \notin G$, then $\exists x \in X \simeq X^{**}$ s.t. 
	\[
		\Lambda x = \text{dist} (\Lambda, G) \neq 0 \text{ and } x \in ^\perp G
	\]
	Impossible.
	So $\Lambda \in G$.
\end{proofs}

\begin{prop}
	Let $X, Y$ be normed spaces and $T \in \mathcal{B}(X, Y)$.
	Then 
	\[
		N(T^t) = \overline{R(T)}^\perp
	\]
	\[
		N(T) = ^\perp \overline{R(T^t)}
	\]
	\[
		^\perp N(T^t) = \overline{R(T)}
	\]
	\[
		N(T)^\perp = (^\perp \overline{R(T^t)})^\perp
	\]
\end{prop}

\begin{proofs}
	The $3^{\text{rd}}$ and $4^{\text{th}}$ follows from the first 2 by Lemma.
	We will only show $N(T^t) = \overline{R(T)}^\perp$.
	Let $y^* \in N(T^t)$.
	By definition, $T^t y^* = 0$
	$\Rightarrow y^*(T x) = T^t y^*(x) = 0 \sfa x \in X$.
	$y^*$ vanishes on $R(T)$.
	By continuity, $y^*$ vanishes on $\overline{R(T)}$.
	So $y^* \in \overline{R(T)}^\perp$.
	Reverse the reasoning gives $\supseteq$.
\end{proofs}

\begin{cor}
	Let $X, Y$ be normed and $T \in \mathcal{B}(X, Y)$.
	Then $R(T)$ is dense in $Y \Leftrightarrow T^t$ is injective.
\end{cor}

\begin{proofs}
	$T^t$ injective $\Leftrightarrow N(T^t) = \{0\} \Leftrightarrow \overline{R(T)}^\perp = \{0\} \Leftrightarrow \overline{R(T)} = Y$.
\end{proofs}

\section*{Examples of linear operators}

Let $x = (x_n)$ be a sequence.
If $T$ is a linear operator that maps sequences to sequences, we can write $T x = y = (y_n)$.
Each $y_n$ depends linearly on $x$.
Formally, we can write 
\[
	y_n = \sum_{j = 1}^\infty c_{jn} x_j
\]
Depending on which sequence space and the growth of $c_{jn}, T$ defines a bounded linear operator or an unbounded one.

\begin{ex}
	Two examples.
	\begin{enumerate}
		\item[(a)] Let $(a_n)$ be a sequence s.t. $\lim_{n \to \infty} a_n = 0, a_n \neq 0 \sfa n$.
			Define $T: \ell^p \to \ell^p$ by 
			\[
				T x= (a_1 x_1, a_2x_2,...).
			\]
			\[
				\|T x\|_p \leq \|a\|_\infty \|x\|_p
			\]
			so $T$ is bounded.
			How about $T^{-1}$?
	\end{enumerate}
\end{ex}

\begin{dfn}
	We say that $T \in \mathcal{B}(X, Y)$ is \textbf{invertible} if it is bijective and $T^{-1} \in \mathcal{B}(Y, X)$.
\end{dfn}

The $T$ above is not invertible.
Why? 
If $T^{-1}$ exists, then $T^{-1} e_j = a_j^{-1} e_j \sfa j$.
If $T^{-1} \in \mathcal{B}(\ell^p)$, then
\[
	\|a_j^{-1} e_j \|_p = |a_j|^{-1} \leq \|T^{-1}\|
\]
$\Rightarrow (|a_j|^{-1})$ is bounded, impossible.

\setcounter{ex}{0}
\begin{ex}
	\begin{enumerate}
		\item[(b)] Right shift operator $S_R : \ell^p \to \ell^p$
			\[
				S_R(x_1, x_2, x_3, ...) = (0, x_1, x_2, x_3, ...)
			\]
			Check $S_R \in \mathcal{B}(\ell^p), \|S_R\| = 1$.
			$S_R$ is not onto, so $S_R$ is not invertible.
	\end{enumerate}
\end{ex}

\section*{Integral operators}

Consider 1-dimensional case for simplicity.
Fix $K \in C^0([a, b] \times [a, b])$ (can be relaxed)
$K$ is usually called the integral kernel.
Define 
\[
	T f(x) = \int_a^b K(x, y) f(y) \mathrm{d} y \sfa f \in C^0([a, b])
\]
$T$ is linear and bounded on $C^0([a, b])$.
\[
	|T f(x)| \leq \int_a^b |K(x, y)||f(y) \mathrm{d} y \leq \|f\|_\infty \int_a^b |K(x, y)| \mathrm{d} y
\]
\[
	\leq (\sup_x \int_a^b |K(x, y)| \mathrm{d} y) \|f\|_\infty
\]

\[
	\Rightarrow \|T f \|_\infty \leq M \|f\|_\infty \Rightarrow \|T\| \leq M
\]
(with more effort, can show $\|T\| = M$.)
Can define integral operators on other spaces, e.g. $L^p$-spaces.
For $1 \leq p < \infty$, 
\[
	\|T f\|_{L^p}^p = \int_a^b \left|\int_a^b K(x, y) f(y) \mathrm{d} y\right|^p \mathrm{d} x
\]
\[
	\leq (b- a) \|K\|_\infty^p\left(\int_a^b |f(y)| \mathrm{d} y \right)^p
\]
by Holder's inequality.
\[
	\leq (b - a) \|K\|_\infty^p \left( \|f\|_{L^p} (b - a)^{\frac{1}{q}} \right)^p
\]
\[
	= (b - a)^{1 + \frac{p}{q}} \|K\|_\infty^p \|f\|_{L^p}^p = (b - a)^p \|K\|_\infty^p \|f\|_{L^p}^p
\]
$\Rightarrow T \in \mathcal{B}(L^p([a, b]))$.

\section*{Differential operator}

$X = C^1([0, 1])$ with sup norm
$X$ is a subspace of $C^0([0, 1])$, but $X$ is not a Banach space.
$\dv{x}: X \to C^0([0, 1])$ is linear but unbounded. (e.g. $f_k(x) = \sin(kx)$)

\section*{Uniform boundedness principle/Banach-Steinhaus theorem}

\begin{thm}
	Let $\mathcal{F}$ be a family of bounded linear operators from a Banach space $X$ to a normed space $Y$.
	Suppose that $\mathcal{F}$ is bounded pointwise:
	\[
		\forall x \in X, \exists \text{ a constant } C_x \text{ s.t. }\|T x\| \leq C_x \sfa T \in \mathcal{F}
	\]
	Then $\exists M > 0$ s.t. $\|T\| \leq M \sfa T \in \mathcal{F}$.
\end{thm}

\begin{lem}
	Let $T:X \to Y$ be linear, where $X, Y$ are normed.
	Fix $x_0 \in X$. Suppose that $\exists c, \rho > 0$ s.t. $\forall x \in B(x_0, \rho), \|T x\| \leq c$.
	Then $\|T\| \leq \frac{2c}{\rho}$
\end{lem}

\begin{proofs}
	By linearity, $B(0, \rho) = B(x_0, \rho) - x_0$.
	If $v \in B(0, \rho)$, then $v + x_0 \in B(x_0, \rho)$.
	\[
		\|T v \| \leq \|T(v + x_0)\| + \|T x_0 \| \leq 2c
	\]
	\[
		\Rightarrow \|T\| \leq \frac{2c}{\rho}
	\]
\end{proofs}

\begin{proofs}[Proof of UBP]
	Recall: $M$ complete metric space.
	If $M$ is a countable union of closed sets, then at least one of them has nonempty interior.
	Let $E_k = \{x \in X: \|T x \| \leq k \sfa T \in \mathcal{F}\}$.
	Then $X = \bigcup_{k = 1}^\infty E_k$.
	Each $E_k$ is closed.
	$X$ is complete.
	At least one of the $E_k$'s has nonempty interior.
	By the Lemma, $\exists M > 0$ s.t. $\|T \| \leq M \sfa T \in \mathcal{F}$.
\end{proofs}

The uniform boundedness principle may not hold if the completeness assumption of $X$ is removed.
\par Alternative formulation:

\begin{dfn}
	A vector $x_0$ is called a \textbf{resonance point} for a family $\mathcal{F}$ of bounded linear operators if $\sup_{T \in \mathcal{F}} \|T x_0\| = \infty$.
\end{dfn}

\begin{thm}
	Let $\mathcal{F}$ be a family of bounded linear operators from $X$ to $Y$, where $X$ is Banach and $Y$ is normed.
	Suppose that $\sup_{T \in \mathcal{F}} \|T\| = \infty$.
	Then the resonance points for $\mathcal{F}$ are dense in $X$.
\end{thm}

\begin{proofs}
	Suppose not.
	$\exists$ a ball $\overline{B(x_0, \rho)}$ on which $\mathcal{F}$ is bounded pointwise.
	$\forall x \in \overline{B(x_0, \rho)}, \|T x\| \leq C x \sfa T \in \mathcal{F}$.
	Pick $0 \neq x \in X$.
	Then 
	\[
		z := \frac{\rho x}{\|x\|} + x_0 \in \overline{B(x_0, \rho)}
	\]
	\[
		\Rightarrow \|T z \| = \left\|T\left(\frac{\rho x}{\|x\|} + x_0 \right) \right\|
	\]
	\[
		\Rightarrow \|T x\| \leq \frac{C z+ \|T x_0\|}{\rho} \|x\| \sfa T \in \mathcal{F}
	\]
	$\Rightarrow \mathcal{F}$ is bounded pointwise on $X$.
	By uniform boundedness principle, $\exists M > 0$ s.t. $\|T\| \leq M \sfa T \in \mathcal{F}$. Impossible!
\end{proofs}

\section*{Interlude: Fourier series}

Let $f \in L_{\text{loc}}^1( \mathbb{R})$ of period $2 \pi$.
We would like to express $f$ as a series of sines and cosines.
\[
	f(x) \sim \frac{a_0}{2} + \sum_{n = 1}^\infty (a_n \cos nx + b_n \sin nx)
\]
In the complex form, 
\[
	f(x) \sim \sum_{n =- \infty}^\infty c_n e^{inx}
\]
Question: What should $c_n$ be if we want
\[
	f(x) = \sum_{n = -\infty}^\infty c_n e^{inx}?
\]
Forget about the convergence issue at this point.
Fact: 
\[
	\frac{1}{2 \pi} \int_{- \pi}^\pi e^{ikx} \mathrm{d} x = 
	\begin{cases}
		1 \text{ if } k = 0\\
		0 \text{ if } k \neq 0
	\end{cases}
\]
If $f(x) = \sum_{n = -\infty}^\infty c_n e^{inx}$, then
\[
	\frac{1}{2 \pi}\int_{- \pi}^\pi f(x) e^{-ikx} \mathrm{d} x "=" \sum_{n = -\infty}^\infty c_n \frac{1}{2 \pi} \int_{- \pi}^\pi e^{inx} \cdot e^{-ikx} \mathrm{d} x = c_k.
\]
We (expectedly) call the left hand side $\hat{f}(k)$, the $k$-th Fourier coefficient of $f$.
\[
	f(x) \sim \sum_{n = -\infty}^\infty \hat{f}(x) e^{-inx}
\]
When does the Fourier series converge?
If yes, is it equal to $f$?

In fact we don't have pointwise convergence if $f$ is justs piecewise continuous.
Consider 
\[
	f(x) = 
	\begin{cases}
		1 \text{ if } 0 \leq x \leq \pi\\
		0 \text{ if } - \pi < x < 0
	\end{cases}
\]
Extend it periodically on $\mathbb{R}$.
\[
	\hat{f}(n) = \frac{1}{2 \pi} \int_0^\pi e^{-inx} \mathrm{d} x = 
	\begin{cases}
		\frac{1 - e^{-in \pi}}{2 \pi i n} & \text{ if } n \neq 0\\
		\frac{1}{2} & \text{ if } n = 0\\
	\end{cases}
\]
\[
	= 
	\begin{cases}
		\frac{1}{i \pi n} & \text{ if } n \text{ is odd}\\
		\frac{1}{2} & \text{ if } n = 0\\
		0 & \text{ if } n \text{ is even, } n \neq 0
	\end{cases}
\]
The Fourier series of $f$ becomes
\[
	\frac{1}{2} + \sum_{n \text{ odd}} \frac{2}{n \pi} \sin nx
\]
$f(0) = 0$, but the Fourier series is $1/2$ at $x = 0$.
How about continuous $f$?
Define the partial sum
\[
	S_N(f)(x) = \sum_{n = -N}^N \hat{f}(n) e^{inx}
\]
Consider the $N^{\text{th}}$-\textbf{Dirichlet kernel}
\[
	D_N(x) = \sum_{n = -N}^N e^{inx}
\]
Check:
\[
	D_N(x) = \frac{\sin \left(\left(N + \frac{1}{2} \right) x \right)}{\sin \left( \frac{x}{2} \right)}  (D_N(0) = 2N + 1)
\]
and
\[
	\frac{1}{2 \pi} \int_{-\pi}^\pi D_N(x) \mathrm{d} x = 1
\]
\[
	S_N(f)(x) = \sum_{n = -N}^N \hat{f}(n) e^{inx}
\]
\[
	= \sum_{n = -N}^N \left( \frac{1}{2 \pi} \int_{-\pi}^\pi f(y) e^{-iny} \mathrm{d} y \right) e^{inx}
\]
\[
	= \frac{1}{2 \pi} \int_{- \pi}^\pi f(y) \left( \sum_{n = -N}^N e^{in (x - y)} \right) \mathrm{d} y
\]
\[
	= f * D_N(x)
\]
where 
\[
	(f*g)(x) = \frac{1}{2 \pi} \int_{- \pi}^\pi f(x - y) g(y) \mathrm{d}y
\]
So
\[
	S_N(f)(x) = \frac{1}{2 \pi} \int_{- \pi}^\pi \frac{\sin \left( \left(N + \frac{1}{2} \right) \left( x - y \right) \right)}{\sin \left(\frac{x - y}{2} \right)} f(y) \mathrm{d} y
\]
\[
	= \frac{1}{2 \pi} \int_{- \pi}^\pi \frac{\sin \left( \left( N + \frac{1}{2} \right) y \right)}{\sin \left( \frac{y}{2} \right)} f(x - y) \mathrm{d} y
\]

\begin{prop}
	If $f$ is $2 \pi$ periodic and H\"older/Lipschitz continuous then $S_N(f) \to f$ pointwise.
\end{prop}

\begin{proofs}
	Let $\alpha \in (0, 1]$ and $c > 0$ such that
	\[
		|f(x + h) - f(x)| \leq c |h|^\alpha \sfa x, h \in \mathbb{R}
	\]
	\[
		S_N(f)(x) - f(x) = \frac{1}{2 \pi} \int_{- \pi}^\pi \left(f(x - y) - f(x)\right) D_N(y) \mathrm{d} y = \frac{1}{2 \pi} \int_{- \pi}^\pi g(y) \sin \left( \left(N + \frac{1}{2} \right) y \right) \mathrm{d} y
	\]
	where $g(y) \in L^1([-\pi, \pi])$.
	For $y \in [-\pi, \pi]$, 
	\[
		\left|\frac{f(x - y) - f(x)}{\sin \left( \frac{y}{2} \right) } \right| \leq c'|y|^{-1 + \alpha}
	\]
	where $c'|y|^{-1 + \alpha}$ is Lebesgue integrable.\\
	Recall that if $g$ is integrable then $\hat{g}(N) \to 0$ as $|N| \to \infty$.(Riemann-Lebesgue lemma.)
	Similarly, can show
	\[
		\int_{-\pi}^\pi g(x) \sin \left( \left( N + \frac{1}{2} \right) x \right) \mathrm{d} y \to 0 \text{ as } N \to \infty
	\]
	So 
	\[
		S_N(f)(x) - f(x) \to 0 \sfa x \in \mathbb{R}, \text{ as } N \to \infty
	\]
\end{proofs}

What if $f$ is merely continuous?
\par Fact: Can construct an explicit example of continuous $f$ such that its Fourier series diverges at one point.
(Stein-Shakarchi: Fourier analysis, Ch3, Section 2.2)
We will give aa soft (non-constructive) proof of a stronger result.
A periodic function can be viewed as a function on $\mathbb{S}^1$.

\begin{thm}
	$\{f \in C^0(\mathbb{S}^1): S_N(f) \text{ diverges at } 0 \}$ is dense in $C^0(\mathbb{S}^1)$.
\end{thm}

\begin{proofs}
	Consider $\Lambda_N f = S_N (f)(0) = \sum_{n = -N}^N \hat{f}(n)$.
	Check: $\Lambda_N \in (C^0(\mathbb{S}^1))^*$.
	Can write 
	\[
		\Lambda_N f = \frac{1}{2 \pi} \int_{- \pi}^\pi D_N(y) f(y) \mathrm{d} y
	\]

	\begin{clm}
		\[
			\|\Lambda_N\| = \int_{- \pi}^\pi |D_N(y)| \mathrm{d} y
		\]
	\end{clm}

	\begin{proofs}
		Will prove something stronger.
		For $G \in C^0([a, b])$, define $\Lambda f = \int_a^b f(x) g(x) \mathrm{d} x$.
		Will show $\Lambda \in (C^0([a, b]))^*$, and
		\[
			\| \Lambda \| = \int_a^b |g(x)| \mathrm{d} x
		\]
		By Riesz representation theorem, take 
		\[
			\alpha (x) = \int_a^x g(t) \mathrm{d} t
		\]
		\[
			\Rightarrow \|\Lambda \| = T_\alpha(a, b) = \|g\|_{L^1}
		\]
		(Can prove this directly without Riesz representation theorem.)
	\end{proofs}
	\[
		\|\Lambda_N\| = \frac{1}{2 \pi} \int_{- \pi}^\pi \left| \frac{\sin \left( \left( N + \frac{1}{2} \right) y \right)}{\sin \left( \frac{y}{2} \right)} \right| \mathrm{d} y
	\]
	\[
		= \frac{1}{\pi} \int_0^\pi \left| \frac{\sin \left( \left( N + \frac{1}{2} \right) y \right) } {\sin \left( \frac{y}{2} \right)} \right| \mathrm{d} y
	\]
	\[
		\geq \frac{2}{\pi} \int_0^\pi \frac{\left| \sin \left( \left( N + \frac{1}{2} \right) y \right) \right|}{y} \mathrm{d} y
	\]
	\[
		= \frac{2}{\pi} \int_0^{\left( N + \frac{1}{2} \right) \pi} \frac{|\sin y|}{y} \mathrm{d} y
	\]
	\[
		\geq \frac{2}{\pi} \sum_{j = 1}^N \int_{(j - 1) \pi}^{j \pi} \frac{|\sin y|}{y} \mathrm{d} y
	\]
	\[
		\geq \frac{2}{\pi} \sum_{j = 1}^N \frac{1}{j \pi} \int_{(j - 1) \pi}^j |\sin y| \mathrm{d} y
	\]
	\[
		\frac{4}{\pi^2} \sum_{j = 1}^N \frac{1}{j} \to \infty \text{ as } N \to \infty
	\]
	That is, $\|\Lambda_N \| \to \infty$ as $N \to \infty$.
	So by the alternative formulation of UBP, the resonance points of $(\Lambda_N)$ are dense in $C^0(\mathbb{S}^1)$.
	The resonance points are exactly the functions whose Fourier series diverges at 0.
\end{proofs}

\section{Open Mapping Theorem}

Recall(?): A function $f: X \to Y$, where $X, Y$ are topological spaces, is called an open map if $f(\mathcal{U})$ is open in $Y$ whenever $\mathcal{U}$ is open in $X$.

\begin{ex}
	Every nonzero linear functional on a normed space $X$ is open.
	Let $\Lambda \in L(X, \mathbb{C})$ be nonzero.
	Pick $z_0 \in X$ such that $\Lambda z_0 = 1$.
	Let $\mathcal{U} \subseteq X$ be open.
	Want: $\Lambda \mathcal{U}$ is open.
	Take $\Lambda x_0 \in \Lambda \mathcal{U}$.
	Since $\mathcal{U}$ is open, $\exists r > 0$ such that $B(x_0, r)\subseteq \mathcal{U}$.
	If $s \in \left(-\frac{r}{\|z_0\|}, \frac{r}{\|z_0\|} \right)$, then $x_0 + sz_0 \in B(x_0, r)$.
	\[
		\Rightarrow \Lambda(x_0 + s z_0) = \Lambda x_0 + s \in \Lambda \mathcal{U}
	\]
	\[
		\Rightarrow \left( \Lambda x_0 - \frac{r}{\|z_0\|}, \Lambda x_0 + \frac{r}{\|z_0\|} \right) \subseteq \Lambda \mathcal{U}
	\]
	So $\Lambda \mathcal{U}$ is open.
\end{ex}

\begin{thm}
	Every surjective bounded linear operator from a Banach space to another Banach space is an open map.
\end{thm}

\begin{proofs}
	Let $T \in \mathcal{B}(X, Y)$ be surjective, where $X, Y$ are Banach spaces.
	\par Step 1: $\exists r > 0$ such that $B_Y(0, r) \subseteq \overline{T B_X(0, 1)}$.
	Why? Since $T$ is onto, 
	\[
		Y = \bigcup_{j = 1}^\infty T B_X(0, j) = \bigcup_{j = 1}^\infty \overline{T B_X(0, j)}
	\]
	$Y$ is complete.
	By Baire category theorem, $\exists j_0$ such that $\overline{T B_X(0, j_0)}$ contains a ball $B_Y(y_0, \rho)$.
	$TB_X(0, j_0)$ is dense in $\overline{T B_X(0, j_0)} \Rightarrow B_Y (y_0, \rho) \cap T B_X(0, j_0) \neq \phi$.
	By replacing $B_Y(y_0, \rho)$ by a smaller ball if necessary, we may assume $y_0 = T x_0$ for some $x_0 \in B(0, j_0)$.
	Then 
	\[
		B_Y(y_0, \rho) \subseteq \overline{T B_X(0, j_0)} \stackrel{\Delta-\text{ineq}}{\subseteq} \overline{T B_X(x_0, j_0 + \|x_0\|)}
	\]
	\[
		\stackrel{\text{Translation}, y_0 = T x_0}{\Rightarrow} B_Y(0, \rho) \subseteq \overline{T B_X(0, j_0 + \|x_0\|)}
	\]
	\[
		\Rightarrow B_Y(0, r) \subseteq \overline{T B_X(0, 1)}, \text{ where } r = \frac{\rho}{j_0 + \|x_0\|}
	\]
	\par Step 2: $B_Y(0, r) \subseteq T B_X(0, 3)$.
	Exercise: This implies the theorem.
	It remains to show Step 2.
	Let $y \in B_Y(0, r)$. 
	Want to find $x^* \in B_X(0, 3)$ such that $T x^* = y$.
	By Step 1, for any $n \geq 0$, we have
	\[
		B_Y\left(0, \frac{r}{2^n} \right) \subseteq \overline{T B_X\left(0, \frac{1}{2^n} \right)}
	\]
	$n = 0$: $\exists x_1 \in B_X(0, 1)$ such that $\|y - T x_1\| < \frac{r}{2}$.
	Now, $y - Tx_1 \in B_Y\left( 0, \frac{r}{2} \right)$.\\
	$n = 1$: $\exists x_2 \in B_X\left( 0, \frac{1}{2} \right)$ such that $\|y - T x_1 - T x_2 \| < \frac{r}{2^2}$.
	Inductively, we obtain $(x_n)$ with $x_n \in B_X\left( 0, \frac{1}{2^{n - 1}} \right)$ and $\|y - T x_1 - T x_2 - \cdots - T x_n \| < \frac{r}{2^n}$.
	Set $z_n = \sum_{j = 1}^n x_n$.
	Then $(z_n)$ is Cauchy: for $r_n < n$, 
	\[
		\|z_m - z_n\| \leq \|x_{m + 1}\| + \cdots + \| x_n \| \leq \frac{1}{2^{m-  1}}
	\]
	$X$ is complete $\Rightarrow x^* = \lim_{n \to \infty} z_n$ exists.
	Check: $x^*\in B_X(0, 3)$ and $T x^* = y$.
	\[
		\|z_n\| \leq \sum_{j = 1}^n \|x_j\| \leq 2
	\]
	\[
		\Rightarrow x^* \in \overline{B_X(0, 2)} \subseteq B_X(0, 3)
	\]
	\[
		\|y - T x^*\| \leq \|y - T z_n\| + \|T z_n - T x^*\| < \frac{r}{2^n} + 0 \to 0
	\]
	$y = T x^*$.
\end{proofs}

\begin{cor}[Banach inverse mapping theorem]
	Let $T \in \mathcal{B}(X, Y)$ be a bijection, where $X, Y$ are Banach spaces.
	Then $T$ is invertible.
\end{cor}

\begin{proofs}
	Want: $T^{-1}$ is bounded.
	From the proof of the open mapping theorem, $\exists r > 0$ such that $B_Y(0, r) \subseteq T B_X(0, 3)$.
	\[
		\Rightarrow T^{-1} B_Y(0, r) \subseteq B_X(0, 3)
	\]
	$\Rightarrow T^{-1}$ maps a ball (and hence any ball) in $Y$ to a bounded set in $X$.
	$\Rightarrow T^{-1}$ is bounded.
\end{proofs}

\section{Closed Graph Theorem}

\begin{thm}
	Let $T: X \to Y$ be linear, where $X, Y$ are vector spaces.
	The graph of $T$ is 
	\[
		G(T) = \{ (x, Tx) : x \in X \} \subseteq X \times Y\}
	\]
	Further suppose that $X, Y$ are normed.
	We say that $T$ is closed if $G(T)$ is a cclosed subset of $X \times Y$ under the product topology.
	Equivalently, $T$ is closed if whenever $x_n \to x$ in $X$ and $T x_n \to y$ then $y = T x$.
\end{thm}

$T$ bounded $\Rightarrow T$ closed. 
$T$ closed $\not\Rightarrow T$ bounded.
Differential operator $\dv{x}$ on $C^1([a, b]) \subseteq C^0([a, b])$ with sup norm is closed by unbounded.

\begin{thm}[Closed Graph Theorem]
	Any closed map from a Banach space to another Banach space is bounded.
\end{thm}

\begin{proofs}
	Let $T \in L(X, Y)$ be a closed map.
	Since $X \times Y$ is complete and $G(T)$ is closed in $X \times Y$, $G(T)$ is also a Banach space.
	Define the projection operator $P: G(T) \to X$ by 
	\[
		P(x, T x) = x \sfa x \in X
	\]
	Clearly, $P$ is bijective.
	Also, 
	\[
		\|P(x, Tx)\| = \|x\| \leq \|x\| + \|T x\|
	\]
	$\Rightarrow P \in \mathcal{B}(G(T), X)$.
	By Banach's inverse mapping theorem, $P^{-1}$ is bounded.
	So $\exists , > 0$ such that 
	\[
		\|x\| + \|T x \| = \|(x, T x) \| = \| P^{-1} x\| \leq c \|x\| \sfa x \in X
	\]
	$\Rightarrow T$ is bounded.
\end{proofs}

We showed open mapping theorem $\Rightarrow$ closed graph theorem. 
Can also show closed graph theorem $\Rightarrow$ open mapping theorem.
These two are equivalent.

\section{Spectrum}

Recall: $\mathcal{B}(X) = \mathcal{B}(X, X)$.
If $X$ is a Banach space then $\mathcal{B}(X)$ is a Banach space.
$I$ is the identity map from $X$ to $X$, $I \in \mathcal{B}(X)$.

\begin{dfn}
	$\lambda \in \mathbb{C}$ is called an \textbf{eigenvalue} of $T$ is $\exists$ nonzero $x \in X$ called an \textbf{eigenvector}, such that $T x = \lambda x$.
\end{dfn}	

We will focus on the case that $X$ is a Banach space and $T$ is bounded.
Open mapping theorem $\Rightarrow$
\[
	T - \lambda I \text{ invertible } \Leftrightarrow T - \lambda I \text{ bijective}
\]

\begin{dfn}
	$\lambda \in \mathbb{C}$ is called a \textbf{regular value} for $T$ if $T - \lambda I$ is invertible.
	\[
		\rho(T) = \{ \lambda \in \mathbb{C}: \lambda \text{ is a regular value for } T\}
	\]
	\[
		\sigma(T) = \mathbb{C} \setminus \rho(T)
	\]
	where $\rho(T)$ is called the \textbf{resolvent set} and $\sigma(T)$ the \textbf{spectrum} of $T$.
\end{dfn}

If $\lambda$ is an eigenvalue of $T$ then $\lambda \in \sigma(T)$. 
($T - \lambda I$ is not injective.)
In finite dimensions, $S:X \to X$ injective $\Leftrightarrow S$ is surjective.
NOT TRUE in infinite dimensions.

\begin{ex}
	Let $X = C^0([0, 1])$.
	Consider 
	\[
		T f(x) = x f(x) \sfa x \in [0, 1], f \in C^0([0, 1]).
	\]
	$T \in \mathcal{B}(C^0([0, 1])), \|T\| \leq 1$.
	If $\lambda$ is an eigenvalue of $T$ and $\varphi$ is an eigenvector/eigenfunction, theen
	\[
		x \varphi(x) = \lambda \varphi(x) \sfa x \in [0, 1]
	\]
	\[
		\Rightarrow \varphi = 0
	\]
	$T$ does not have any eigenvalue!
	For $\lambda \in \mathbb{C} \setminus [0, 1]$, the inverse of $T - \lambda I$ is 
	\[
		S f(x) = \frac{f(x)}{x - \lambda}
	\]
	Can check: $S \in \mathcal{B}(C^0([0, 1]))$.
	If $\lambda \in [0, 1]$, then the inverse of $T - \lambda I$ does not exist.
	Conclusion: $T$ has no eigenvalues, but $\sigma(T) = [0, 1], \rho(T) = \mathbb{C} \setminus [0, 1]$.
\end{ex}

What can we say about $\sigma (T)$?

\begin{prop}[Lemma]
	Let $T \in \mathcal{B}(X)$, where $X$ is a Banach space.
	Then $I - T$ is invertible if $\|T\| < 1$.
	(Want to prove that $(I - T)^{-1} = \sum_{k = 0}^\infty T^k$.)
\end{prop}

\begin{proofs}
	By assumption, $\exists r \in (0, 1)$ such that $\|T\| \leq r$.
	\[
		\|T^k\| \leq \|T\|^k \leq r^k
	\]
	$\Rightarrow \sum_k T^k$ converges in $X$ (similar to the Weierstrass M-test).
	\[
		(I - T) \sum_{k = 0}^\infty T^k = \lim_{n \to \infty} \left( (I - T) \sum_{k = 0}^n T^k \right) = \lim_{n \to \infty} (I - T^{n + 1}) = I
	\]
	Similaraly, 
	\[
		\sum_{k = 0}^\infty T^k (I - T) = I
	\]
	So $I - T$ is invertible with inverse $\sum_{k = 0}^\infty T^k$.
\end{proofs}

\begin{cor}
	Suppose that $T \in \mathcal{B}(X)$.
	Then $\sigma(T)$ is compact in $\mathbb{C}$.
	In fact, $|\lambda| \leq \|T\| \sfa \lambda \in \sigma(T)$.
\end{cor}

\begin{proofs}
	Let $\lambda \notin \sigma(T)$ ($\lambda \in \rho(T)$).
	Then $T - \lambda I$ is invertible.
	Want: If $\lambda' \approx \lambda$ then $T - \lambda' I$ is also invertible.
	Let $r = \|(T - \lambda I)^{-1}\|^{-1}$.
	Consider $S \in \mathcal{B}(T - \lambda I, r)$, a ball in $\mathcal{B}(X)$.
	\[
		\|I - (T - \lambda I)^{-1} S\| = \|(T - \lambda I)^{-1}(T - \lambda I - S)\|
	\]
	\[
		\leq \|(T - \lambda I)^{-1}\| \|T - \lambda I - S\| < \frac{1}{r} \cdot r = 1
	\]
	By lemma, $(T - \lambda I)^{-1} S$ is invertible $\Rightarrow S$ is invertible $\Rightarrow \rho(T)$ is open $\Rightarrow \sigma(T)$ is closed.
	If $|\lambda| > \|T\|$, then $I - \lambda^{-1} T$ is invertible.
	($\|T/\lambda\| < 1$ and by lemma.)
	$I - \lambda^{-1}T$ invertible $\Rightarrow \lambda I - T$ is invertible $\Rightarrow \lambda \in \rho(T)$.
	If $\lambda \in \sigma(T)$, then $|\lambda| \leq \|T\|$.
	$\Rightarrow \sigma(T)$ is bounded $\Rightarrow \sigma(T)$ is compact.
\end{proofs}

Is $\sigma(T) \neq \phi \sfa T \in \mathcal{B}(X)$?
Yes, but the proof relies on complex analysis.

\begin{thm}[Liouville's Theorem]
	If $f: \mathbb{C} \to \mathbb{C}$ is complex analytic, and if $f$ is bounded then $f$ is a constant.
\end{thm}

\begin{thm}
	Let $T \in \mathcal{B}(X)$, $X$ Banach space over $\mathbb{C}$.
	Then 
	\begin{enumerate}
		\item[(a)] For each $\Lambda \in \mathcal{B}(X)^*$, the function $\varphi (\lambda) = \Lambda (\lambda I - T)^{-1}$ is analytic in $\rho(T)$.

		\item[(b)] $\sigma(T) \neq \phi$.
	\end{enumerate}
\end{thm}

\begin{proofs}
	\begin{enumerate}
		\item[(a)] Fix $\lambda_0 \in \rho(T)$.
			It suffices to show that we can represent $\varphi$ as a power series in $\lambda$ around $\lambda_0$.
			\[
				\lambda I - T = \lambda_0 I - T + (\lambda - \lambda_0) I
			\]
			\[
				= (I + (\lambda - \lambda_0)(\lambda_0 I - T)^{-1})(\lambda_0 I - T)
			\]
			\[
				"\Rightarrow" (\lambda I - T)^{-1} = (\lambda_0 I - T)^{-1} (I + (\lambda - \lambda_0)(\lambda_0 I - T)^{-1})^{-1}
			\]
			Consider
			\[
				(\lambda_0 I - T)^{-1} \sum_{k = 0}^\infty (-1)^k (\lambda_0 I - T)^{-k} (\lambda - \lambda_0)^k
			\]
			$\|(\lambda - \lambda_0)(\lambda_0 I - T)^{-1}\| < 1$ happens when 
			\[
				|\lambda - \lambda_0| < \|(\lambda_0 I - T)^{-1}\|^{-1}
			\]
			For such a $\lambda$, the power series converges, and it converges to $(\lambda I - T)^{-1}$.
			\par For $\Lambda \in \mathcal{B}(X)^*$, 
			\[
				\varphi(\lambda) = \sum_{k = 0}^\infty (-1)^k \Lambda ((\lambda_0 I - T)^{-k - 1})(\lambda - \lambda_0)^k
			\]
			This series converges when $|\lambda - \lambda_0| < \|(\lambda_0 I - T)^{-1}\|^{-1}$.
			So $\varphi$ is analytic at $\lambda_0$.

		\item[(b)] We first show that $\varphi(\lambda) \to 0$ as $|\lambda| \to \infty$ for any $\Lambda \in \mathcal{B}(X)^*$.
			We expand $\varphi$ "at $\infty$".
			\[
				(\lambda I - T)^{-1} = \frac{1}{\lambda}(I - \lambda^{-1} T)^{-1} = \frac{1}{\lambda} \sum_{k = 0}^\infty \lambda^{-k} T^k
			\]
			This series makes sense when $|\lambda| > \|T\|$.
			\[
				|\varphi(\lambda)| = |\Lambda(\lambda I - T)^{-1}| \leq \frac{1}{|\lambda|} \sum_{k = 0}^\infty |\lambda|^{-k}|\Lambda T^k|
			\]
			Note that 
			\[
				|\lambda|^{-k} |\Lambda T^k| \leq \frac{\|\Lambda\| \|T^k\|}{|\lambda|^k} \leq \|\Lambda\| \left(\frac{\|T\|}{\lambda}\right)^k < \|\Lambda\|
			\]
			Thus
			\[
				|\varphi(\lambda)| \leq \frac{C\|\Lambda\|}{|\lambda|} \to 0 \text{ as } |\lambda| \to \infty
			\]
			If $\sigma(T) = \phi$, then $\varphi$ is analytic over $\mathbb{C}$.
			Moreover, it is bounded.
			By Liouville's theorem, $\varphi(\lambda) = 0 \sfa \lambda \in \mathbb{C}$.
			$\Rightarrow \Lambda(\lambda I - T)^{-1} = 0 \sfa \lambda \in \mathbb{C}, \sfa \Lambda \in \mathcal{B}(X)^*$.
			By Hahn-Banach,
			\[
				(\lambda I - T)^{-1} = 0 \sfa \lambda \in \mathbb{C}
			\]
			Impossible!
			So $\sigma(T) \neq \phi$.
	\end{enumerate}
\end{proofs}

\begin{dfn}
	Let $T \in \mathcal{B}(X)$.
	The \textbf{spectral radius} of $T$ is 
	\[
		r(T) = \sup \{|\lambda|: \lambda \in \sigma(T)\}
	\]
\end{dfn}

We know $0 \leq r(T) \leq \|T\|$.

\begin{thm}[Spectral Radius Formula]
	If $X$ is a Banach space over $\mathbb{C}$ and if $T \in \mathcal{B}(X)$, then
	\[
		r(T) = \limsup_{n \to \infty} (\|T^n\|)^{\frac{1}{n}}
	\]
\end{thm}

\begin{rem}
	Can replace $\limsup_{n \to \infty}$ by $\lim_{n \to \infty}$.
	\[
		\|T^{m + n} \| \leq \| T^m\|\|T^n\|
	\]
	\[
		\log \|T^{m + n}\| \leq \log \|T^m\| + \log \|T^n\|
	\]
	\[
		\lim_{n \to \infty} \frac{\log \|T^n\|}{n} = \inf_{n \geq 1} \frac{\log \|T^n\|}{n}
	\]
	By Fekete's lemma, $\lim_{n \to \infty}(\|T^n\|)^{\frac{1}{n}}$ exists and equals $\inf_{n \geq 1}(\|T^n\|)^{\frac{1}{n}}$.
\end{rem}

\begin{proofs}[Proof of Theorem]
	For $|\lambda| > \limsup_{n \to \infty} (\|T^n\|))^\frac{1}{n}, \exists \delta \in (0, 1)$ and $n_0$ such that
	\[
		|\lambda|(1 - \delta) > (\|T^n\|)^{\frac{1}{n}} \sfa n \geq n_0
	\]
	\[
		\Leftrightarrow \frac{\|T^n\|}{|\lambda|^n} < (1 - \delta)^n \sfa n \geq n_0
	\]
	$\Rightarrow (1/\lambda) \sum_{k = 0}^\infty \lambda^{-k} T^k = (\lambda I - T)^{-1}$ converges.
	$\Rightarrow \lambda \in \rho(T)$.
	$\Rightarrow r(T) \leq \limsup_{n \to \infty} (\|T^n\|)^{\frac{1}{n}}$.
	On the other hand, if $|\lambda| > \|T\|$, then $\lambda \in \rho(T)$.
	For $\Lambda \in \mathcal{B}(X)^*, \varphi(\lambda) = \Lambda(\lambda I - T)^{-1} = \sum_{k = 0}^\infty \frac{\Lambda T^k}{\lambda^{k + 1}}$ holds $\sfa |\lambda| > \|T\|$.
	$\varphi$ is analytic on $\rho(T)$.
	$\Rightarrow \varphi(\lambda)$ is analytic if $|\lambda| > r(T)$.
	So $\varphi(\lambda) = \sum_{k = 0}^\infty$ still holds $\forall |\lambda| > r(T)$.
	$\Rightarrow$ for each such $\lambda$, $\left(\frac{\Lambda T^k}{\lambda^{k + 1}} \right)_k$ is bounded for each $\Lambda \in \mathcal{B}(X)^*$.
	\[
		\frac{\Lambda T^k}{\lambda^{k + 1}} = \frac{\tilde{T^k} \Lambda}{\lambda^{k + 1}}
	\]
	where $\tilde{T^k} \in \mathcal{B}(X)^{**}$ is the canonical identification.
	We have $\left( \frac{\tilde{T^k}}{\lambda^{k + 1}} \right)_k$ is bounded pointwise.
	By the uniform boundedess principle, $\exists M > 0$ such that 
	\[
		\frac{\|T^k\|}{|\lambda|^{k + 1}} = \left\|\frac{\tilde{T^k}}{\lambda^{k + 1}} \right\| \leq M \sfa k
	\]
	\[
		\Rightarrow \limsup_{n \to \infty} (\|T^n\|)^{\frac{1}{n}} \leq |\lambda|
	\]
	\[
		\Rightarrow \limsup_{n \to \infty} (\|T^n\|)^{\frac{1}{n}} \leq r(T)
	\]
\end{proofs}

\section{Hilbert Space}

A Hilbert space is a Banach space whose norm is induced by an inner product.

\begin{ex}
	\begin{itemize}
		\item $\ell^2$ is an inner product space with
			\[
				\langle x, y \rangle = \sum_{j = 1}^\infty x_j \overline{y_j}
			\]
			This is well-defined by Cauchy-Schwarz.
			Can also define sequences over integers:
			\[
				\ell^2(\mathbb{Z}) = \{x = (x_n)_{n \in \mathbb{Z}}: \sum_{n = - \infty}^\infty |x_n|^2 < \infty\}
			\]
			\[
				\langle x, y \rangle = \sum_{n = -\infty}^\infty x_n \overline{y_n}
			\]
		\item The inner product of $L^2(\mathbb{R})$ is given by 
			\[
				\langle f, g \rangle = \int_{\mathbb{R}} f(x) \overline{g(x)} \mathrm{d} x
			\]
	\end{itemize}
\end{ex}

We say two vectors $x, y$ are orthogonal if $\langle x, y \rangle = 0$.
Define a norm by using inner product:
\[
	\|x\| = \sqrt{\langle x, x \rangle}
\]
Check:
\begin{itemize}
	\item $(x, y) \mapsto \langle x, y \rangle$ is continuous from $X \times X$ to $\mathbb{C}$.

	\item If $(X, \langle \cdot, \cdot \rangle)$ is an inner product space, and if $(X', \| \cdot \|')$ is a completion of $(X, \|\cdot \|)$, where $\| \cdot \|$ is the norm induced by $\langle \cdot, \cdot \rangle$, then $\exists$ an inner product $\langle \cdot, \cdot \rangle'$ on $X'$ such that it induces $\|\cdot \|'$.
\end{itemize}

A complete inner product space is called a Hilbert space.

\begin{prop}[Parallelogram law]
	If $\| \cdot \|$ is induced by an inner product then $\|x + y \|^2 + \|x - y\|^2 = 2(\|x\|^2 + \|y\|^2)$.
\end{prop}

\begin{ex}
	\begin{enumerate}
		\item[(a)] On $\mathbb{C}^n, n \geq 2, \| \cdot \|_[$ is induced from an inner product $\Leftrightarrow p = 2$.
			Take $x = (1, 1, 0, ..., 0)$ and $y = (1, -1, 0, ..., 0)$.
			$\|x\|_p = 2^{1/p} = \|y\|_p$.
			$\|x + y \|_p = 2 = \|x - y\|_p$.
			Parallelogram law holds only when $p = 2$.
			
		\item[(b)] The sup norm on $C^0([0, 1])$ is not from an inner product.
			Take $f(x) = 1, g(x) = x$.
	\end{enumerate}
\end{ex}

\begin{rem}
	Polarization identity:
	\[
		\Re \langle x, y \rangle = \frac{1}{4} (\|x + y \|^2 - \|x - y \|^2), \Im \langle x, y \rangle = \frac{1}{4} (\|x + iy\|^2 - \|x - iy \|^2)
	\]
\end{rem}

\begin{thm}
	Let $K$ be a nonempty closed, convex, proper subset of a Hilbert space.
	Let $x_0 \in X \setminus K$.
	Then $\exists ! x^* \in K$ such that
	\[
		\|x_0 - x^*\| = \inf_{x \in K} \|x - x_0\|
	\]
\end{thm}

\begin{proofs}
	Let $(x_n)$ be a minimizing sequence:
	\[
		\|x_0 - x_n\| \to \inf_{x \in K} \|x - x_0\| =: d
	\]
	\begin{clm}
		$(x_n)$ is Cauchy.
	\end{clm}

	\begin{proofs}
		\[
			\|x_n - x_m\|^2 = \|x_n - x_0 + x_0 - x_m\|^2
		\]
		\[
			\stackrel{\text{//-gram law}}{=} - \|x_n - x_0 + x_m - x_0\|^2 + 2 (\|x_n - x_0\|^2 + \|x_m - x_0\|^2)
		\]
		\[
			= -4 \left\| \frac{x_m + x_n}{2} - x_0 \right\|^2 + 2 (\|x_n - x_0\|^2 + \|x_m - x_m\|^2)
		\]
		\[
			\leq -4d^2 + 2(\|x_n - x_0\|^2 + \|x_m - x_0\|^2)
		\]
		Since $(x_m + x_n)/2 \in K$, 
		\[
			\to -4d^2 + 2(d^2 + d^2) = 0
		\]
	\end{proofs}
	So $x^* = \lim_{n \to \infty} x_n \in K$ exists.
	Norm is continuous $\Rightarrow d = \|x_0 - x^*\|$.
	Uniqueness: exercise.
\end{proofs}

\section{Orthogonal Decomposition}

\begin{thm}
	Let $Y$ be a closed proper subspace of a Hilbert space $X$.
	Let $x_0 \in X \setminus Y$.
	Then the point $y_0 \in Y$ that minimizes the distance between $x_0$ and $Y$ satisfies
	\[
		\langle x_0 - y_0 , y \rangle = 0 \quad \forall y \in Y
	\]
	Conversely, if $z \in Y$ such that $\langle x_0 - z, y \rangle = 0 \quad y \in Y$, then $z = y_0$.
	In this case, we have $\|x_0 - y_0\|^2 + \|y_0\|^2 = \|x_0\|^2$.
\end{thm}

\begin{proofs}
	For $y \in Y$ and $h \in \mathbb{R}$, 
	\[
		\varphi(h) = \|x_0 - y_0 - hy\|^2
	\]
	attains a minimum at $h = 0$.
	\[
		\varphi(h) = \|x_0 - y_0\|^2 - h \langle x_0 - y_0 , y \rangle - h \langle y, x_0 - y_0 \rangle + h^2 \|y\|^2
	\]
	\[
		\varphi'(0) = 0 \Rightarrow \Re \langle x_0 - y_0, y \rangle = 0
	\]
	Replacing $y$ by $iy$, we obtain $\Im \langle x_0 - y_0, y \rangle = 0$.
	Conversely, if $\langle x_0 - z, y \rangle = 0 \quad \forall y \in Y$, then 
	\[
		\|x_0 - y\|^2 = \|x_0 - z + z - y\|^2 = \|x_0 - z\|^2 + \|z - y\|^2 \geq \|x_0 - z\|^2
	\]
	Since $y$ is arbitrary, $z$ minimizes the distance between $x_0$ and $Y \Rightarrow z = y_0$.
\end{proofs}

\begin{dfn}
	Let $Y$ be a closed subspace of a Hilbert space $X$.
	The \textbf{projection operator} $P$ of $X$ onto $Y$ is given by
	\[
		P x_0 = 
		\begin{cases}
			y_0 & \text{if } x_0 \in X \setminus Y\\
			x_0 & \text{if } x_0 \in Y
		\end{cases}
	\]
	We may call $Px$ the \textbf{best approximation} of $x$ in $Y$/\textbf{orthogonal projection} of $x$ on $Y$.
\end{dfn}

Check:
\begin{itemize}
	\item $P \in \mathcal{B}(X, Y)$

	\item $P^2 = P$.

	\item $\|P\| = 1$.
\end{itemize}

\begin{ex}
	To show that $P$ is linear, we just need to show that
	\[
		\langle \alpha x_1 + \beta x_2 - (\alpha P x_1 + \beta P x_2), y \rangle = 0 \quad \forall y \in Y
	\]
	By uniquenesss we have $P(\alpha x_1 + \beta x_2) = \alpha P x_1 + \beta P x_2$.
\end{ex}

Check: If $x, z \in X$, then $z = Px \Leftrightarrow z$ satisfies $\langle x - z, y \rangle = 0 \quad \forall y \in Y$.

\par Two consequences:

\begin{enumerate}
	\item Hilbert space is self-dual.
		To each $z \in X$, we associate a bounded linear function 
		\[
			\Lambda_z x = \langle x, z \rangle \quad \forall x \in X
		\]
		Easy to check: $\Lambda_z \in X^*$ and $\|\Lambda_z\| = \|z\|$.
		The map $\Phi: z \mapsto \Lambda_z$ defines a \textbf{sesquilinear} map from $X$ to $X^*$, i.e.
		\[
			\Phi(\alpha x_1 + \beta x_2) = \bar{\alpha} \Phi(x_1) + \bar{\beta} \Phi(x_2)
		\]
		Will show: $\Phi$ is isometric sesquilinear isomorphism.
		$\Rightarrow$ Hilbert space is self-dual.
		\begin{thm}[Riesz Representation Theorem]
			Let $X$ be a Hilbert space.
			For every $\Lambda \in X^*$, $\exists ! z \in X$ such that $\Lambda_z = \Lambda$ and $\|z\| = \|\Lambda\|$.
		\end{thm}
		Theorem $\Rightarrow \Phi$ is surjective and isometric.
		\begin{proofs}
			Let $\Lambda \in X^*$.
			Consider 
			\[
				Y = \{ x \in X: \Lambda x = 0\}. \quad \text{( So } Y = N(\Lambda) \text{.)}
			\]
			$Y$ is closed.
			If $Y = X$, then $\Lambda = 0$.
			Take $z = 0$.
			Otherwise, take any $x_0 \in X \setminus Y$.
			Then $\langle x_0 - P x_0, y \rangle = 0$ $\forall y \in Y$.
			Set $z_0 = x_0 - P x_0$ and $z = \frac{\overline{\Lambda z_0}}{\|z_0\|^2} z_0$.
			Fix $x \in X$.
			Let $u = (\Lambda x) z_0 - (\Lambda z_0) x$.
			Then $\Lambda u = 0 \Rightarrow u \in Y$.
			\[
				\Rightarrow 0 = \langle z_0, u \rangle = \langle u, z_0 \rangle = \langle (\Lambda x) z_0 - (\Lambda z_0) x, z_0 \rangle
			\]
			\[
				= (\Lambda x) \|z_0\|^2 - \langle(\Lambda z_0) x, z_0 \rangle = (\Lambda x) \|z_0\|^2 - \langle x, (\overline{\Lambda z_0}) z_0 \rangle
			\]
			\[
				\Rightarrow \Lambda x = \frac{1}{\|z_0\|^2} \langle x, (\overline{\Lambda z_0}) z_0 \rangle = \langle x, z \rangle
			\]
			Check: $\|\Lambda\| = \|z\|$ and $z$ is unique.
		\end{proofs}

	\item Direct sum decomposition in a Hilbert space.
		$X = X_1 \oplus X_2$.
		If $X$ is normed, we hope that the projections $X \to X_1$ and $X \to X_2$ are bounded to preserve the topology.
		Also hope that $X_1, X_2$ are closed (so $X$ Banach $\Rightarrow X_1, X_2$ Banach).
		If $X_1, X_2$ are closed, then by the closed graph theorem the projections are bounded.
\end{enumerate}

Another question: Gieven any closed subspace $X_1$ of a Banach space $X$, can wew find a closed subspace $X_2$ such that $X = X_1 \oplus X_2$?
Not always possible in the general situation.
Fact: If a Banach space possesses the property that any closed subspace satisfies this complementary property, then its norm must be equivalent to a norm induced by an inner product.

Let $X$ be a Hilbert space.
$X_1 \subseteq X$ be a closed subspace.
The orthogonal complement $X_1^\perp$ is defined as 
\[
	X_1^\perp = \{x \in X: \langle x, x_1 \rangle = 0 \quad \forall x_1 \in X_1\}
\]
By the Riesz Representation Theorem, $X_1^\perp$ is also the annihilation of $X_1$.
The notation is consitent.
$X_1^\perp$ is a closed subspace of $X$.
\[
	x = P x + (x - P x) \in X_1 + X_1^\perp
\]
\begin{clm}
	This is a direct sum.
\end{clm}

\begin{proofs}
	If $x_0 \in X_1 \cap X_1^\perp$, then $\langle x_0, x_1 \rangle = 0 \quad \forall x_1 \in X_1$.
	$\Rightarrow \langle x_0, x_0 \rangle = 0 \Rightarrow x_0 = 0$.
\end{proofs}
Moreover, $P, I - P$ are precisely the projection maps of $X_1 \oplus X_1^\perp$.
To summarize:
\begin{thm}
	$\forall$ closed subspace $X_1$ of a Hilbert space $X$, $X = X_1 \oplus X_1^\perp$.
	Moreover, if $P: X \to X_1$ is the projection operator, then $\forall x \in X$, $P x$ is the unique point in $X_1$ that satisfies $\|x - Px\| = \text{dist}(x, X_1)$ and the projection $Q: X \to X_1^\perp$ is given by $Q x = x - P x$.
\end{thm}

\section{Complete Orthonormal Set}

Question: How can we determine $P x_0$ when $x_0, Y$ are given?
In finite dimensions, if $\{x_1, ..., x_m\}$ is a basis for $Y$, then any projection $y_0$ of $x_0$ can be written as $y_0 = \sum_{k = 1}^m \alpha_k x_k$.
Also $\langle y_0 - x_0, x_j \rangle = 0 \quad j = 1, ..., m$.
To determine $\alpha_k$'s, we just need to solve
\[
	\sum_{k = 1}^m \langle x_k, x_j \rangle \alpha_k = \langle x_0, x_j \rangle \quad \forall j = 1, ..., m
\]
If $\{x_1, ..., x_m\}$ is orthonormal, we see $\alpha_j = \langle x_0, x_j \rangle$, so $y_0 = \sum_{k = 1}^m \langle x_0, x_k \rangle x_k$.
In general, if we have an orthonormal spanning set in $Y$, then we should be able to find $P x_0$ easily.

\begin{lem}[Bessel's Inequality]
	Let $S$ be an orthonormal set in a Hilbert space $X$.
	Then for each $x \in X$, $\langle x, x_\alpha \rangle = 0$ for all but at most countable many $\alpha$.
	If we write $B$ for this exceptional indices, then for any sequence $(\alpha_k)$ in $B$, 
	\[
		\sum_k |\langle x, x_{\alpha_k} \rangle|^2 \leq \|x\|^2
	\]
\end{lem}

\begin{proofs}
	Step 1: We show the Bessel inequality for a finite orthonormal set $\{x_1, ..., x_N\}$. 
	\begin{clm}
		$\sum_{k = 1}^N |\langle x, x_k \rangle|^2 \leq \|x\|^2$.
	\end{clm}

	\begin{proofs}
		Let $y = \sum_{k = 1}^N \langle x, x_k \rangle x_k$.
		Then 
		\[
			\langle x - y, x_k \rangle = \left\langle x - \sum_{l = 1}^N \langle x, x_l \rangle x_l, x_k \right\rangle
		\]
		\[
			= \langle x, x_k \rangle - \langle x, x_k \rangle = 0
		\]
		So $y$ is the orthogonal projection of $x$ onto $\text{span}(\{x_1, ..., x_N\})$.
		Also 
		\[
			\sum_{k = 1}^N |\langle x, x_k \rangle|^2 = \|y\|^2 = \|x\|^2 - \|x - y\|^2 \leq \|x\|^2
		\]
		This proves the claim.
	\end{proofs}
	
	Step 2: Let $x \in X$ and $l \in \mathbb{N}$. 
	Define 
	\[
		S_l = \{x_\alpha \in S: |\langle x, x_\alpha \rangle | \geq \frac{1}{l}\}
	\]
	We show that $S_l$ is a finite set.
	Pick $x_{\alpha_1}, ..., x_{\alpha_N}$ from $S_l$.
	Then by Step 1,
	\[
		\frac{N}{l^2} \leq \sum_{k = 1}^N |\langle x, x_{\alpha_k} \rangle |^2 \leq \|x\|^2
	\]
	$\Rightarrow N \leq l^2 \|x\|^2$.
	So $S_l$ has at most $l^2 \|x\|^2$ many elements.

	\par Step 3: Fix $x \in X$.
	Then there are at most countable manny $\langle x, x_\alpha \rangle$ are nonzero.
	Ler $S_x = \{x_\alpha \in S: \langle x, x_\alpha \rangle \neq 0\}$.
	Then
	\[
		S_x = \bigcup_{l = 1}^\infty S_l
	\]
	So $S_x$ is at most countable.\\
	\par Finally the Bessel inequality follows from the finite case by taking $N \to \infty$.
\end{proofs}

\begin{thm}
	Let $Y$ be a closed subspace of a Hilbert space $X$.
	Suppose that $S$ is an orthonormal subset of $Y$ such that $\text{span}(S)$ is dense in $Y$.
	Then $\forall x \in X$, its orthogonal projection on $Y$ is given by $\sum_k \langle x, x_k \rangle x_k$, where $(x_k)$ is any ordering of those $x_\alpha$ in $S$ with $\langle x, x_\alpha \rangle \neq 0$.
	(So we can write $\sum_\alpha \langle x, x_\alpha \rangle x_\alpha$ without any ambiguity.)
\end{thm}

\begin{proofs}
	We first verigy that $\sum_k \langle x, x_k \rangle x_k$ is convergent.
	Let $z_n = \sum_{k = 1}^n \langle x, x_k \rangle x_k$.
	We just need to show that $(z_n)$ is Cauchy.
	For $m < n$, 
	\[
		\|z_m - z_n\|^2 = \left\|\sum_{k = m + 1}^n \langle x, x_k \rangle x_k \right\|^2 = \sum_{k = m + 1}^n |\langle x, x_k \rangle|^2
	\]
	where the last term is small as $m, n$ are large, by Bessel's inequality.
	So $(z_n)$ is Cauchy.
	Also, it is easy to check that 
	\[
		\left\langle x - \sum_k \langle x, x_k \rangle x_k, y \right\rangle = 0 \quad \forall y \in Y
	\]
	So $\sum_k \langle x, x_k \rangle x_k$ is the orthogonal projection of $x$ on $Y$.
\end{proofs}

\begin{dfn}
	A subset $B$ of a Hilbert space $X$ is called a \textbf{complete orthonormal set} if 
	\begin{enumerate}
		\item[(a)] It is an orthonormal set.

		\item[(b)] $\overline{\text{span}(B)} = X$.
	\end{enumerate}
\end{dfn}

Recall: A Hamel basis $B$ satisfies 
\begin{enumerate}
	\item[(a')] All vectors in $B$ are linearly independent.

	\item[(b')] $\text{span}(B) = X$.
\end{enumerate}

(a)$\Rightarrow$(a'), but (b') is stronger than (b).
A complete orthonormal set is a good substitution for a Hamel basis.
(Some books called a complete orthonormal set as an orthonormal basis.)

\begin{thm}
	Every nonzero Hilbert space admits a complete orthonormal set.
\end{thm}

\begin{proofs}
	Let $\mathcal{O}$ be the collection of all orthonormal sets in $X$.
	$\mathcal{O} \neq \phi$, partially ordered by $\subseteq$.
	If $\mathcal{C}$ is a chain in $\mathcal{O}$, then
	\[
		O^* = \bigcup_{O \in \mathcal{C}} O
	\]
	is an upper boundd of $\mathcal{C}$ in $\mathcal{O}$.
	By Zorn's lemma, $\mathcal{O}$ has a maximal element $B$.
	
	\begin{clm}
		$B$ is a complete orthonormal set.
	\end{clm}

	\begin{proofs}
		$B$ is clearly orthonormal.
		Suppose $\exists z \in X \setminus \overline{\text{span}(B)}$.
		By orthogonal decomposition, if $P$ is the projection operator onto $\overline{\text{span}(B)}$, then
		\[
			z' = \frac{z - {Pz}}{\|z - P z\|}
		\]
		is a unit vector $\perp \overline{\text{span}(B)}$.
		Then $B \cup \{z'\} \in \mathcal{O}$, a contradiction.
	\end{proofs}
\end{proofs}

When is an orthonormal set complete?

\begin{thm}
	Let $B$ be an orthonormal set in a Hilbert space $X$.
	The following are equivalent.
	\begin{enumerate}
		\item[(a)] $B$ is a complete orthonormal set.

		\item[(b)] $x = \sum_\alpha \langle x, x_\alpha \rangle x_\alpha$ holds for all $x \in X$.

		\item[(c)] $\|x\|^2 = \sum_\alpha |\langle x, x_\alpha \rangle|^2$ holds for all $x \in X$.

		\item[(d)] $\langle x, x_\alpha \rangle = 0 \quad \forall x_\alpha \in B$ then $x = 0$.
	\end{enumerate}
	(c) is called the \textbf{Parseval Identity}.
\end{thm}

\begin{proofs}
	\par "(a)$\Rightarrow$(b)" Suppose that $B$ is a complete orthonormal set.
	The orthogonal projection on $\overline{\text{span}(B)}$ is just $I$.
	So (b) holds.

	\par "(b)$\Rightarrow$(c)" 
	\[
		\|x\|^2 - \sum_{k = 1}^n |\langle x, x_k \rangle |^2 = \left\|x - \sum_{k = 1}^n \langle x, x_k \rangle x_k \right\|^2 \to 0
	\]

	\par "(c)$\Rightarrow$(d)" is obvious.

	\par "(d)$\Rightarrow$(a)" Suppose that $\overline{\text{span}(B)} \subset X$ is a proper subset of $X$.
	Then $\exists$ nonzero $x_0 \in X \setminus \overline{\text{span}(B)}$ such that $\langle x_0, x_\alpha \rangle = 0 \quad \forall x_\alpha \in B$.
	(similar to the proof of existence of a complete orthonormal set).
	$\Rightarrow x_0 = 0$ by (a), a contradiction.
\end{proofs}

\section{Separable Hilbert Space}

\begin{prop}
	A Hilbert space $X$ has a countable complete orthonormal set $\Leftrightarrow$ it is separable.
\end{prop}

\begin{proofs}
	Let $B$ be a countable complete orthonormal set.
	Then rational linear combinations of elements in $B$ is dense in $X$.
	$\Rightarrow X$ is separeble.
	For "$\Leftarrow$", suppose that $X$ is separable.
	Let $D = \{x_1, x_2, ... \}$ be a countable dense subset of $X$.
	We can throw away vectors which are linearly dependent of the previous ones to obtain $\{y_1, y_2, ...\}$.
	We still have $\overline{\text{span}(\{y_1, y_2, ..\})} = X$.
	Then use Gram-Schmidt to obtain orthonormal $\{z_1, z_2, ...\}$ such that $\text{span}(\{z_1, z_2, ...\}) = X$.
\end{proofs}

\begin{thm}
	Let $X$ be an infinite dimensional separable Hilbert space.
	Then $\exists$ an inner-product preserving linear isomorphism $\Phi$ from $X$ onto $\ell^2$.
\end{thm}

\begin{proofs}
	Pick a complete orthonormal set $(x_k)$ of $X$.
	$\forall x \in X$, we have $x = \sum_{k = 1}^\infty \langle x, x_k \rangle x_k$.
	Define $\Phi(x) = (\langle x, x_1 \rangle, \langle x, x_2 \rangle, ...)$.
	Recall: Parseval's identity:
	\[
		\|x\|^2 = \sum_{k = 1}^\infty |\langle x, x_k \rangle|^2
	\]
	So $\Phi$ is an isometric linear map from $X$ to $\ell^2$.
	Inner-product is preserved by polarization.
	Remains to show $\Phi$ is onto.
	let $(a_k) \in \ell^2$.
	Define $u_n = \sum_{j = 1}^n a_j x_j$.
	Check $(y_n)$ is Cauchy.
	$y_n \to \sum_{j = 1}^\infty a_j x_j =: x$.
	Clearly, $a_j = \langle x, x_j, \rangle$.
	So $\Phi$ is onto.
\end{proofs}

\section{Fourier Series in $L^2$}

$L^2([-\pi, \pi])$ can be equipped with the inner product
\[
	\langle f, g \rangle = \frac{1}{2 \pi} \int_{- \pi}^\pi f(x) \overline{g(x)} \mathrm{d} x
\]
$B = \{e^{inx}: n \in \mathbb{Z}\}$ is a countable orthonormal set in $L^2$.
\[
	\hat{f}(n) = \frac{1}{2 \pi} \int_{- \pi}^\pi f(x) e^{-inx} \mathrm{d} x = \langle f, e^{i n \cdot} \rangle
\]
If $f \in L^2([-\pi, \pi])$, its Fourier series $\sum_{n = -\infty}^\infty \hat{f}(n) e^{inx} = \sum_{n = -\infty}^\infty \langle f, e^{inx} \rangle e^{inx}$, which is the orthogonal projection of $f$ on $\overline{\text{span}(B)}$, is well-defined in $L^2([-\pi, \pi])$.
By the Weierstrass approximation theorem, we know that $\text{span}(B)$ is dense in the subspace of periodic functions in $C^0([-\pi, \pi])$. under the sup norm.
\[
	\|f - g\|_{L^2} \leq \|f - g\|_{\infty} \quad \forall f, g \in C^0([-\pi, \pi])
\]
So $\text{span}(B)$ is also dense in $L^2([-\pi, \pi])$.
$\Rightarrow B$ is a complete orthonormal set.
$\forall f \in L^2([-\pi, \pi])$ its Fourier series converges to $f$ in $L^2$:
\[
	\|f(x) = \sum_{n = -N}^N \hat{f}(n) e^{inx}\|_{L^2} \to 0 \text{ as }N \to \infty
\]
Parseval's identity:
\[
	\frac{1}{2 \pi} \int_{- \pi}^\pi |f(x)|^2 \mathrm{d} x = \sum_{n = -\infty}^\infty |\hat{f}(n)|^2
\]

\section{Adjoint Operators}

Let $X, Y$ be Hilbert spaces.
Let $T \in \B(X, Y)$.
For any $y \in Y$, the map $x \mapsto \langle T x, y \rangle_{Y}$ is linear and bounded.
This defines an element in $X^*$.
By self-duality, $\exists ! x^* \in X$ such that $\langle T x, y \rangle_Y = \langle x, x^* \rangle_X$.
We define the adjoint of $T$ to be the map
\[
	T^* y = x^*
\]
Then $\langle T x, y \rangle_Y = \langle x, T^* y \rangle_X \quad \forall x \in X, y \in Y$.

\begin{prop}
	Let $T$ be as above. 
	Then $(T^*)^* = T, T^* \in \B(Y, X), \|T^*\| = \|T\|$.
\end{prop}

\begin{proofs}
	We will only show $\|T^*\| = \|T\|$.
	If $T^* y \neq 0$, then
	\[
		\|T^* y \| = \frac{|\langle T^* y, T^* y \rangle|}{\|T^* y\|} \leq \sup_{x \neq 0} \frac{|\langle x, T^* y \rangle|}{\|x\|} = \sup_{x \neq 0} \frac{|\langle T x, y \rangle |}{\|x\|} \leq \|T\| \|y\|
	\]
	The inequality also holds when $T^* y = 0$.
	$\Rightarrow \|T^*\| \leq \|T\|$.
	The other inequality follows from $(T^*)^* = T$.
\end{proofs}

Some other basic properties:
\begin{itemize}
	\item $(\alpha T_1 + \beta T_2)^* = \bar{\alpha} T_1^* + \bar{\beta} T_2^*$

	\item $(ST)^* = T^* S^*$.

	\item $(T^{-1})^* = (T^*)^{-1}$ if $T \in \B (X)$ is invertible.
\end{itemize}

\begin{dfn}
	Let $X$ be a Hilbert space.
	$T \in \B(X)$ is \textbf{self-adjoint} if $T^* = T$.
\end{dfn}

\begin{rem}
	Some textbooks use "symmmetric operator" instead of self-adjoint operator.
	"Self-adjoint operator" is used for a densely defined unbounded operator whose adjoint is equal to itself.
\end{rem}

\begin{prop}
	Let $T \in \B(X)$ be self-adjoint.
	\begin{enumerate}
		\item[(a)] All eigenvalues of $T$ are real.

		\item[(b)] Eigenvectors corresponding to distinct eigenvectors are orthogonal.
	\end{enumerate}
\end{prop}

\begin{proof}
	Linear algebra.
\end{proof}

\begin{prop}
	Let $T \in \B(X)$ be self-adjoint.
	Then 
	\[
		\|T\| = \sup_{\|x\| = 1} |\langle T x, x\rangle| =: M
	\]
\end{prop}

\begin{proofs}
	May assume $T \neq 0$.
	\[
		|\langle T x, x \rangle| \leq \|T\|\|x\|^2 \quad \forall x \in X
	\]
	\[
		\Rightarrow M \leq \|T\|
	\]
	On the other hand, 
	\[
		\langle T(x + y), x + y \rangle - \langle T(x - y), x - y \rangle = 2 \langle T x, y \rangle + 2 \langle T y, x \rangle = 4 \Re \langle T x, y \rangle
	\]
	\[
		\Rightarrow \Re \langle T x, y \rangle = \frac{1}{4} ( \langle T (x + y), x + y \rangle - \langle T(x - y), x - y \rangle ) 
	\]
	\[
		\leq \frac{M}{4} ( \|x + y\|^2 + \|x - y\|^2) \stackrel{\text{//-gram law}}{=} \frac{M}{2} (\|x\|^2 + \|y\|^2)
	\]
	Take $x \in X$ with $\|x\| = 1$ and $T x \neq 0$.
	Set $y = Tx/\|T x\|$.
	\[
		\Rightarrow \|T x\| = \Re \left\langle Tx, \frac{T x}{\|T x\|} \right\rangle \leq \frac{M}{2} (\|x\|^2 + 1) = M
	\]
	$\Rightarrow \|T\| \leq M$.
\end{proofs}

\begin{rem}
	Let $T \in \B(X)$ be self-adjoint.
	\begin{enumerate}
		\item[(a)] Note that we can express
			\[
				\|T\| = \max \left\{ \sup_{\|x\| = 1} \langle T x, x \rangle, - \inf_{\|x\| = 1} \langle T x, x \rangle \right\}
			\]
			
		\item[(b)] $\langle T x, x \rangle = 0 \quad \forall x \in X$.
			$\Rightarrow T = 0$.

	\end{enumerate}
\end{rem}

\section{Compact Operators}

\begin{dfn}
	Let $X, Y$ be normed spaces.
	A linear operator $T: X \to Y$ is called \textbf{compact} if the following holds.
	If $(x_n)$ is a uniformly bounded sequence ($\exists M > 0$ such that $\|x_n\| \leq M \quad \forall n$) then $(T x_n)$ has a convergent subsequence in $Y$.
\end{dfn}

Note: A compact operator must be bounded. (Why?)\\
Basic properties:
\begin{itemize}
	\item The set of all compact operators in $\B(X)$, where $X$ is a Banach space, forms a closed subspace of $\B(X)$ under the operator norm.
		\begin{proof}
			Diagonal argument.
		\end{proof}

	\item If $S$ is bounded and $T$ is compact, then $ST$ and $TS$ are compact.
		(In other words, the space of compact operators is a 2-sided ideal.)

	\item The transpose or the adjoint of a compact operator is compact.
		\begin{proofs}
			We prove the transpose case.
			Suppose that $T \in \B(X)$ is compact.
			Let $(\Lambda_n)$ be a bounded sequence in $X^*$.
			Want: Find a convergent subsequence of $(T^t \Lambda_n)$.
			Define $A = \overline{T B(0, 1)}$.
			Then $A$ is compact.
			$(\Lambda_n)$ is a sequence of Lipschitz functions with uniformly bounded Lipschitz constants.
			So $(\Lambda_n)$ is equicontinuous on $A$.
			Moreover, for each $x \in A$, $(\Lambda_n(x))$ lies in a compact set of $\CC$.
			By Arzel\`a-Ascoli, $\exists$ a subsequence $(\Lambda_{n_k})$ that converges uniformly on $A$.
			For $\|x\| < 1$, 
			\[
				| T^t \Lambda_{n_k} (x) - T^t \Lambda_{n_l}(x)| = |\Lambda_{n_k} (T x) - \Lambda_{n_l} (T x)| \leq \|\Lambda_{n_k} - \Lambda_{n_l}\|_\infty
			\]
			\[
				\Rightarrow \|T^t \Lambda_{n_k} - T^t \Lambda_{n_l}\| \to 0 \text{ as }k, l \to \infty
			\]
			$\Rightarrow T^t$ is compact.
		\end{proofs}
\end{itemize}

\begin{ex}
	Let $K \in C^0([a, b] \times [a, b])$ and consider 
	\[
		T f(x) = \int_a^b K(x, y) f(y) \mathrm{d} y
	\]
	We saw that $T \in \B(C^0([a, b])$ and $T \in \B(L^p([a, b])), 1 \leq p < \infty$.
	$T$ is compact on any of these spaces.
	We just consider the $L^p$ case.
	Let $(f_n)$ be a bounded sequence in $L^p$.
	$\exists M > 0$ such that $\|f_n\|_{L^p} \leq M$.
	$\exists g_n \in C^0([a, b])$ such that $\|f_n - g_n\|_{L^p} < 1/n$.
	Let $\epsilon > 0$.
	By uniform continuity, $\exists \delta > 0$ such that $|K(x, y) - K(x', y')| < \epsilon$ whenever $|(x, y) - (x', y')| < \delta$.
	So whenever $|x - x'| < \delta$, 
	\[
		|T g_n(x) - T g_n(x')| \leq \int_a^b |K(x, y) - K(x', y)| |g_n(y)| \mathrm{d} y
	\]
	\[
		\leq \epsilon (b - a)^{\frac{1}{q}} \|g_n\|_{L^p} \leq (b - a)^{\frac{1}{q}} (1 + M)\epsilon
	\]
	So $(T g_n)$ is equicontinuous.
	By Arzel\`a-Ascoli, $\exists$ a subsequence $(T g_{n_k})$ that converges uniformly to $h \in \C^0([a, b])$.
	Uniform convergence $\Rightarrow L^p$-convergence.
	\[
		\|T f_{n_k} - h\|_{L^p} \leq \|T f_{n_k} - T g_{n_k}\|_{L^p} + \|T g_{n_k} - h \|_{L^p} 
	\]
	The right hand side converges to 0 since
	\[
		\|T f_{n_k} - T g_{n_k}\|_{L^p} \leq \|T\|\|f_{n_k} - g_{n_k}\|_{L^p}  \|T\| \cdot \frac{1}{n_k} \to 0
	\]
	So $T$ is compact.
\end{ex}

\begin{ex}
	Another subclass of compact operators is provided by operators of finite rank.
	A bounded linear operator $T$ is of finite rank if its image is a finite dimensional subspace.
	In this case, $(T x_n)$ is bounded in a finite dimensional space whenever $(x_n)$ is bounded, $(T x_n)$ must have a convergent subsequence.
\end{ex}

Limits of operators of finite rank is copact.
Not all compact operators arise from this in general.
In Hilbert space, these are equivalent.

\begin{prop}
	Let $X$ be a Hilbert space and let $T \in \B(X)$ be a compact operator.
	Then $T$ is the limit of a sequence of operators of finite rank.
\end{prop}

\begin{proofs}
	Let $\epsilon > 0$ be given.
	$\overline{TB(0, 1)}$ is compact, so we can cover $\overline{TB(0, 1)}$ by open balls of radius $\epsilon$ centered at $T x_1, ..., T x_n$.
	Let $P$ be the orthogonal projection onto 
	\[
		\text{span}(\{T x_1, ..., T x_n\})
	\]
	which is finite dimensional.
	For any $x \in X$, for any $x_i$
	\[
		\|P x - T x_i\| = \|P x - P T x_i\| \leq \|x - T x_i\| (\text{since } \|P\| = 1) \cdots (*)
	\]
	Fix $x \in X$ with $\|x\| < 1$.
	Then $\exists T x_i$ such that $\|T x - T x_i\| < \epsilon$.
	Then 
	\[
		\| T x - P T x\| \leq \|T x - T x_i\| + \| T x_i - P T x\| < \epsilon + \|T x_i - T x\| \stackrel{(*)}{<} 2 \epsilon 
	\]
	$\Rightarrow \|T - P T\| \leq 2 \epsilon$, where $PT$ is the operator of finite rank.
\end{proofs}

\section{Compact, Self-Adjoint Operators}

\begin{prop}
	Let $T \in \B(X)$ be self-adjoint and compact.
	Then 
	\begin{enumerate}
		\item[(a)] For any nonzero eigenvalue $\lambda$, the corresponding eigenspace is finite dimensional.

		\item[(b)] If $(\lambda_k)$ is a sequence of distinct eigenvalues that converges to $\lambda_0$, then $\lambda_0 = 0$.
	\end{enumerate}
\end{prop}

\begin{proofs}
	We only prove (b).
	(The proof of (a) is similar.)
	Let $(\lambda_k)$ be as above.
	Let $x_k$ be an eigenvector of $T$ with eigenvalue $\lambda_k$ with $\|x_k\| = 1$.
	Then $(x_k)$ is orthonormal.
	$\Rightarrow \|x_k - x_j\| = \sqrt{2}$ if $k \neq j$.
	Suppose that $\lambda_0 \neq 0$.
	By compactness, $\exists$ a subsequence $(T x_{k_j})$ such that $\lambda_{k_j} x_{k_j} = T x_{k_j} \to x_0$ in $X$.
	$\Rightarrow x_{k_j} \to x_0/\lambda_0$.
	So $(x_{k_j})$ is Cauchy.
	$\|x_{k_j} - x_{k_l}\| < \sqrt{2}$, a contradiction.
	So $\lambda_0 = 0$.
\end{proofs}

\begin{lem}
	Let $T \in \B(X)$ be compact, self-adjoint. 
	($X$ is Hilbert space.)
	Then
	\[
		M = \sup_{x \neq 0} \frac{\langle T x, x \rangle}{\|x\|^2}
	\]
	is an eigenvalue of $T$ provided that $M > 0$.
	Similarly,
	\[
		m = \inf_{x \neq 0} \frac{\langle T x, x \rangle}{\|x\|^2}
	\]
	is an eigenvalue if $m < 0$.
\end{lem}

\begin{proofs}
	We will just prove the first case.
	Let $(x_k)$ be a sequence in $X$ with $\|x_k\| = 1$ and $\langle T x_k, x_k \rangle \to M$ as $k \to \infty$.
	By compactness, $\exists (T x_{k_j})$ that converges to some $x_0 \in X$.
	Let $m$ be defined as above.
	Consider the self-adjoint operator $T - m I$.
	(Recall: If $S$ is self-adjoint then $\|S\| = \max\{ \sup_{\|x\| = 1} \langle Sx, x\rangle, -\inf_{\|x\| = 1} \langle S x, x \rangle\}$)
	So 
	\[
		\|T - mI\| = \max \{ M - m, m - m\} = M - m
	\]
	\[
		\begin{split}
			\|T x_k - M x_k\|^2 & = \|T x_k - m x_k + m x_k - M x_k\|^2\\
			& = \|(T - m I) x_k\|^2 + (M - m)^2 \|x_k\|^2 \\
			& + \langle (T - mI) x_k, (M - m) x_k \rangle - \langle (M - m) x_k, (T - mI) x_k \rangle\\
			& \leq \|T - mI\|^2 + (M - m)^2 - 2 (M - m)(\langle T x_k, x_k \rangle - m) \\
			& = 2(M - m)^2 - 2 (M - m)(\langle T x_k, x_k \rangle - m)
		\end{split}
	\]
	which goes to 0 as $k \to \infty$.
	So we also have $T x_{k_j} - M x_{k_j} \to 0$.
	Recall: 
	\[
		T x_{k_j} \to x_0 \Rightarrow x_{k_j} \to \frac{x_0}{M}
	\]
	Since $M > 0, x_0 \neq 0$.
	(If $x_0 = 0$, then $\langle T x_{k_j}, x_{k_j} \rangle \to 0$.)
	By continuity, 
	\[
		T x_{k_j} \to \frac{T x_0}{M} \Rightarrow T x_0 = M x_0
	\]
	So $x_0$ is an eigenvector with eigenvalue $M$.
\end{proofs}

\section{Spectral Theorem for Compact, Self-Adjoint Operators}

\begin{thm}
	Let $T \in \B(X)$ be compact, self-adjoint, where $X$ is a Hilbert space.
	\begin{enumerate}
		\item[(a)] Suppose that $\langle Tx, x \rangle > 0$ for some $x \in X$, then
			\[
				\lambda_0 = \sup_{x \neq 0} \frac{ \langle T x, x \rangle}{\|x\|^2}
			\]
			is a positive eigenvalue of $T$.

		\item[(b)] Recursively, for $n \geq 2$, define 
			\[
				\lambda_n = \sup \left\{\frac{\langle T x, x \rangle}{\|x\|^2}: x \neq 0, x \perp \text{span}(\{x_1, ..., x_{n - 1}\}) \right\}
			\]
			where $x_j$ satisfies $T x_j = \lambda_j x_j, \|x_j\| = 1$ for all $j = 1, ..., n - 1$.
			Then $\lambda_n$ is a positive eigenvalue of $T$ as long as the supremum is positive.
			The collection of positive eigenvvalues is finite when $\exists N$ such that $\langle T x, x \rangle \leq 0$ for all $x \perp \text{span}(\{x_1, ..., x_N\})$.
			Otherwise, there are infinitely many $\lambda_j$ and $\lambda_1 \geq \lambda_2, \geq, ... \to 0$.

		\item[(c)] For any eigenpair $(\lambda, z)$ where $\lambda > 0$, $\lambda$ must be equal to some $\lambda_j$ and $z$ belongs to the subspace spanned by the eigenvectors of $\lambda_j$.

		\item[(d)] Similarly, all negative eigenvalues are given by 
			\[
				\lambda_1' = \inf_{x \neq 0} \frac{\langle T x, x \rangle}{\|x\|^2}
			\]
			if $\langle T x, x \rangle < 0$ for some $x$, and 
			\[
				\lambda_n' = \inf \left\{ \frac{\langle T x, x \rangle}{\|x\|^2}: x \neq 0, x \perp \text{span}(\{x_1', ..., x_{n - 1}'\})\right\}
			\]
			$x_j'$ is a normalized eigenvector of $\lambda_j'$.

		\item[(e)] Let $Y$ be the span of all normalized eigenvectors construccted above.
			Then $X = \bar{Y} \oplus X_0$, where $X_0$ is the eigenspace corresponding to $\lambda = 0$.
	\end{enumerate}
\end{thm}

\begin{proofs}
	\begin{enumerate}
		\item[(a)] is proved.

		\item[(d)] is left as an exercise.

		\item[(b)] We will only show the case $n = 2$ for the first part.
			Consider the closed subspace
			\[
				X_1 = \text{span}(\{x_1\})^{\perp}
			\]
			\begin{clm}
				$T: X_1 \to X_1$.
			\end{clm}
			
			\begin{proof}
				Let $x \in X$ be such that $x \perp x_1$.
				Need to show $T x \perp x_1$.
				\[
					\langle T x, x_1 \rangle = \langle x, T  x_1 \rangle = \lambda_1 \langle x, x_1 \rangle = 0
				\]
			\end{proof}
			Routine to check: $T: X_1 \to X_1$ is compact and self-adjoint.
			We can apply the lemma to conclude that
			\[
				\lambda_2 = \sup \left\{ \frac{\langle T x, x \rangle}{\|x\|^2}: x \neq 0, x \in X_1 \right\}
			\]
			is an eigenvalue if the sup is positive.
			We can repeat this process until it exhausts all positive eigenvalues, or we have an infinite sequence of positive, nonincreasing eigevalues.
			In this case, the sequence must converge to 0.
		\item[(c)] Suppose that $(\lambda, z)$ is not from the above construction.
			Either $\lambda \in (\lambda_{n + 1}, \lambda_n]$ for some $n$, or $\lambda \in (0, \lambda_N]$ when there are only $N$ positive eigenvalues.
			We consider the first case.
			\begin{enumerate}
				\item[1.] $\lambda \neq \lambda_n$.
					Then $z$ is orthogonal to all $x_1, ..., x_n$.
					Then 
					\[
						\lambda = \frac{\langle T z, z \rangle}{\|z\|^2} \leq \sup \left\{ \frac{\langle T x, x \rangle}{\|x\|^2}: x \neq 0, x \perp \text{span}(\{x_1, ..., x_n\}) \right\} = \lambda_{n + 1}
					\]
					contradiction.

				\item[2.] $\lambda = \lambda_n$.
					Let's assume $\lambda_{n - k} > \lambda_{n - k + 1} = \cdots = \lambda_n > \lambda_{n + 1}$.
					Let $P$ be the orthogonal projection onto $\text{span}(\{x_{n - k + 1}, ..., x_n\})$.
					Define $z' = z - P z$.
					Then $z' \perp \text{span}(\{x_{n - k + 1}, ..., x_n\})$.
					Also, $z' \perp x_1, ..., x_{n - k}$.
					Moreover, $T z' = \lambda z'$.
					Repeating the same argument as in 1. (replacing $z$ by $z'$) shows $\lambda \leq \lambda_{n + 1}$, contradiction.
			\end{enumerate}
			The case $\lambda \in (0, \lambda_N]$ is similar.

		\item[(e)] Recall: $Y = $ span of all eigenvectors constructed above.
			Observe: 
			\begin{itemize}
				\item $\langle T x, x \rangle = 0 \quad \forall x \in \bar{Y}^{\perp}$.

				\item $T: \bar{Y}^{\perp} \to \bar{Y}^{\perp}$.
			\end{itemize}
			Then $T = 0$ on $\bar{Y}^\perp$ (0-eigenspace) by a remark last time.
			$X = \bar{Y} \oplus \bar{Y}^\perp = \bar{Y} \oplus X_0$.
	\end{enumerate}
\end{proofs}

\section{An Application}

Consider the eigenvalue problem
\[
	-y'' + q(x) y = \mu y, y(a) = y(b) = 0
\]
$q$:"potential", a continuous function on $[a, b]$.
Goal: Find $\mu$ such that this problem has a nontrivial solution $y$.
$\mu$: eigenvalue, $y$: eigenfunction corresponding to $\mu$.
$L = -\dv[2]{x} + q(x)$
Look at the simplest case $q = 0$ and $[a, b] = [0, \pi]$.
Then the BVP becomes
\[
	-y'' = \mu y, y(0) = y(\pi) = 0
\]
\[
	\langle f, g \rangle = \int_0^\pi f(x) \overline{g(x)} \dd{x} \text{ on } L^2([0, \pi]) 
\]
The eigenvalues are given by $j^2$, where $j \in \NN$, and $\varphi_j(x) = \sqrt{2/\pi} \sin(jx)$ is the corresponding normalized eigenfunction.
All eigenvalues are simple.
Want: Extend this result to general $q$, using the spectral theorem for compact, self-adjoint operators.
$L$ is unbounded!
Will convert the problem to one that involves integral operator.
Observation: for any contant $c_0$, 
\[
	- y'' + (q(x) + c_0) y = \mu' y, \quad y(a) = y(b) = 0
\]
Then $\mu$ is an eigenvalue of the original problem $\Leftrightarrow \mu' = \mu + c_0$ is an eigenvalue of the new problem.
Hence choosing $c_0$ large enough we may assume $q > 0$ on $[a, b]$.
\begin{clm}
	If $q > 0$ then all eigenvalues are positive.
\end{clm}
\begin{proofs}
	Let $(\mu, \phi)$ be an eigenpair.
	May assume that $\phi$ is positive somewhere (otherwise just consider $- \phi$.)
	So $\exists x_0 \in (a, b)$ such that $\phi$ attains maximum at $x_0$
	\[
		\Rightarrow \mu \phi(x_0) = - \phi''(x_0) + q(x_0) \phi(x_0) > 0
	\]
	$\Rightarrow \mu > 0$.
\end{proofs}
We use the Green function to convert $L$ into an integral operator.
Consider $-y'' + q(x) y = 0$.
Pick any two nontrivial solutions $h_a(x)$ and $h_b(x)$ with $h_a(b) = 0 = h_b(a)$.
\begin{clm}
	$h_a$ and $h_b$ are linearly independent.
\end{clm}

\begin{proofs}
	If $\exists C$ such that $h_a = C h_b$, $\Rightarrow h_a(a) = C h_b(a) = 0$.
	$\Rightarrow h_a$ is a nontrivial eigenfunction for $\mu = 0$.
	But we assumed $q > 0$, so all eigenvalues are positive, a contradiction!.
\end{proofs}

Wronskian $W(x) = (h_a h_b' - h_a' h_b)(x) \neq 0$.
\begin{clm}
	$W$ is a nonzero constant $c$.
\end{clm}
\begin{proof}
	Compute $W'$.
\end{proof}

Define the Green operator $\G$ by 
\[
	(\G f)(x) = \int_a^b G(x, y) f(y) \dd{y}, \quad f \in L^2([a, b])
\]
where the Green function $G$ is 
\[
	G(x, y) = 
	\begin{cases}
		\frac{1}{c} h_a(x) h_b(y) & \text{if } x \geq y\\
		\frac{1}{c} h_a(y) h_b(x) & \text{if } x \leq y
	\end{cases}
\]
Then $G \in C^0([a, b] \times [a, b]), G(x, y) = G(y, x)$.
So $\G$ is a compact, self-adjoint operator on $L^2([a, b])$.
Define 
\[
	E = \{ \phi: C^1([a, b]): \phi(a) = \phi(b) = 0\}
\]
\begin{prop}
	\begin{enumerate}
		\item[(a)] One has $\G : C^0([a, b]) \to C^2([a, b]) \cap E$.
			Moreover, $L \G f = f \quad \forall f \in C^0([a, b])$.

		\item[(b)] We also have $L:C^2([a, b]) \cap E \to C^0([a, b])$.
			Moreover, $\G L \phi = \phi \quad \forall \phi \in C^2([a, b]) \cap E$.
	\end{enumerate}
\end{prop}

\begin{proofs}
	We only prove (a).
	Write
	\[
		(\G f)(x) = \int_a^x \frac{1}{c} h_a(x) h_b(y) f(y) \dd{y} + \int_x^b \frac{1}{c} h_a(y) h_b(x) f(y) \dd{y}
	\]
	Then $(\G f)(a) = (\G f)(b) = 0$.
	\[
		\begin{split}
			(\G f)'(x) & = \int_a^x \frac{1}{c} h_a'(x) h_b(y) f(y) \dd{y} + \frac{1}{c} h_a(x) h_b(x) f(x)\\
			& + \int_x^b \frac{1}{c} h_a(y) h_b'(x) f(y) \dd{y} - \frac{1}{c} h_a(x) h_b(x) f(x)\\
			& = \int_a^x \frac{1}{c} h_a'(x) h_b(y) f(y) \dd{y} + \int_x^b \frac{1}{c} h_a(y) h_b'(x) f(y) \dd{y}
		\end{split}
	\]
	\[
		\begin{split}
			(\G f)''(x) & = \int_a^x \frac{1}{c} h_a''(x) h_b(y) f(y) \dd{y} + \frac{1}{c} h_a'(x) h_b(x) f(x)\\
			& + \int_x^b \frac{1}{c} h_a(y) h_b''(y) f(y) \dd{y} - \frac{1}{c} h_a(x) h_b'(x) f(x)\\
			& \stackrel{-W = -c}{=} q(x) (\G f)(x) - f(x)
		\end{split}
	\]
	$\Rightarrow L \G f = f$.
\end{proofs}

\begin{prop}
	$\exists C > 0$ such that
	\[
		\| \G f\|_{\infty} + \|(\G f)'\|_{\infty} \leq C \| f\|_{L^2} \quad \forall f \in L^2([a, b])
	\]
\end{prop}

\begin{proofs}
	\[
		|(\G f)(x)| \leq \|G\|_\infty \|f\|_{L^1} \leq \sqrt{b - a} \|G\|_{\infty} \|f\|_{L^2}
	\]
	Similarly can show $\|(\G f)'\|_{\infty} \leq C \|f\|_{L^2}$.
\end{proofs}

\begin{prop}
	$N(\G) = \{0\}$.
\end{prop}

\begin{proofs}
	Suppose that $\G f = 0$.
	Want: $f = 0$.
	Let $f_n \in C^0([a, b])$ such that $f_n \to f$ in $L^2([a, b])$.
	Then 
	\[
		\|\G f_n - \G f\|_{\infty} \leq C \|f_n - f\|_{L^2}
	\]
	So $\G f_n \to \G f = 0$ in sup-norm.
	Let $\varphi$ be a smooth function such that $\varphi(a) = \varphi(b) = 0$.
	\[
		\begin{split}
			\langle f_n , \varphi \rangle &= \int_a^b f_n(x) \overline{\varphi(x)} \dd{x}\\
			&= \int_a^b L \G f_n(x) \overline{\varphi(x)} \dd{x}\\
			&= \int_a^b \left( - \dv[2]{x} + q(x) \right)(\G f_n)(x) \overline{\varphi(x)} \dd{x}\\
			&= \int_a^b (\G f_n)(x) \overline{L \varphi(x)} \dd{x}
		\end{split}
	\]	
	where the last equation is done by integration by parts with $\varphi(a) = \varphi(b) = (\G f_n)(a) = (\G f_n)(b) = 0$.
	We have
	\[
		\int_a^b (\G f_n)(x) \overline{L \varphi(x)} \dd{x} \leq \int_a^b \|\G f_n\|_\infty \overline{L \varphi(x)} \dd{x} \to 0
	\]
	since $\|G f_n\|_\infty \to 0$.
	$\Rightarrow \langle f, \varphi \rangle = 0 \quad \forall$ smooth $\varphi \in E$
	$\Rightarrow \langle f, g \rangle = 0 \quad \forall g \in L^2([a, b])$, by denseness of smooth functions (smooth functions dense in continuous functions which are dense in $L^2$.)
	$\Rightarrow f = 0$.
\end{proofs}

Apply the spectral theorem for compact, self-adjoint operators:
$\exists$ orthonormal $\varphi_j^+, \varphi_j^- \in L^2([a, b]), \lambda_j^+ > 0, \lambda_j^- < 0$ such that $\G \varphi_j^+ = \lambda_j^+ \varphi_j^+, \G \varphi_j^- = \lambda_j^- \varphi_j^-$.
$N(\G) = 0 \Rightarrow \{\varphi_j^+, \varphi_j^-: j \geq 1\}$ is a complete orthonormal set of $L^2([a, b])$.

\begin{thm}
	Let $q \in C^0([a, b])$.
	The eigenvalue problem has infinitely many positive eigenvalues $\mu_j \to \infty$ and at most finitely many negative eigenvalues.
	Each eigenvalue has simple multiplicity.
	The normalized eigenfunctions $\varphi_j^+ \varphi_j^-$ belong to $C^2([a, b])$ with $\varphi_j^+(a) = \varphi_j^+(b) = \varphi_j^-(a) = \varphi_j^-(b) = 0$.
	They form a complete orthonormal set in $L^2([a, b])$.
\end{thm}

\begin{proofs}
	May assume $q > 0$ such that all eigevalues are positive.
	\begin{clm}
		$(\mu, \phi)$ is an eigenpair for $L$ (here $\phi$ is assumed to be in $C^2 \cap E$ since it must be operatable for $L$) $\Leftrightarrow (\lambda, \phi)$ is an eigenpair for $\G$, where $\lambda = 1/\mu$ (here $\phi$ could be assumed to be in $C^0$).
	\end{clm}

	\begin{proofs}
		Suppose that $L \phi = \mu \phi, \phi \in C^2([a, b]) \cap E$.
		\[
			\phi = \Rightarrow \G L \phi = \mu \G \phi
		\]
		\[
			\Rightarrow \G \phi = \frac{1}{\mu} \phi \quad \forall \phi \in C^2([a, b]) \cap E
		\]
		Converse can be shown similarly.
		(Note that $\G \phi = \lambda \phi$ automatically promotes $\phi$ from $C^0$ to $C^2 \cap E$ since we've already knew that $\G: C^0 \to C^2 \cap E$.)
	\end{proofs}
	The claim shows that there are infinitely many (since $L^2$ is a infinite dimensional space there are infinitely many) positive eigenvalues $\mu_j \to \infty$.
	\par For at most finitely many negative eigenvalues, note that we've replaced $q(x)$ with $q(x) + C$ for some $C$ such that $q > 0$ and all eigenvalues $> 0$, 
	it suffices to state that there are at most finitely many eigenvalues $\mu$ in the interval $[0, C]$.
	This is easy since if not, then there exists a sequence of $\mu$ that does not converge to $\infty$.
	\par The normalized eigenfunctions part comes directly from the spectral theorem of compact, self-adjoint operators.
	\par Remains to show every eigenvalue has a simple multiplicity.
	If $\phi, \psi$ are eigenfunctions for the same eigenvalue $\mu$, choose $c_1, c_2 \in \CC$ ssuch that $c_1 \phi'(a) + c_2 \psi'(a) = 0$.
	Define $g = c_1 \phi + c_2 \psi$.
	Then $g(a) = 0, g'(a) = 0$.
	Also, $g$ is a solution to 
	\[
		-y'' + q(x) y = \mu y
	\]
	So $g = 0$ by the uniqueness of the initial value problem for ODEs.
	Thus $\phi$ and $\psi$ are linearly dependent.

\end{proofs}

\section{Weak Sequential Compactness}

For simplicity, we assume that the scalar field is $\RR$.

\begin{dfn}
	Let $(X, \|\cdot\|)$ be a normed space.
	A sequence $(x_n)$ in $X$ is called \textbf{weakly convergent} to some $x \in X$ if $\forall \Lambda \in X^*, \Lambda x_n \to \Lambda x$ as $n \to \infty$.
	Write $x_n \rightharpoonup x$.
\end{dfn}

$x_n \to x \Leftrightarrow \|x_n - x \| \to 0$ is called \textbf{strong convergence}/\textbf{norm-convergence}.

\par Basic properties:
\begin{itemize}
	\item $x_n \rightharpoonup x$ and $x_n \rightharpoonup y$ implies $x = y$.

	\item $x_n \Rightarrow x \Rightarrow x_n \rightharpoonup x$.

	\item If $x_n \rightharpoonup x$ then $\exists C > 0$ such that $\|x_n\| \leq C \quad \forall n$.
		\begin{proofs}
			Since $\Lambda x_n \to \Lambda x \quad \forall \Lambda \in X^*$, $(\Lambda x_n) = (\tilde{x_n}(\Lambda))$ is bounded.
			By uniform boundedness principle ($X^*$ is a Banach space), $(\tilde{x_n})$ is uniformly bounded.
			$\Rightarrow (x_n)$ is uniformly bounded.
		\end{proofs}

	\item If $x_n \rightharpoonup x$ then $\|x\| \leq \liminf_{n \to \infty} \|x_n\|$.
		\begin{proofs}
			Pick $\Lambda_0 \in X^*$ such that $\Lambda_0 x = \|x\|$ and $\|\Lambda_0\| = 1$.
			\[
				\|x\| = \Lambda_0 x = |\Lambda_0 x| \leq |\Lambda_0 (x - x_n)| + |\Lambda_0 x_n| \leq \epsilon + \|\Lambda_0 \| \|x_n \| = \epsilon + \|x_n\|
			\]
			where $\epsilon \to 0$ as $n \to \infty$.$\Ra \|x\| \leq \liminf_{n \to \infty} \|x_n\|$.
		\end{proofs}

	\item If $A \subseteq X$, the \textbf{convex hull} of $A$ is the smallest convex set that contains $A$.
		If $x_n \ra x$ then $x \in \overline{\text{co}}(\{x_n\})$.
		\begin{proofs}
			Suppose $x \notin \overline{\text{co}}(\{x_n\})$.
			$\{x\}$ compact, convex, nonempty.
			$\overline{\text{co}}(\{x_n\})$ closed, convex, nonempty.
			By geometric Hahn-Banach, $\exists \Lambda \in X^*$ and $\alpha$ such that 
			\[
				\Lambda x < \alpha < \Lambda y \quad \forall y \in \overline{\text{co}}(\{x_n\})
			\]
			Take $y = x_n$, let $n \to \infty$.
			$\Rightarrow \Lambda x < \alpha \leq \Lambda x$, contradiction.
		\end{proofs}
\end{itemize}

If $X$ is finite dimensional, then weak convergence $\Lra$ strong convergence.
Why? Fix a basis $\{e_1, ..., e_n\}$ for $X$.
For each $x \in X$, write $x = \sum_{j = 1}^n a_j e_j$.
Define $\Lambda_j x = a_j$.
If $x_k \ru x$, where $x_k = \sum_{j = 1}^n a_j^k e_j$, then 
\[
	a_j^i = \Lambda_j x_k \to \Lambda_j x = a_j \quad \forall j
\]
So $x_k \to x$.
Not true in general when $X$ is infinite dimensional.
\begin{exs}
	\begin{enumerate}
		\item[(a)] Fix $1 < p < \infty$ and consider $\ell^p$.
			$e_j = (0, ..., 0, 1, 0, ...)$ where only the $j$-th position is 1.
			$(e_j)$ does not have any convergent subsequence.
			\begin{clm}
				$e_j \ru 0$.
			\end{clm}

			\begin{proofs}
				Recall: Every $\Lambda \in (\ell^p)^*$ can be identified with $\Lambda x = \sum_{j = 1}^\infty y_j x_j$ where $y \in \ell^q$.
				$\Lambda e_j = y_j \to 0$ as $j \to \infty$.
				So $e_j \ru 0$.
			\end{proofs}

		\item[(b)] For each $n \geq 1$, let $f_n(x) = \sin(nx)$.
			View $(f_n)$ as a sequence in $L^2([0, \pi])$.
			Can check:
			\[
				\int_0^\pi |f_n - f_m|^2 = 1 + \O\left(\frac{1}{n}\right) + \O \left( \frac{1}{m} \right) \text{ as } n, m \to \infty
			\]
			So $(f_n)$ does not converge strongly.
			But $f_n \ru 0$ by self-duality and the Riemann-Lebesgue lemma.
	\end{enumerate}
\end{exs}

\begin{dfn}
	A set $E$ in a normed space is \textbf{weakly sequentially compact} if every sequence in $E$ contains a weakly convergent subsequence whose weak limit lies in $E$. 
\end{dfn}

\begin{thm}
	Every closed ball in a reflexive space is weakly sequentially compact.
\end{thm}

\begin{proofs}
	WLOG assume the ball is the closed unit ball centered at 0.
	Let $(x_n)$ be a sequence in this ball.
	Let $Y$ be the norm-closure of the subspace spanned by $\{x_n\}$.
	Then $Y$ is separable.
	Recall: Any closed subspace of a reflexive space is reflexive.
	So $Y$ is reflexive.
	Recall: $X^*$ is separable $\Ra X$ separable.
	$Y$ reflexive and separable $\Ra Y^*$ separable.
	Let $S$ be a countable dense subset of $Y^*$.
	By a diagonal argument, find a subsequence $(y_n)$ of $(x_n)$ such that
	\[
		\lim_{n \to \infty} \Lambda y_n \text{ exists} \quad \forall \Lambda \in S
	\]
	Pick $\Lambda \in Y^*$.
	\begin{clm}
		$(\Lambda y_n)$ is Cauchy.
	\end{clm}
	\begin{proofs}
		Fix $\epsilon > 0$.
		Take $j_0$ such that $\|\Lambda_{j_0} - \Lambda\| < \epsilon/3$ where $\Lambda_{j_0} \in S$.
		\[
			\begin{split}
				|\Lambda y_n - \Lambda y_m| & \leq |(\Lambda - \Lambda_{j_0}) y_n| + |\Lambda_{j_0} y_n - \Lambda_{j_0} y_m| + |(\Lambda j_0 - \Lambda) y_m|\\
				&< \frac{2 \epsilon}{3} + |\Lambda_{j_0} y_n - \Lambda_{j_0} y_m|
			\end{split}
		\]
		where the second term $\to 0$ as $n, m \to \infty$ since $\Lambda_{j_0} \in S$.
		$\Ra (\Lambda y_n)$ is Cauchy.
	\end{proofs}
	Define $\sigma: Y^* \to \RR$ by
	\[
		\sigma(\Lambda) = \lim_{n \to \infty} \Lambda y_n
	\]
	$\sigma$ is linear.
	Moreover, 
	\[
		|\sigma(\Lambda)| = \left|\lim_{n \to \infty} \Lambda y_n\right| \leq \|\Lambda \| \limsup_{n \to \infty} \|y_n\| \leq \|\Lambda\|
	\]
	$\Ra \sigma$ is bounded.
	$\Ra \sigma \in Y^{**}$.
	$Y$ reflexive $\Ra \exists ! y \in Y$ such that $\Lambda y = \sigma(\Lambda) \quad \forall \Lambda \in Y^*$.
	So $\Lambda y_n \to \Lambda y \quad \forall \Lambda \in Y^*$.
	$\Ra \Lambda y_n \to \Lambda y \quad \forall \Lambda \in X^*$.
	$\Ra y_n \ru y$.
	Finally, $\|y\| \leq \liminf_{n \to \infty} \|y_n\| \leq 1$, so $y$ is also in the closed unit ball.
\end{proofs}

\begin{cor}
	Let $C$ be a nonempty convex subset of a reflexive space $X$.
	$C$ is weakly sequentially compact $\Lra C$ is closed (norm-closed) and bounded.
\end{cor}

\begin{proofs}
	"$\La$, $C$ is bounded $\Ra C$ is contained in some closed ball $B$.
	So any sequence $(x_n)$ in $C$ has a subsequence that converges weakly to $x \in B$.
	$C$ is closed and convex $\Ra x \in C$, since $x \in \overline{\text{co}}(\{x_{n_k}\}) \subseteq C$.
	So $C$ is weakly sequentially compact.
	\par "$\Ra$". Let $(x_n)$ be a sequence in $C$ that converges strongly to some $x \in X$.
	Want: $x \in C$.
	By weak sequential compactness, $\exists$ a subsequence $(x_{n_k})$ of $(x_n)$ which converges weakly to $y \in C$.
	By the uniqueness of weak limit, $x = y \in C$.
	Therefore, $C$ is closed.
	Suppose that $C$ is not bounded.
	Then $\exists (x_n)$ in $C$ with $\|x_n\| \to \infty$.
	$\exists$ a weakly convergent subsequence $(x_{n_j})$.
	But such a sequence is uniformly bounded, contradiction.
\end{proofs}

\begin{thm}
	Let $X$ be reflexive and let $C$ be nonempty, closed convex subset of $X$.
	Then $\forall x \in X, \exists z \in C$ such that
	\[
		\|x - z\| = \inf\{ \|x - y\|: y \in C\}
	\]
	$z$ might not be unique: $(\RR^2, \|\cdot\|_1)$ is reflexive.
\end{thm}

\begin{proofs}
	Let $(y_n)$ be a minimizing sequence.
	\[
		\|x - y_n\| \to \inf\{ \|x - y\|: y \in C\} =: d
	\]
	$(y_n)$ is bounded:
	\[
		\|y_n\| \leq \|x - y_n\| + \|x\| \to d + \|x\|
	\]
	So $(y_n)$ has a weakly convergent subsequence $(y_{n_k})$.
	Call the weak limit $z$.
	Then $z \in C$ and 
	\[
		\|x - z\| < \liminf_{k \to \infty} \|x - y_{n_k}\| = d
	\]
	So $z \in C$ minimizes the distance.
\end{proofs}

\begin{dfn}
	We call a \textbf{sequence} $(\Lambda_k)$ in $X^*$ \textbf{converges} to $\Lambda$ \textbf{in weak*} if $\Lambda_k x \to \Lambda x \quad \forall x \in X$.
	We denote this by $\Lambda_k \stackrel{*}{\ru} \Lambda$.
	(This is a weaker requirement than weak convergence in $X^*$ since $\Lambda_k x = \tilde{x} \Lambda_k$.)
\end{dfn}

Basic properties:
Let $X$ be a normed space, and let $\Lambda_k$. 
\begin{itemize}
	\item $\|\Lambda\| \leq \liminf_{k \to \infty} \|\Lambda_k\|$.
		
	\item If $X$ is a Banach space then $\exists C > 0$ such that $\|\Lambda_k\| \leq C \quad \forall k$.
		\begin{proof}
			Uniform boundedness principle.
		\end{proof}

	\item If $X$ is a Banach space and $x_k \to x$ in $X$ then 
		\[
			\Lambda_k x_k \to \Lambda x
		\]

		\begin{proofs}
			\[
				|\Lambda_k x_k - \Lambda x| \leq |\Lambda_k x_k - \Lambda_k x| + |\Lambda_k x - \Lambda| \leq \|\Lambda_k\|\|x_k - x\| + |\Lambda_k x - \Lambda x|
			\]
			Since $|\Lambda_k x - \Lambda x| \to 0$ and $\|x_k - x\| \to 0$, $\|\Lambda_k\| \leq C$, this must converge to 0.

		\end{proofs}
\end{itemize}

\section{Topology Induced by Functionals}
\noindent $X$: nonempty set.\\
$\F$: A collection of functions from $X$ to $\RR$.\\
$\B$: Collection of all finite intersections of unions of sets of the form $f^{-1}((a, b))$, where $a, b \in \RR, f \in \F$.\\
Can check that $\B$ is a topological basis.
Define $\tau = \tau(X, \F)$ to be the topology corresponding to $\B$.
By construction, every $f \in \F$ is continuous in $(X, \tau)$.
In fact, if $\T$ is a topology on $X$ such that every function in $\F$ is continuous with respect to $\T$, then $\tau \subseteq \T$.
We call $\tau$ the \textbf{induced topology by} $\F$.

\begin{prop}
	If $\F$ separates points then $(X, \tau(X, \F))$ is Hausdorff.
\end{prop}

\begin{proofs}
	Let $x, y \in X$ be distinct.
	$\F$ separetes points $\Ra \exists f \in \F$ such that $f(x) \neq f(y)$.
	WLOG assume $f(x) < f(y)$.
	$\exists \alpha \in \RR$ such that $f(x) < \alpha < f(y)$.
	Consider $x \in \{ z: f(z) < \alpha\}$ and $y \in \{z: f(z) > \alpha\}$.
	The sets are open and disjoint, so $(X, \tau(X, \F))$ is Hausdorff.
\end{proofs}

Now we assume that $X$ is a vector space and $\F \subseteq L(X, \RR)$.

\begin{prop}
	Suppose that $X$ is a vector space and $\F \subseteq L(X, \RR)$.
	Let $\U \subseteq X$ be nonempty.
	\begin{enumerate}
		\item[(a)] $\U$ is open if and only if $\forall x_0 \in \U, \exists V$ of the form 
			\[
				V = \{x: |\Lambda_j x| < \alpha \text{ for all } j = 1, ..., N\}
			\]
			for some $\Lambda_j \in \F$ and $\alpha > 0$ such that $x_0 + V \subseteq \U$.
			$V$ here is called a $\bm{\tau}$\textbf{-open set} (centered at 0).

		\item[(b)] $\U$ is open $\Lra x + \U$ is open $\forall x \in X$.

		\item[(c)] $\U$ is open $\Lra \lambda \U$ is open $\forall \lambda \neq 0$.
	\end{enumerate}
	(b), (c) say that translations and dilations are homeomorphisms with respect to $\tau(X, \F)$.
\end{prop}

\begin{proofs}
	\begin{enumerate}
		\item[(a)] "$\La$" is obvious.
			\par "$\Ra$" Suppose that $\U$ is open.
			Let $x_0 \in \U$.
			By definition, $\exists$ a set of the form $W = \{x: \Lambda_j x \in G_j \text{ for all } j = 1, ..., N\}$ such that $x_0 \in W \subseteq \U$, where $G_j$ are open in $\RR$. 
			May assume that $G_j = (a_j, b_j)$.
			If $x \in W$, then 
			\[
				\Lambda_j x - \Lambda_j x_0 \in (a_j - \Lambda_j x_0, b_j - \Lambda_j x_0)
			\]
			\[
				\Ra x - x_0 \in \Lambda_j^{-1}((a_j - \Lambda_j x_0, b_j - \Lambda_j x_0))
			\]
			Note that $a_j - \Lambda_j x_0 < 0$ and $b_j - \Lambda_j x_0 > 0$.
			We take $\alpha = \min\{ \Lambda_j x_0 - a_j, b_j - \Lambda_j x_0 \} > 0$.
			Then we can see that $V$ is a $\tau$-open set such that $x_0 + V \subseteq \U$.

		\item[(b)] "$\La$" is obvious.
			\par "$\Ra$" Suppose that $\U$ is open, and fix $x \in X$.
			Let $x_0 \in \U$.
			By (a), $\exists V$ of the above form such that $x_0 + V \subseteq \U$.
			$\Ra x_0 + (x + V) \subseteq x + \U$.

		\item[(c)] Similar to (b)
	\end{enumerate}
\end{proofs}

\begin{prop}
	Let $\Lambda$ be a linear functional on $(X, \tau(X, \F))$, where $\F \subseteq L(X, \RR)$, $X$ is a vector space.
	\begin{enumerate}
		\item[(a)] $\Lambda$ is continuous $\Lra \Lambda$ is continuous at one point.

		\item[(b)] $\Lambda$ is continuous $\Lra \Lambda$ is bounded on a $\tau$-ball.
	\end{enumerate}
\end{prop}

\begin{proofs}
	\begin{enumerate}
		\item[(a)] Suppose that $\Lambda$ is continuous at $x_0 \in X$.
			Let $x \in X$ be arbitrary.
			Want: $\Lambda$ is continuous at $x$ (for all neighborhood of $\Lambda x$, its preimage contains a neighborhood of $x$.)
			$\Lambda$ continuous at $x_0 \Ra \forall$ open interval $(a_0, b_0) \ni \Lambda x_0, \Lambda^{-1}((a_0, b_0))$ contains a $\tau$-open set $\U \ni x_0$.
			Let $(a, b)$ be any open interval containing $\Lambda x$.
			$(a_0, b_0) := (a, b) - \Lambda x + \Lambda x_0$ is an open interval containing $\Lambda x_0$.
			By linearity, $\Lambda^{-1}((a_0, b_0)) = \Lambda^{-1}((a, b)) + x_0 - x$ contains a $\tau$-open set $\U \ni x_0$.
			$\Ra \Lambda^{-1}((a, b))$ contains the open set $\U - x_0 + x \ni x$.
			$\Ra \Lambda$ is continuous at $x$.

		\item[(b)] Suppose that $\Lambda$ is continuous.
			Then $\Lambda^{-1}((-1, 1))$ is $\tau$-open.
			$O \in \Lambda^{-1}((-1, 1)) \Ra \Lambda^{-1}((-1, 1))$ contains a $\tau$-ball $V$ centered at 0.
			$\Lambda(V) \subseteq (-1, 1)$.
			So $\Lambda$ is bounded on $V$.
			
			\par Conversely, suppose that $V$ is a $\tau$-ball and $\Lambda(V) \subseteq (-M, M)$ for some $M > 0$.
			It suffices to show $\Lambda$ is continuous at 0.
			Let $(a, b) \ni 0$.
			Pick $x_0 \in \Lambda^{-1}((a, b))$.
			$\exists \epsilon > 0$ such that $(\Lambda x_0 - \epsilon, \Lambda x_0 + \epsilon) \subseteq (a, b)$.
			Let $W = V\epsilon/(2M) $.
			Can check that $x_0 + W$ is open, $x_0 \in x_0 + W \subseteq \Lambda^{-1}((a, b))$.
			Thus $\Lambda^{-1}((a, b))$ is open.
	\end{enumerate}
\end{proofs}

\begin{prop}
	$X$ a vector space, $\F \subseteq L(X, \RR)$.
	In $(X, \tau(X, \F))$, the collection of all continuous linear functionals is given by $\F$ if and only if $\F$ is a subspace of $L(X, \RR)$.
\end{prop}

\begin{proofs}
	"$\Ra$" Exercise.
	\par "$\La$" Let $\Lambda$ be continuous in $\tau(X, \F)$.
	$\exists$ a $\tau$-ball $V$ such that
	\[
		V = \{ x: \Lambda_j x \in (-\alpha, \alpha) \quad \forall j = 1, ... K\} \subseteq \Lambda^{-1}((-1, 1))
	\]
	\begin{clm}
		$\Lambda$ vanishes on $\cap_{j = 1}^K N(\Lambda_j)$.
	\end{clm}

	\begin{proofs}
		Let $z \in \cap_{j = 1}^K N(\Lambda_j)$.
		Then 
		\[
			\Lambda_j z = 0 \quad \forall j = 1, ..., K
		\]
		\[
			\Ra \Lambda_j(\lambda z) = 0 \quad \forall j = 1, ..., K , \forall \lambda \in \RR
		\]
		\[
			\Ra \lambda z \in V \quad \forall \lambda \in \RR
		\]
		\[
			|\lambda||\Lambda z| = |\Lambda(\lambda z)| < 1 \quad \forall \lambda \in \RR
		\]
		$\Ra \Lambda z = 0$.
	\end{proofs}
	Claim $\Ra \Lambda$ is a linear combination of $\Lambda_1, ..., \Lambda_k$. (linear algebra!)
	$\F$ is a subspace $\Ra \Lambda \in \F$.
\end{proofs}

\begin{lem}
	$X$ vector space, $\F \subseteq L(X, \RR)$.
	Let $C$ be an open convex set in $(X, \tau(X, \F))$ containing $O$ and let $p_C$ be the gauge of $C$. ($p_C(x) = \inf\{\alpha > 0: x \in \alpha C\}$.)
	Then 
	\[
		C = \{x: p_C(x) < 1\}
	\]
\end{lem}

\begin{rem}
	$C$ is open, $O \in C \Ra C$ contains a $\tau$-ball.
	$\forall x \in C, \exists \epsilon > 0$ such that $\epsilon x \in $ this $\tau$-ball $\subseteq C$.
	So $p_C(x) < \infty \quad \forall x \in X$.
\end{rem}

\begin{proofs}
	\begin{clm}
		$\{x:p_C(x) < 1\} \subseteq C$ whenever $O \in C$, $C$ convex.
	\end{clm}

	\begin{proofs}
		If $p_C(x) < 1, \exists \alpha \in (0, 1)$ such that $x \in \alpha C$.
		By convexity, $x = (1 - \alpha) \cdot 0 + \alpha \cdot (x/\alpha) \in C$.
	\end{proofs}
	Now let $x \in C$.
	Since $C$ is open, $\exists$ a $\tau$-ball $V$ such that $x + V \subseteq C$.
	Since $V$ is a $\tau$-ball, $\exists \epsilon > 0$ such that $\epsilon x \in V$.
	$\Ra x + \epsilon x \in C$.
	$\Ra p_C(x) \leq 1/(1 + \epsilon) < 1$.
\end{proofs}

\begin{thm}
	Let $A, B$ be disjoint nonempty convex sets in $(X, \tau(X, \F))$, where $X$ is a vector space, $\F \subseteq L(X, \RR)$.
	\begin{enumerate}
		\item[(a)] When $A$ is open, $\exists \tau$-continuous linear function $\Lambda$ such that $\Lambda x < \Lambda y \quad \forall x \in A, y \in B$.
			
		\item[(b)] When $A$ is compact and $B$ is closed, $\exists$ a $\tau$-continuous linear functional $\Lambda$ and $\alpha, \beta \in \RR$ such that $\Lambda x < \alpha < \beta < \Lambda y \quad \forall x \in A, y \in B$.
	\end{enumerate}
\end{thm}

\begin{proofs}
	\begin{enumerate}
		\item[(a)] Consider $C = A - B + x_0$, where $x_0 \in B - A$.
			Then 
			\begin{itemize}
				\item $C$ is convex.

				\item $C$ is open, because $C = \cup_{x \in B} (A - x + x_0)$.

				\item $O \in C$.
			\end{itemize}
			Define $\Lambda_0$ on $\text{span}(\{x_0\})$ by $\Lambda_0 (\alpha x_0) = \alpha$.
			\begin{clm}
				$\Lambda_0 \leq p_C$ on $\text{span}(\{x_0\})$.
			\end{clm}
			
			\begin{proofs}
				Nothing to prove if $\alpha \leq 0$.
				\par If $\alpha > 0$, since $x_0 \notin C$, by lemma, $p_C(x_0) \geq 1$.
				$\Ra \alpha > 0, p_C(\alpha x_0) = \alpha p_C(x_0) \geq \alpha = \Lambda_0(\alpha x_0)$.
				By Hahn-Banach, $\exists \Lambda \in L(X, \RR)$ of $\Lambda_0$ such that $\Lambda \leq p_C$ on $X$ $\forall x \in A, y \in B$, then
				\[
					\Lambda(x - y + x_0) \leq p_C(x - y + x_0) < 1 = \Lambda_0 (x_0) = \Lambda x_0
				\]
				$\Ra \Lambda x < \Lambda y$.
			\end{proofs}
			We need to show that $\Lambda$ is continuous.
			Let $V$ be a $\tau$-ball in $C$.
			$x \in V \Ra -x \in V$.
			So 
			\[
				|\Lambda x| \leq p_C(x) < 1 \quad \forall x \in V
			\]
			$\Lambda$ is bounded on the $\tau$-ball $V$.
			$\Ra \Lambda$ is continuous!.

	\end{enumerate}

	We next prove (b).
	\begin{clm}
		$\exists$ open set $W$ such that $A + W$ is open convex and is disjoint from $B$.
	\end{clm}

	\begin{proofs}
		Will use a compactness argument.
		For each $x \in A$, since $A \cap B = \phi$ and $B$ is closed, $\exists V_x = \{y: |\Lambda_j y| < \gamma_x \quad \forall j = 1, ..., N\}$, $\gamma_x > 0$ such that $W_x := x + V_x$ is disjoint from $B$.
		$(W_x)_{x \in A}$ forms an open cover for $A$.
		By compactness, $\exists$ a finite subcover $(W_{x_k})_{k = 1, ..., m}$, we write $W_{x_l} = \{y: |\Lambda_{j_l} y| < \gamma_{x_l} \quad \forall l = 1, ..., N(l)\}$.
		Let 
		\[
			\gamma = \min\{\gamma_{x_1}, ..., \gamma_{x_m}\}, \quad W = \{y: |\Lambda_{j_k} y| < \gamma \quad \forall j_k\}
		\]
		Check: $A + W$ is open convex, $A + W$ is disjoint from $B$.
	\end{proofs}
	By (a), $\exists \tau$-continuous $\Lambda \in L(X, \RR)$ such that
	\[
		\Lambda x < \Lambda y \quad \forall x \in A + W, \quad \forall y \in B
	\]
	Also, a nonzero linear functional is an open map (check!).
	$\Ra \Lambda(A + W)$ is open in $\RR$.
	$\Lambda(A)$ is compact.
	So we can find $\alpha, \beta$ such that
	\[
		\Lambda x < \alpha < \beta < \Lambda y \quad \forall x \in A, \quad \forall y \in B
	\]
\end{proofs}

\section{Weak and Weak$^{*}$-Topologies}

$X$: normed space.
The topology $\tau(X, X^*)$ is called the weak topology of $X$.
By Hahn-Banach, weak topology is Hausdorff.
This weak topology is much weaker than the norm topology if $X$ is infinite dimensional.

\begin{prop}
	Let $X$ be an infinite dimensional normed space.
	Every weakly open set conatin an infinite dimensional subspace of $X$.
\end{prop}

\begin{proofs}
	Every weakly open set contains a weak ball (a $\tau(X, X^*)$-ball) $V$, we prove the result for $V = \{x: |\Lambda_j x| < \alpha \quad \forall j = 1, ..., N\}$.
	Consider $\Phi: X \to \RR^N$ defined by 
	\[
		\Phi x = (\Lambda_1 x, ..., \Lambda_N x)
	\]
	$N(\Phi)$ is infinite dimensional, $N(\Phi) \subseteq V$.
\end{proofs}

\begin{prop}
	The weak topology is not metrizable if $X$ is an infinite dimensional normed space.
\end{prop}

\begin{dfn}
	$\B$ is a \textbf{local basis} for $(X, \T)$ at $x_0$ if 
	\begin{enumerate}
		\item[(a)] All $B \in \B$ is open and contains $x_0$

		\item[(b)] $\forall$ open neighborhood $\U$ of $x_0, \exists B \in \B$ such that $B \subseteq \U$.
	\end{enumerate}
\end{dfn}

Fact: The metric topology has a countable local basis
\[
	\left\{ \left\{ x: d(x, x_0) < \frac{1}{n} \right\}: n \geq 1 \right\}
\]

\begin{proofs}[Proof of Proposition]
	Suppose that the weak topology comes from a metric $d$.
	Then $\exists$ a countable local basis at $0$ consisting of weak balls $V_n = \{x: |\lambda_j^{(n)}x| < \alpha_n \quad \forall j = 1, ..., K(n)\}, n \geq 1$.
	$(\Lambda_j^{(n)})$ forms a countable set in $X^*$.
	$X^*$ is a Banach space.
	Recall that every Hamel basis of $X^*$(a Banach space) is uncountable (by Baire-category in some homework last semester).
	So $\exists \Lambda \in X^*$ such that $\Lambda$ is linearly independent of $\Lambda_j^{(n)}$.
	Consider the open set $\U = \{x: |\Lambda x| < 1\}$.
	$\U$ must contain some $V_{n_0}$.
	$\Ra \Lambda$ vanishes on $\cap_{j = 1}^{K(n_0)} N(\Lambda_j^{(n_0)})$.
	$\Ra \Lambda$ is a linear combination of $\Lambda_j^{(n_0)}$, a contradiction!
	So the weak topology is not metrizable.
\end{proofs}

\begin{prop}
	A convex set in a normed space $X$ is weakly closed if and only if it is norm-closed.
\end{prop}

\begin{proofs}
	Weakly closed $\Ra$ Norm-closed.

	\par Suppose that $C$ is norm-closed and convex.
	Will show: $X \setminus C$ is weakly open.
	Let $x \in X \setminus C$.
	$\{x\}$ is compact.
	By the separation theorem, $\exists \Lambda \in X^*$ and $\alpha \in \RR$ such that
	\[
		\Lambda x < \alpha < \Lambda y \quad \forall y \in C
	\]
	The $\tau$ ball $V = \{z: \Lambda z < \alpha\}$ is disjoint from $C$.
	$x \in V \Ra X\setminus C$ is weakly open.
\end{proofs}

\begin{dfn}
	Let $X$ be a normed space.
	The \textbf{weak$^{\bm{*}}$-topology on $X^*$} is given by $\tau(X^*, J(X))$, where $J: X \to X^{**}$ is the canonical identification.
	Again, the weak$^*$-topology is Hausdorff.
	\textbf{Weak$^{\bm{*}}$-balls} are of the form
	\[
		V = \{\Lambda: |\Lambda x_j| < \alpha \quad \forall j = 1, ..., N\}
	\]
	where $N \geq 1, \alpha > 0, x_j \in X$.
\end{dfn}

\noindent Weak topology on $X$: Weakest topology on $X$ such that all bounded linear functionals are continuous.\\
Weak$^*$-topology on $X^*$: Weakest topology on $X^*$ such that all the evaluation maps are continuous.\\
Can also talk about weak topology on $X^*$.\\
Weak topology on $X^*$: Weakest topology on $X^*$ such that all bounded linear functionals in $X^{**}$ are continuous, which is a stronger requirement than in the weak$^*$-topology.

\par In general, on $X^*$, weak$^*$-topology is weaker than the weak topology.

\begin{thm}[Banach-Alaoglu]
	A closed ball in $X^*$ is weak$^*$-compact.
\end{thm}

\begin{proofs}
	We will prove that $B = \overline{B(0, 1)}$ in $X^*$ is weak$^*$-compact.
	Consider the product space
	\[
		Y = \prod_{x \in X} [-\|x\|, \|x\|]
	\]
	Then $Y$ is compact by Tychonoff's theorem.
	Define $\Phi: B \to Y$ by $\Phi(\Lambda) = (\Lambda x)_{x \in X}$.
	(Note that this is well-defined since $\|\Lambda\| \leq 1$, $|\Lambda x| \leq \|x\|$.)
	Recall: The product topology is generated by sets of the form
	\[
		\{z \in Y: |z_{x_j} - y_{x_j}| < \alpha \quad \forall j = 1, ..., N\}
	\]
	where $N \geq 1, x_j \in X, \alpha > 0$.
	The topology induced on $B$ by the product topology on $Y$ is exactly the weakest topology on $B$ that makes all $\Lambda \mapsto \Lambda x$ continuous $\forall x \in X$.
	This is the weak$^*$-topology.
	So $\Phi$ is continuous.
	To prove $B$ is compact, it suffices to show that $\Phi(B)$ is closed in $Y$.
	(Since $\Phi(B)$ will then be compact; 
	also, $\Phi: B \to \Phi(B)$ is a homoemorphism, so this implies that $B$ is also compact.)
	Let $y \in \overline{\Phi(B)}$.
	Define a map $\Lambda: X \to \RR$ by $\Lambda x = y_x$.
	To show $y \in \Phi(B)$, we need to show that $\Lambda$ is linear and $\|\Lambda\| \leq 1$.
	Fix $\alpha > 0$ and $x_1, x_2 \in X$.
	Consider the following neighborhood $V$ of $y$:
	\[
		V = \left\{z \in Y: |z_{x_1} - y_{x_1}|, |z_{x_2} - y_{x_2}|, |z_{x_1 + x_2} - y_{x_1 + x_2}| < \frac{\alpha}{3} \right\}
	\]
	\[
		\Ra |y_{x_1} + y_{x_2} - y_{x_1 + x_2}| < \alpha
	\]
	$\alpha$ is arbitrary $\Ra y_{x_1 + x_2} = y_{x_1} + y_{x_2} \Ra \Lambda (x_1 + x_2) = \Lambda x_1 + \Lambda x_2$.
	Similarly, $\Lambda (cx) = c \Lambda x \quad \forall c \in \RR, \quad \forall x \in X$.
	Finally, 
	\[
		|\Lambda x| = |y_x| \leq \|x\|
	\]
	$\Ra \|\Lambda\| \leq 1$.
\end{proofs}

\begin{cor}
	A bounded set in $X^*$ is weak$^*$-compact $\Lra$ it is weak$^*$-closed.
\end{cor}

\begin{proofs}
	Weak$^*$-topology is Hausdorff, so weak$^*$-compact $\Ra$ weak$^*$-closed.

	\par Conversely, every bounded set is containd in some closed ball, which is weak$^*$-compact.
	$\Ra$ a bounded weak$^*$-closed set is also weak$^*$-compact.
\end{proofs}

\begin{lem}
	The closed unit ball in a normed space $X$ is dense in the closed unit ball in $X^{**}$ under tthe $\tau(X^{**}, J^*(X^*))$ topology, where $J^*: X^* \to X^{***}$ is the canonical identification.
\end{lem}

\begin{proofs}
	Let $B, B^{**}$ be the closed unit balls in $X, X^{**}$ respectively.
	$J: X \to X^{**}$ canonical identification.
	Write $C$ for the weak$^*$-closure of $J(B)$.
	Want: $C = B^{**}$.
	Suppose not.
	$\exists p \in B^{**}$ such that $p \notin C$.
	$B^{**}$ is weak$^*$-compact $\Ra B^{**}$ is weak$^*$-closed.
	Since $J(B) \subseteq B^{**}$, we have $C \subseteq B^{**}$.
	$\{p\}$ compact, $C$ weak$^*$-closed.
	Thus $\exists J^*(\Lambda) \in J^*(X^*), \alpha, \beta \in \RR$ such that
	\[
		J^*(\Lambda) q < \alpha < \beta < J^*(\Lambda) p \quad \forall q \in C
	\]
	Take $q = Jx$, where $x \in B$.
	Then
	\[
		\Lambda x = J^*(\Lambda) J x < \alpha
	\]
	$\Ra \|\Lambda\| \leq \alpha$.
	On the other hand, 
	\[
		\beta < |J^*(\Lambda) p| \leq \|\Lambda\| \|p\| \leq \|\Lambda\|
	\]
	a contradiction.
\end{proofs}

\begin{thm}
	The closed unit ball in a normed space is weakly compact if and only if the space is reflexive.
\end{thm}

\begin{proofs}
	Suppose that $X$ is reflexive.
	The weak topology on $X$ can be identified with the weak$^*$-topology on $X^{**}$.
	So the closed unit ball of $X$ is weakly compact by Banach-Alaoglu.
	
	\par Conversely, suppose that $B = \overline{B(0, 1)} \subseteq X$ is weakly compact.
	Then $J(B)$ is compact in $\tau(X^{**}, J^*(X^*))$. (Check!)
	$\Ra J(B)$ is closed in $\tau(X^{**}, J^*(X^*))$ (Hausdorff).
	$\Ra J(B) = B^{**}$ by lemma.
	So $J$ is surjective and thus $X$ is reflexive.
\end{proofs}

\section{Extreme Points in Convex Sets}

\begin{dfn}
	Let $X$ be a vector space and let $E \subseteq X$ be nonempty.
	A point $x \in E$ is called an \textbf{extreme point} if whenever it is expressed as $\lambda x_1 + (1 - \lambda) x_2$ for some $x_1, x_2 \in E, \lambda \in (0, 1)$, then $x_1 = x_2 = x$.	
\end{dfn}

\begin{exs}
	\begin{enumerate}
		\item[(a)] Closed unit ball centered at 0 in $\ell^1$.
			The extreme points are $\{\pm e_j: j \geq 1\}$.

		\item[(b)] 
			\[
				C_1 := \{ f \in C^0([0, 1]): |f(x)| \leq 1, f(0) = f(1) = 0\}
			\]
			is closed and convex in $C^0([0, 1])$.
			\begin{clm}
				$C_1$ has no extreme points
			\end{clm}
			\begin{proofs}
				Let $f \in C_1$.
				Then there exists a subinterval $[a, b] \subseteq (0, 1)$ and $\alpha, \beta \in (-1, 1)$ such that $\alpha < f(x) < \beta \quad \forall x \in [a, b])$.
				Fix $\phi \in C^0([0, 1])$ such that $\phi = 0$ outside of $[a, b]$ and $\phi \neq 0$.
				Then for small $\epsilon > 0, f \pm \epsilon \phi \in C_1$.
				$\Ra f = [(f + \epsilon \phi) + (f - \epsilon \phi)]/2$ is not an extreme point.
			\end{proofs}

		\item[(c)] 
			\[
				C_2 := \{f \in C^0([0, 1]): 0 \leq f(x) \leq 1, \quad f(0) = f(1) = 0\}
			\]
			Then every nonzero function is not an extreme point and 0 is an extreme point.
	\end{enumerate}
\end{exs}

\begin{lem}
	Let $X$ be a normed space or a vector space over $\RR$ with topology induced by a separating subset $\F$ of $L(X, \RR)$.
	Let $K$ be a nonepmty, compact, convex subset of $X$.
	Then $K$ has an extreme point.
\end{lem}

\begin{proofs}
	We call a set $E \subseteq K$ extreme if $\forall x \in E$, if $x = \lambda x_1 + (1 - \lambda) x_2$ for some $x_1, x_2 \in K, \lambda \in (0, 1)$, then $x_1, x_2 \in E$.
	Let $\E$ be the collection of all nonempty, closed extreme subsets of $K$.
	$K \in \E$, so $\E \neq \phi$.
	$\E$ is partially ordered by set inclusion.
	Will show: $\E$ has a minimal element by Zorn's lemma.
	Let $\C$ be a chain in $\E$.
	Define
	\[
		E' = \bigcap_{E \in \C} E
	\]
	Then $E'$ is closed.
	Moreover, $K$ is compact.
	So $E'$ is compact subset of $K$.
	By the finite intersection property, $E' \neq \phi$.
	Also, $E'$ is extreme (easy to check).
	So $E'$ is a lower bound for $\C$ in $\E$.
	By Zorn's lema, $\E$ has a minimal element $E^*$.

	\begin{clm}
		$E^*$ is a singleton. 
		(This point is an extreme point of $K$.)
	\end{clm}
	
	\begin{proofs}
		Suppose that $x, y \in E^*, x \neq y$.
		Choose a continuous $\Lambda$ such that $\Lambda x < \Lambda y$.
		$\Lambda$ is nonconstant on $E^*$.
		$\Lambda$ achieves its maximum on some proper subset $F$ of $E^*$.
		$\Lambda$ continuous, $E^*$ closed $\Ra F$ is closed.
		\begin{clm}
			$F$ is an extreme subset of $E^*$.
		\end{clm}

		\begin{proofs}
			Let $z \in F$.
			Write $z = \lambda x_1 + (1 - \lambda) x_2$ where $x_1, x_2 \in E^*, \lambda \in (0, 1)$.
			\[
				\Ra \Lambda z = \lambda \Lambda x_1 + (1 - \lambda) \Lambda x_2
			\]
			Since $\Lambda z$ is the maximum value of $\Lambda$ on $E^*$, we must have $\Lambda x_1 = \Lambda x_2 = \Lambda z$ are all maximum values of $\Lambda$ on $E^*$, i.e. $x_1, x_2 \in F$.
		\end{proofs}
		Actually by claim, $F$ is also an extreme subset of $K$:
		\[
			z = \lambda x_1 + (1 - \lambda) x_2, \quad x_1, x_2 \in K, \lambda \in (0, 1)
		\]
		$z \in E^* \Ra x_1, x_2 \in E^* \Ra x_1, x_2 \in F$ by claim.
		$F$ is a proper subset of $E^*$.
		$F$ is nonempty, closed, extreme subset of $K$.
		$E^*$ is minimal, a contradiction.
		So $E^*$ is a singleton.
	\end{proofs}
\end{proofs}
Here is a fact (the Carathe\`odory theorem)

\begin{thm}[Carath\`eodory Theorem]
	Any point in a nonempty, compact, convex subset of $\RR^n$ can be expressed as a linear combination of at most $n + 1$ many extreme points.	
\end{thm}

\begin{proof}
	By induction.
\end{proof}

Infinite dimensions?
Recall: $X$ vector space over $\RR$ and $E \subseteq X$.
\[
	\begin{split}
		\text{co}(E) &= \text{ intersection of all convex sets containing }E\\
		&= \text{ smallest convex set containing } E
	\end{split}
\]
\[
	\overline{\text{co}}(E) = \text{ closure of } \text{co}(E)
\]

\begin{thm}[Krein-Milman]
	Let $X$ be a normed space or a vector space over $\RR$ with topology induced by a separating subset $\F$ of $L(X, \RR)$.
	Let $K$ be a nonempty, compact, convex subset of $X$.
	Let $E(K)$ be the set of all extremum points in $K$.
	Then $\overline{\text{co}}(E(K)) = K$.
\end{thm}

\begin{proofs}
	$\text{co}(E(K)) \subseteq K \Ra \overline{\text{co}}(E(K)) \subseteq K$ since $K$ is closed.
	Suppose that $\overline{\text{co}}(E(K)) \subset K$ strictly.
	Pick $x_0 \in K \setminus \overline{\text{co}}(E(K))$.
	By the separation theorem, $\exists$ continuous $\Lambda$ and $\alpha, \beta \in \RR$ such that
	\[
		\Lambda x < \alpha < \beta < \Lambda x_0 \quad \forall x \in \overline{\text{co}}(E(K))
	\]
	Let $M = \max_{y \in K} \Lambda y$ ($K$ is compact and $\Lambda$ is continuous, it makes sense to write $\max$).
	Define $A = \{x \in K: \Lambda x = M\}$.
	Clearly $A \cap \overline{\text{co}}(E(K)) = \phi$ (since all $x \in \Lambda(\overline{\text{co}}(E(K)) < \Lambda x_0$).
	$A$ is nonempty, compact (closed in compact), convex subset of $X$.
	By lemma, $A$ has an extreme point $z$.
	By using the same proof as in lemma, $z$ is also an extreme point of $K$.
	Thus $\Lambda z < \Lambda x_0 \leq M$, a contradiction to $z \in A$.
	Thus $\overline{\text{co}}(E(K)) = K$.
\end{proofs}

\begin{cor}
	Let $K$ be nonempty, closed, bounded convex subset of a relfexivve space.
	Then $K = \overline{\text{co}}(E(K))$.
\end{cor}

\begin{proofs}
	$K$ is contained a closed ball of the reflexive space.
	By last time, this ball is weakly compact.
	So $K$ is weakly compact.
	Apply Krein-Milman.
\end{proofs}

\section{Fourier Analysis}

\subsection{Fourier Series}

If $f \in L^1([-\pi, \pi])$, then we could define the Fourier series 
\[
	\sum_{n = -\infty}^\infty \hat{f}(n) e^{inx}
\]
where the Fourier coefficient $\hat{f}(n)$ is defined by
\[
	\hat{f}(n) = \ev{f, e^{inx}} = \frac{1}{2 \pi} \int_{- \pi}^\pi f(x) e^{-inx} \dd{x}
\]

Recall:
\begin{itemize}
	\item If $f$ is H\"older continuous and $2 \pi$-periodic, then its Fourier series converges to $f$ pointwise. (Ref W5-1)

	\item No pointwise convergence if $f$ is merely continuous.

	\item If $f \in L^2([-\pi, \pi])$, then
		\[
			\|f - S_N(f)\|_{L^2} \to 0 \quad \text{as } N \to \infty
		\]
		where $S_N(f) = \sum_{n = -N}^N \hat{f}(n) e^{inx}$.

	\item If $f \in C^0([-\pi, \pi])$ and $2 \pi$-periodic, then $\forall \epsilon > 0, \exists$ trigonometric polynomial $p$ such that $\|f - p\|_{\infty} < \epsilon$.
\end{itemize}

Can the trigonometric polynomail be chosen such that it is related to $S_N(f)$?

Recall: $(x_n)$ a sequence of complex numbers.
If $(x_n)$ converges, then
\[
	\lim_{n \to \infty} \frac{x_1 + \cdots + x_n}{n}
\]
also exists (and equals to $\lim_{n \to \infty} x_n$.)
The converse is not true.

\begin{dfn}
	Let $(x_n)$ be a sequence of complex numbers.
	Let $s_n = \sum_{k = 1}^n x_k$.
	We say that $\sum_n x_n$ is \textbf{Ces\`aro summable} to $s$ if 
	\[
		\lim_{n \to \infty} \frac{s_1 + \cdots + s_n}{n} = s
	\]
\end{dfn}

Consider the Ces\`aro mean of $S_N(f)$:
\[
	\sigma_N(f)(x) = \frac{S_0(f)(x) + \cdots + S_{N - 1}(f)(x)}{N}
\]
Recall: $S_n(f)(x) = f * D_n(x)$, where $D_n(x) = \sum_{k = -n}^n e^{ikx}$.
So 
\[
	\sigma_N(f)(x) = (f * F_N)(x)
\]
$F_N$ is called the $N^{\text{th}}$-Fej\'er kernel, 
\[
	F_N(x) = \frac{D_0(x) + \cdots + D_{N - 1}(x)}{N} = \sum_{n = -(N - 1)}^{N - 1} \left( 1 - \frac{|n|}{N} \right) e^{inx} = \frac{1}{N} \left( \frac{\sin \left( \frac{Nx}{2} \right)}{\sin \left( \frac{x}{2} \right)} \right)^2
\]

Basic properties of $F_N$:
\begin{itemize}
	\item $F_N \geq 0$

	\item $\frac{1}{2 \pi} \int_{- \pi}^\pi F_N(x) = 1$ (directly by the properties of the Dirichlet kernel.)

	\item $\forall \delta > 0, \int_{\{\delta \leq |x| \leq \pi\}} |F_N(x)| \dd{x} \to 0$ as $N \to \infty$.
\end{itemize}

$(F_N)$ satisfies the nice properties of an appriximation to the identity.
If $f$ is continuous at $x$, then $(f * F_N)(x) \to f(x)$.
Moreover, if $f$ is continuous everywhere, then $f * F_N \rightrightarrows f$.

\begin{cor}
	If $f \in L^1([-\pi, \pi])$, then the Fourier series of $f$ is Ces\`aro summable to $f$ at every continuity point of $f$.
	If $f$ is continuous and $2 \pi$-periodic, then the Fouier series is uniformly Ces\`aro summable to $f$.
\end{cor}

\begin{cor}[Uniqueness Theorem]
	If $f \in L^1([-\pi, \pi])$ and if $\hat{f}(n) = 0 \quad \forall n \in \ZZ$ then $f = 0$ a.e.
\end{cor}

\begin{proof}
	$\sigma_N(f)(x) = 0 \to f$ a.e.
\end{proof}

\begin{cor}
	Suppose that $f$ is continuous and $2 \pi$-periodic and that the Fourier series of $f$ is absolutely convergent
	\[
		\sum_{n = -\infty}^\infty |\hat{f}(n) e^{inx}| = \sum_{n = -\infty}^\infty |\hat{f}(n)| < \infty
	\]
	Then the Fourier series converges to $f$ uniformly.
\end{cor}

\begin{proof}
	By Weierstrass M-test, the Fourier series converges uniformly, with limit equal to the Ces\`aro sum, which is $f$.
\end{proof}

Recall: If $f \in L^1([-\pi, \pi])$, then $\lim_{|n| \to \infty} \hat{f}(n) = 0$ (Riemann-Lebesgue lemma).
Can we obtain a vanishing rate of $\hat{f}(n)$?
Given a sequence $(a_n)$ such that $\lim_{|n| \to \infty} a_n = 0$, can we find $f \in L^1([-\pi, \pi])$ such that $\hat{f}(n) = a_n$?

\begin{thm}
	Let $(a_n)$ be a sequence of nonnegative numbers such that $\lim_{|n| \to \infty} a_n = 0$.
	Suppose that $a_{-n} = a_n \quad \forall n \geq 1$ and 
	\[
		a_{n - 1} + a_{n + 1} - 2 a_n \geq 0 \quad \forall n \geq 1
	\]
	Then there exists a nonnegative $f \in L^1([-\pi, \pi])$ such that $\hat{f}(n) = a_n$.
\end{thm}

Let $\phi:[0, \infty) \to \RR$ be convex.
then $a_n = \phi(n)$ satisfies $a_{n - 1} + a_{n + 1} - 2 a_n \geq 0 \quad \forall n \geq 1$.
We can take convex $\phi$ such that $\phi(x) \to 0$ arbitrarily slowly as $x \to \infty$.
This provides examples of $f$ with arbitrarily slow decaying Fourier coefficients.

\begin{proofs}[Proof of Theorem]
	$(a_n - a_{n + 1})$ is monotone decreasing in $n$.
	Moreover, 
	\[
		\sum_{n = 0}^N (a_n - a_{n + 1}) = a_0 - a_{N + 1} \to a_0 \quad \text{as } N \to \infty
	\]
	Hence 
	\[
		\lim_{n \to \infty} n(a_n - a_{n + 1}) = 0
	\]
	Thus 
	\[
		\sum_{n = 1}^N n(a_{n - 1} + a_{n + 2} - 2 a_n) = a_n - a_N - N (a_N - a_{N + 1}) \to a_0
	\]
	Set 
	\[
		f(x) = \sum_{n = 1}^\infty n(a_{n - 1} + a_{n + 1} - 2 a_n) F_n(x)
	\]
	Since $\|F_n\|_{L^1} = 1$, the series converges in $L^1$.
	$f \geq 0$.
	Furthermore, since
	\[
		F_n(x) = \sum_{m = -(n - 1)}^{n - 1} \left(1 - \frac{|m|}{n} \right) e^{imx}
	\]
	\[
		\hat{F}_n(m) = 
		\begin{cases}
			1 - \frac{|m|}{n} &\text{if } |m| \leq n - 1\\
			0 & \text{otherwise}
		\end{cases}
	\]
	We have
	\[
		\hat{f}(m) = \sum_{n = 1}^\infty n(a_{n - 1} + a_{n + 1} - 2 a_n) \hat{F}_n(m) = \sum_{n = |m| + 1}^\infty n(a_{n - 1} + a_{n + 1} - 2 a_n) \left( 1 - \frac{|m|}{n} \right)
	\]
	Can check that this is equal to $a_{|m|}$, which proves the theorem.
\end{proofs}

\begin{thm}
	Let $f \in L^1([-\pi, \pi])$ and assume that $\hat{f}(|n|) = -\hat{f}(-|n|) \geq 0 \quad \forall n \in \ZZ$.
	Then 
	\[
		\sum_{n \neq 0} \frac{1}{n} \hat{f}(n) < \infty
	\]
\end{thm}

Consequence: $\hat{f}(0) = 0$.
For $n \geq 1$, 
\[
	\hat{f}(n) e^{inx} + \hat{f}(-n) e^{-inx} = \hat{f}(n) (e^{inx} - e^{-inx}) = 2i \hat{f}(n) \sin (nx)
\]
So the Fourier series of $f$ becomes
\[
	2 i \sum_{n = 1}^\infty \hat{f}(n) \sin (nx)
\]
Choose $(a_n)$ such that $a_n > 0, a_n \to 0$ as $n \to \infty$ and $\sum_{n = 1}^\infty a_n/n = \infty$, then $\sum_{n = 1}^\infty a_n \sin (nx)$ is not a Fourier series.
In particular, $\sum_{n = 2}^\infty \sin (nx)/\log n$ is not a Fourier series.
But $\sum_{n= 2}^\infty \cos(nx)/\log n$ is a Fourier series since
\[
	\sum_{n = 2}^\infty \frac{\cos(nx)}{\log n} = \sum_{|n| \geq 2} \frac{e^{inx}}{2 \log |n|}
\]
and by $1/\log x$ is convex.

\begin{proofs}[Proof of Theorem]
	\[
		\frac{1}{2 \pi} \int_{-\pi}^\pi f(x) \dd{x} \hat{f}(0) = 0
	\]
	Define $F(x) = \int_{-\pi}^x f(t) \dd{t}$.
	Then $F$ is continuous, $2 \pi$-periodic, and 
	\[
		\hat{F}(n) = \frac{1}{in} \hat{f}(n) \quad \text{if }n \neq 0
	\]
	by integration by parts.
	Since $F$ is continuous, its Ces\`aro mean $\sigma_N(F)$ converges to $F$ uniformly.
	\[
		\widehat{\sigma_N(F)}(n) = \widehat{F * F_N}(n) = \widehat{F}(n) \widehat{F_N}(n)
	\]
	since if $g, h \in L^1(\RR)$, then
	\[
		\begin{split}
			\widehat{g * h}(n) & = \frac{1}{2 \pi} \int_{- \pi}^\pi g * h(x) e^{-inx} \dd{x}\\
			& = \frac{1}{2 \pi} \int_{- \pi}^{\pi} \frac{1}{2 \pi} g(x - y) h(y) \dd{y} e^{-inx} \dd{x}\\
			& = \frac{1}{2 \pi} \int_{- \pi}^\pi \frac{1}{2 \pi} \int_{- \pi}^\pi g(x - y) e^{-in (x - y)} \dd{x} h(y) e^{-iny} \dd{y}\\
			& = \frac{1}{2 \pi} \int_{- \pi}^\pi \frac{1}{2 \pi} \widehat{g}(n) h(y) e^{- iny} \dd{y}
		\end{split}
	\]
	Since $\sigma_N(F)(0) \to F(0)$, and by symmetry on $\pm N$, we have
	\[
		\sigma_N(F)(0) = \lim_{N \to \infty} 2 \sum_{n = 1}^{N - 1} \left(1 - \frac{n}{N} \right) \frac{\widehat{f}(n)}{n} = i (F(0) - \widehat{F}(0))
	\]
	\[
		\Ra \lim_{N \to \infty} 2 \left( \sum_{n  = 1}^{N - 1} \frac{\widehat{f}(n)}{n} - \frac{1}{N} \sum_{n = 1}^{N - 1} \widehat{f}(n) \right) = i(F(0) - \widehat{F}(0))
	\]
	Note that $|\widehat{f}(n)| \leq \|f\|_{L^1}$, the second term in the limit is bounded by $\|f\|_{L^1}$.
	Moreover, $\hat{f}(n) \geq 0$, thus the first term is monotone.
	Thus 
	\[
		\Ra \lim_{N \to \infty} \sum_{n = 1}^{N - 1} \frac{\widehat{f}(n)}{n} < \infty
	\]

\end{proofs}

\section{Functional Analytic Point of View}

$\F: L^1([-\pi, \pi]) \to \ell^\infty$ defined by $f \mapsto (\widehat{f}(n))_{n \in \ZZ}$ defined a linear map.
Moreover, by Riemann-Lebesgue lemma, $\lim_{|n| \to \infty} \widehat{f}(n) = 0$, thus in fact the range could be restricted to $c_0$.
Also, 
\[
	\|\F f\|_{\ell^\infty} = \|\widehat{f}\|_{\ell^\infty} \leq \|f\|_{L^1}
\]
Thus $\F$ is bounded with $\|\F\|_{L^1 \to c_0} \leq 1$.
On the other hand, by the Parseval identity, 
\[
	\F: L^2([-\pi, \pi]) \to \ell^2(\ZZ)
\]
is an isomretric linear isomorphism.
\[
	\|\F f\|_{\ell^2} = \|f\|_{L^2}
\]
What if $f \in L^p([-\pi, \pi]), p \neq 1, 2$?
Guess: $\widehat{f} \in \ell^q, q = p/(p - 1)$.
This is not true for $p > 2$!

\par Fact: $\exists 2 \pi$-periodic (continuous) $f$ such that for all $\epsilon > 0$, we have
\[
	\sum_{n = -\infty}^\infty |\widehat{f}(n)|^{2 - \epsilon} = \infty
\]
Thus the guess is true when $1 < p < 2$.

\begin{thm}[Hausdorff-Young]
	Let $1 \leq p \leq 2$ and let $q = p/(p - 1)$.
	If $f \in L^p([-\pi, \pi])$ then 
	\[
		\|\hat{f}\|_{\ell^q} \leq \|f\|_{L^p}
	\]
\end{thm}

This is actually a consequence of the following theorem:

\begin{thm}[Riesz-Thorin]
	Let $(X, \mu)$ and $(Y, \nu)$ be two $\sigma$-finite measure spaces.
	Let $B = L^{p_0}(\mu) \cap L^{p_1}(\mu)$ and $B' = L^{p_0'}(\nu) \cap L^{p_1'}(\nu)$.
	Suppose that $T: B \to B'$ is linear such that $T: (B, \|\cdot\|_{L^{p_j}}) \to (B', \|\cdot\|_{L^{p_j'}})$ is bounded, $j = 0, 1$.
	For $\alpha \in [0, 1]$, define
	\[
		p_{\alpha} = \frac{p_0 p_1}{\alpha p_0 + (1 - \alpha) p_1} \quad \left( \frac{1}{p_\alpha} = \frac{1 - \alpha}{p_0} + \frac{\alpha}{p_1} \right)
	\]
	(if $p_1 = \infty$, define $p_\alpha = p_0/(1 - \alpha)$.) 
	Define $p_\alpha'$ similarly.
	Then $T: (B, \|\cdot\|_{L^{p_j}}) \to (B', \|\cdot\|_{L^{p_j'}})$ is also bounded.
	Furthermore, $\|T\|_{\alpha} \leq \|T\|_0^{1 - \alpha} \|T\|_1^{\alpha}$.
\end{thm}

\section{An Application}

$\alpha \in \RR$, write $[\alpha]$ for the integer part of $\alpha$.
$\{\alpha\} = \alpha - [\alpha]$ is the fractional part of $\alpha$.
Want to understand the sequence $\{\alpha\}, \{2 \alpha\}, \{3 \alpha\}, ...$.
If $\alpha \in \QQ$, this sequence is periodic.
If $\alpha \in \QQ^c$, then these numbers are all distinct.
Can even show that $(\{n \alpha\})$ is dense in $[0, 1)$ if $\alpha \in \QQ^c$.
We will prove something stronger.

\begin{dfn}
	A sequence $(\xi_n)$ in $[0, 1)$ is said to be \textbf{equidistributed} if for all interval $(a, b) \subseteq [0, 1)$, we have
	\[
		\lim_{N \to \infty} \frac{|\{1 \leq n \leq N: \xi_n \in (a, b)\}|}{N} = b - a
	\]
\end{dfn}

\begin{thm}[Weyl]
	If $\alpha \in \QQ^c$, then $(\{n \alpha\})$ is equidistributed.
\end{thm}

\begin{proofs}
	Consider $\chi_{(a, b)}$ and extend it to a function with period 1.
	Then
	\[
		|\{1 \leq n \leq N: \{n \alpha\} \in (a, b)\}| = \sum_{n = 1}^N \chi_{(a, b)}(n \alpha)
	\]
	Need to show
	\[
		\frac{1}{N} \sum_{n = 1}^N \chi_{(a, b)}(n \alpha) \to \int_0^1 \chi_{(a, b)}(x) \dd{x}
	\]
	Can approximate $\chi_{(a, b)}$ by a continuous function with period 1>
	Suffices to show for such an $f$, 
	\[
		\frac{1}{N} \sum_{n = 1}^N f(n \alpha) \to \int_0^1 f(x) \dd{x}
	\]
	By Ces\`aro mean/Weierstrass approximation theorem, suffices to verify this for trigonometric polynomials.
	If $f \equiv 1$, this holds obviously.
	If $f(x) = e^{2 \pi i kx}$, where $k \in \ZZ \setminus \{0\}$, then
	\[
		\frac{1}{N} \sum_{n = 1}^N e^{2 \pi i kn \alpha} = \frac{e^{2 \pi i k \alpha}}{N} \frac{1 - e^{2 \pi  i k N \alpha}}{1 - e^{2 \pi i k \alpha}} \to 0 = \int_0^1 e^{2 \pi i k x} \dd{x}
	\]
	and we are done.
\end{proofs}

Can show something more:

\begin{thm}[Weyl's Criterion]
	$(\xi_n)$ is equidistributed $\Lra \forall k \neq 0$, we have
	\[
		\frac{1}{N} \sum_{n = 1}^N e^{2 \pi k \xi_n} \to 0 \quad \text{as }N \to \infty
	\]
\end{thm}

Can view the problem ($(\{n\alpha\})$ is equidistributed) by using a dynamical system.
$T:[0, 1) \to [0, 1)$ defined by $T(x) = (x + \alpha) \pmod{1} = \{x + \alpha\}$.
$T^{\circ n}(x) = (x + n \alpha) \pmod{1}$.
We proved that if $\alpha \in \QQ^c$ then for all continuous function $f$, 
\[
	\lim_{N \to \infty} \frac{1}{N} \sum_{n = 1}^N f( T^{\circ n}(0)) \to \int_0^1 f(y) \dd{y}
\]
Which is time average converges to space average.
The orbit ($T^{\circ n}(0)$) spreads around the whole space evenly.
In this case, we say that this dynamical system is \textbf{ergodic}. 

\section{Fourier Transform}

Goal: Develop an analogous theory for nonperiodic functions.
If $f$ is a nice function (say, smooth, supported on $[-M, M]$), then fixing $L > 2M$, one can write
\[
	f(x) = \sum_{n = -\infty}^\infty a_n(L) e^{ \frac{2 \pi i n x}{L}}
\]
\[
	a_n(L) = \frac{1}{L} \int_{-\frac{L}{2}}^{\frac{L}{2}} f(x) e^{-\frac{2 \pi i n x}{L}} \dd{x} =: \frac{1}{L} \widehat{f} \left( \frac{n}{L} \right)
\]
Set $\delta = 1/L$, then
\[
	\widehat{f}(\delta n) = \int_{- \frac{1}{2 \delta}}^{\frac{1}{2 \delta}} f(x) e^{- 2 \pi i \delta n x} \dd{x}
\]
Pretend that $\widehat{f}$ can be extended to a nice continuous function on $\RR$.
For any $\xi \in RR$, we can choose $\delta$ depending on $n$ such that $\delta n \to \xi$.
We obtain
\[
	\widehat{f}(\xi) = \int_{- \infty}^\infty f(x) e^{- 2 \pi i \xi x} \dd{x}
\]

\begin{dfn}
	If $f \in L^1(\RR)$ then we define its \textbf{Fourier transform} as
	\[
		\widehat{f}(\xi) = \int f(x) e^{- 2 \pi i \xi x} \dd{x} \quad \forall \xi \in \RR
	\]
\end{dfn}

Similar to Fourier coefficients, but now we have a function on $\RR$.\\
Basic properties: let $f, g \in L^1(\RR)$.
\begin{itemize}
	\item $\|\widehat{f}\|_{L^\infty} \leq \|f\|_{L^1}$.	

	\item $\widehat{f + ag} = \widehat{f} + a \widehat{g} \quad \forall a \in \CC$.

	\item $\widehat{\overline{f}}(\xi) = \overline{\widehat{f}(- \xi)}$.

	\item Writing $f_y(x) = f(x - y)$, where $y \in \RR$, then $\widehat{f}_y (\xi) = \widehat{f}(\xi) e^{- 2 \pi i \xi y}$.

	\item Writing $f_\lambda(x) = \lambda f(\lambda x)$,where $\lambda > 0$, then $\widehat{f}_\lambda(\xi) = \widehat{f}(\xi/\lambda)$.

	\item $\widehat{f * g} = \widehat{f} \widehat{g}$.

	\item If $f' \in L^1(\RR)$, then $\widehat{f'}(\xi) = 2 \pi i \xi \widehat{f}(\xi)$.
\end{itemize}

\begin{prop}
	Let $f \in L^1(\RR)$.
	Then $\widehat{f}$ is uniformly continuous on $\RR$.
	If further $x f(x0 \in L^1(\RR)$, then $\widehat{f}$ is differentiable and 
	\[
		\dv{\widehat{f}(\xi)}{\xi} = \widehat{(- 2 \pi i x f)} (\xi)
	\]
\end{prop}

\begin{proofs}
	For any $\xi, \eta \in \RR$, 
	\[
		\widehat{f}(\xi + \eta) - \widehat{f}(\xi) = \int f(x) (e^{- 2 \pi i (\xi + \eta) x} - e^{- 2 \pi i \xi x}) \dd{x}
	\]
	\[
		\Ra |\widehat{f}(\xi + \eta) - \widehat{f}(\xi)| \leq \int |f(x)| |e^{- 2 \pi i \eta x} - 1| \dd{x} 
	\]
	where $|e^{- 2 \pi i \eta x} - 1| \to 0$ as $\eta \to 0$.
	By the dominated convergence theorem, the right sides in the inequalities goes to 0 uniformly in $\xi$.	
	This shows uniform continuity.
	Another statement: exercise.
\end{proofs}

\begin{thm}[Riemann-Lebesgue lemma]
	If $f \in L^1(\RR)$, then
	\[
		\lim_{|\xi| \to \infty} \widehat{f}(\xi) = 0
	\]
\end{thm}

\begin{proofs}
	If $f \in C^1$ with compact support then by the last basic property, 
	\[
		|2 \pi i \xi \widehat{f}(\xi)| \leq \|f'\|_{L^1} \quad \forall \xi \in RR
	\]
	\[
		\Ra |\widehat{f}(\xi)| \leq \frac{1}{2 \pi |\xi|} \|f'\|_{L^1} \quad \forall \xi \neq 0
	\]
	\[
		\Ra \lim_{|\xi| \to \infty} |\widehat{f}(\xi)| = 0
	\]
	Let $f \in L^1(\RR)$ be arbitrary.
	Fix $\epsilon > 0$, and choose a $C^1$-function $g$ with compact support such that $\|f - g\|_{L^1} < \epsilon$.
	Then 
	\[
		|\widehat{f}(\xi) - \widehat{g}(\xi)| \leq \|f - g\|_{L^1} < \epsilon
	\]
	Let $|\xi| \to \infty$, 
	\[
		\limsup_{|\xi| \to \infty} |\widehat{f}(\xi)| \leq \epsilon
	\]
	$\epsilon > 0$ is arbitrary, and we are done.
\end{proofs}

\begin{dfn}
	Define the \textbf{Fej\'er kernel} on $\RR$ by 
	\[
		F_\lambda(x) = \lambda \left( \frac{\sin (\pi \lambda x)}{\pi \lambda x} \right)^2 \quad (F_\lambda(0) = \lambda)
	\]
\end{dfn}

$F_\lambda$ comes from the Fourier transform of 
\[
	f(x) = 
	\begin{cases}
		1 - |x| & \text{if } |x| \leq 1\\
		0 & \text{otherwise}
	\end{cases}
\]
we have
\[
	\int_{-1}^1 (1 - |x|) e^{- 2 \pi i \xi x} \dd{x} = \left( \frac{\sin (\pi \xi)}{\pi \xi} \right)^2 \cdots (\dagger)
\]
Check: $(F_\lambda)$ is an approximation to the identity as $\lambda \to \infty$.
We have $f * F_\lambda(x) \to f$ almost everywhere and in $L^1$ as $\lambda \to \infty$.

\begin{clm}
	\[
		f(x) = \lim_{\lambda \to \infty} \int_{-\lambda}^\lambda \left( 1 - \frac{|\xi|}{\lambda} \right) \widehat{f}(\xi) e^{2 \pi i \xi x} \dd{\xi}
	\]
\end{clm}

\begin{lem}
	Let $f, g \in L^1(\RR)$ and $g(x) = \int G(\xi) e^{2 \pi i \xi x} \dd{\xi}$ for some $G \in L^1(\RR)$.
	Then 
	\[
		f * g(x) = \int G(\xi) \widehat{f}(\xi) e^{2 \pi i \xi x} \dd{\xi}
	\]
\end{lem}

we have
\[
	F_\lambda(x) = \int_{- \lambda}^\lambda \left(1 - \frac{|\xi|}{\lambda} \right) e^{2 \pi i \xi x} \dd{x}
\]
by $(\dagger)$ and symmetry.
Thus lemma implies claim.

\begin{proofs}[Proof of Lemma]
	$(\xi, y) \mapsto G(\xi) f(y)$ is integrable.
	\[
		\begin{split}
			(f * g)(x) &= \int f(y) g(x - y) \dd{y}\\
			&= \iint G(\xi) e^{2 \pi i \xi x} e^{-2 \pi i \xi y} f(y) \dd{\xi} \dd{y}\\
			&\stackrel{\text{Fubini}}{=} \iint e^{-2 \pi i \xi y}f(y) \dd{y} G(\xi) e^{2 \pi i \xi x} \dd{\xi}\\
			&= \int G(\xi) \widehat{f}(\xi) e^{2 \pi i \xi x} \dd{\xi}
		\end{split}
	\]
\end{proofs}

\begin{cor}[Uniqueness Theorem]
	If $f \in L^1(\RR)$ and $\widehat{f}(\xi) = 0  \quad \forall \xi \in \RR$, then $f = 0$ almost everywhere.
\end{cor}

\begin{cor}[Fourier Inversion]
	If $f, \widehat{f} \in L^1(\RR)$, then
	\[
		f(x) = \int \widehat{f}(\xi) e^{2 \pi i \xi x} \dd{\xi}
	\]
\end{cor}

\begin{proofs}
	$\widehat{f} \in L^1(\RR)$,
	\[
		\Ra \lim_{\lambda \to \infty} \int_{-\lambda}^\lambda \left( 1 - \frac{|\xi|}{\lambda} \right) \widehat{f}(\xi) e^{2 \pi i \xi x} \dd{\xi} \stackrel{\text{DCT}}{=}\int \widehat{f}(\xi) e^{2 \pi i \xi x} \dd{\xi}
	\]
\end{proofs}

\begin{cor}
	The functions whose Fourier transforms are compactly supported form a dense subspace of $L^1(\RR)$.
\end{cor}

\begin{proofs}
	$f*F_\lambda \to f$ in $L^1$, where 
	\[
		\widehat{f*F_\lambda} (\xi) = \left( 1 - \frac{|\xi|}{\lambda} \right) \widehat{f}(\xi) \chi_{[-\lambda, \lambda]} (\xi)
	\]
	is compact supported.
\end{proofs}

\section{Poisson Summation Formula}

For $f \in L^1(\RR)$, define 
\[
	\varphi(x) = \sum_{n = -\infty}^\infty f(x + n)
\]
$\varphi$ can be seen as a 1-periodic function on $\RR$.
Well-defined?
\[
	\begin{split}
		\int_0^1 |\varphi(x)| \dd{x} &\leq \sum_{n = -\infty}^\infty \int_0^1 |f(x + n)| \dd{x}\\
		&= \sum_{n = -\infty}^\infty \int_n^{n + 1} |f(x)| \dd{x}\\
		&= \int_{\RR} |f(x)| \dd{x} = \|f\|_{L^1}
	\end{split}
\]
$\varphi$ makes sense as an $L^1$-function on $[0, 1]$.
\[
	\begin{split}
		\widehat{\varphi}(k) = \int_0^1 \varphi(x) e^{2 \pi i k x} &= \int_0^1 \sum_{n = -\infty}^\infty f(x + n) e^{-2 \pi i k x} \dd{x}\\
		&\stackrel{\text{DCT}}{=} \sum_{n = -\infty}^\infty \int_0^1 f(x + n) e^{- 2 \pi i k x} \dd{x}\\
		&= \int_{- \infty}^\infty f(x) e^{-2 \pi i k x} \dd{x} = \widehat{f}(k)
	\end{split}
\]
The Fourier coefficients of $\varphi$ are just $\widehat{f}|_{\ZZ}$.

\begin{thm}[Poisson Summation Formula]
	Let $f \in L(\RR)$ and let $\varphi$ be as above.
	Suppose that the Fourier series of $\varphi$ converges to $\varphi$ at $x$.
	Then
	\[
		\sum_{n = -\infty}^\infty f(x + n) = \sum_{n = -\infty}^\infty \widehat{f}(n) e^{2 \pi i n x}
	\]
	(In particular, if the Fourier series of $\varphi$ converges to $\varphi$ at 0, then $\sum_{n = -\infty}^\infty f(n) = \sum_{n = -\infty}^\infty \widehat{f}(n)$.)
\end{thm}

\begin{rem}
	Even if $f, \widehat{f}$ are continuous and if both sides converge absolutely at $x$, the Poisson summation formula might not hold.
	However, if we replace the RHS by
	\[
		\lim_{N \to \infty} \sum_{n = -(N - 1)}^{N - 1} \left( 1 - \frac{|n|}{N} \right) \widehat{f}(n) e^{2 \pi i n x}
	\]
	which is the Ces\`aro mean of the Fourier series of $\varphi$, then the formula holds whenever $\varphi$ is continuous at $x$.
\end{rem}

\section{Fourier Transforms in $L^p, 1 < p \leq 2$}

For Fourier series, $L^p([-\pi, \pi]) \subseteq L^1([-\pi, \pi]) \quad \forall p \geq 1$.
Can talk about the Fourier series of $f$ if $f \in L^-([-\pi, \pi])$.
However, $L^p(\RR) \not\subseteq L^1(\RR) \quad \forall p > 1$.
Need to define Fourier transform in some other way for functions in $L^p(\RR)$.
Start with $L^2(\RR)$.

\begin{lem}
	If $f$ is continuous with compact support on $\RR$ then
	\[
		\|\widehat{f}\|_{L^2} = \|f\|_{L^2}
	\]
\end{lem}

\begin{proofs}
	Write $\tilde{f}(x) = \overline{f(-x)}$.
	Let $g = f * \tilde{f}$.
	Then 
	\[
		g(0) = (f * \tilde{f})(0) = \int f(y) \tilde{f}(-y) \dd{y} = \int |f(y)|^2 \dd{y} = \|f\|_{L^2}^2
	\]

	Also, $\widehat{g}(\xi) = |\widehat{f}(\xi)|^2$.
	Moreover, $g$ is continuous
	\[
		\begin{split}
			\|f\|_{L^2}^2 = g(0) &= \lim_{\lambda \to \infty} \int_{-\lambda}^\lambda \left( 1 - \frac{|\xi|}{\lambda} \right) \widehat{g}(\xi) e^{2 \pi i \xi 0} \dd{\xi}\\
			&= \lim_{\lambda \to \infty} \int_{-\lambda}^\lambda \left(1 - \frac{|\xi|}{\lambda} \right) |\widehat{f}(\xi)|^2 \dd{\xi}\\
			&\stackrel{\text{MCT}} = \int |\widehat{f}(\xi)|^2 \dd{\xi} = \|\widehat{f}\|_{L^2}^2
		\end{split}
	\]
\end{proofs}

\begin{thm}[Plancherel]
	$\exists !$ surjective operator $\F \in \B(L^2(\RR))$ such that $\F f = \hat{f} \quad \forall f \in L^1(\RR) \cap L^2(\RR)$ and 
	\[
		\| \F f\|_{L^2(\RR)} = \|f\|_{L^2(\RR)} \quad \forall f \in L^2(\RR)
	\]
\end{thm}

\begin{proofs}
	First, $L^1(\RR) \cap L^2(\RR)$ is dense in $L^2(\RR)$. (Check)
	So any operator in $\B(L^2(\RR))$ is determined by its value on $L^1(\RR) \cap L^2(\RR)$.
	So there is at most one such operator.
	By the lemma, the isometry property holds for all continuous $f$ with compact support.
	Such functions are dense in $L^1(\RR) \cap L^2(\RR)$ with respec to to the norm $\|\cdot\|_{L^1} + \|\cdot\|_{L^2}$.
	By continuity, the isometry property holds $\forall f \in L^1(\RR) \cap L^2(\RR)$.
	Again by continuity, $\F$ defines an isometry from $L^2(\RR)$ to $L^2(\RR)$.
	Remains to show $\F$ is onto.
	\begin{clm}
		Let $g$ be a twice differentiable function with compact support.
		Then $g$ is the Fourier transform of some bounded $f \in L^1(\RR)$.
		(such $f$ belongs to $L^2(\RR)$.)
	\end{clm}

	\begin{proofs}
		Define $f(x) = \int g(\xi) e^{2 \pi i \xi x} \dd{\xi}$.
		$g$ has compact support $\Ra g''$ has compact suppoer.
		Define 
		\[
			h(x) = \int g''(\xi)e^{2 \pi i \xi x} \dd{\xi}
		\]
		By integration by parts, 
		\[
			h(x) = - 4 \pi^2 x^2 \int g(\xi) e^{2 \pi i \xi x} \dd{\xi} = -4 \pi^2 x^2 f(x)
		\]
		\[
			\Ra f(x) = -\frac{1}{4 \pi^2 x^2} h(x) \text{ if }x \neq 0
		\]
		$f$ is bounded and $f(x) = \O(1/x^2)$ as $|x| \to \infty$.
		So $f \in L^1(\RR)$.
		By Fourier inversion, $g = \widehat{f}$.
	\end{proofs}
	By Claim, the range of $\F$ is dense in $L^2(\RR)$.
	Remains to show that the range is closed.
	Let $(\F f_n)$ be a Cauchy sequence in $\F(L^2(\RR))$.
	Since $\F$ is an isometry $(f_n)$ is Cauchy in $L^2(\RR)$.
	So $f_n \to f$ for some $f \in L^2(\RR)$.
	$\Ra \F f_n \to \F f$ in $L^2(\RR)$.
	So $\F(L^2(\RR))$ is closed.
\end{proofs}

\begin{rem}
	$ $\par\nobreak\ignorespaces
	\begin{enumerate}
		\item If $f \in L^2(\RR)$, we just define $\widehat{f} = \F f$.
			Equivalently, given $f \in L^2(\RR)$, we can define $\widehat{f}$ to be the $L^2$-limit of $\widehat{f_n}$, where $(f_n)$ is any sequence in $L^1(\RR) \cap L^2(\RR)$ that converges to $f$ in $L^2(\RR)$.
			An easy choice is $f_n = f \chi_{[-n, n]}$.
			\[
				\widehat{f_n}(\xi) = \int_{-n}^n f(x) e^{-2 \pi i \xi x} \dd{x} \to \widehat{f}(\xi) \text{ in } L^2
			\]

		\item $\F$ is invertible.
			We can obtain the inverse map by $f(x) = \lim_{n \to \infty} \int_{-n}^n \widehat{f}(\xi) e^{2 \pi i \xi x} \dd{\xi}$ in $L^2$.

		\item By polarization, we have the following:
			\[
				\ev{f, g} = \ev{\widehat{f}, \widehat{g}} \quad \forall f, g \in L^2(\RR)
			\]
			We also call this the Parseval identity.
	\end{enumerate}
\end{rem}

For $1 < p < 2$, we use Riesz-Thorin again to obtain the following:
\begin{thm}[Hausdorff-Young]
	Let $1 \leq p \leq 2$ and $q = p/(p - 1) \quad \forall f \in L^1(\RR) \cap L^2(\RR)$, one has
	\[
		\| \widehat{f} \|_{L^q} \leq \|f\|_{L^p}
	\]
\end{thm}
Can use this to define $\widehat{f}$ for $f \in L^p(\RR), 1 < p < 2$.
What about $p > 2$?
A crazy idea:
Suppose that $f \in L^p(\RR)$ and $g \in L^q(\RR), 2 < p \leq \infty, q = p/(p - 1)$.
Then $\int f(x) \overline{g(x)} \dd{x}$ makes sense by H\"older's inequality.
Pretend that we can apply the Parseval identity:
\[
	\int f(x) \overline{g(x)} \dd{x} = \int \widehat{f}(\xi) \overline{\widehat{g}(\xi)} \dd{\xi}
\]
But what is $\widehat{f}$? 
We know $\widehat{g}$ at least.
Let's define $\widehat{f}$ as a function such that
\[
	\ev{\widehat{f}, \widehat{g}} = \ev{f, g} \quad \forall g \in L^q(\RR)
\]
Questions
\begin{enumerate}
	\item Does this $\widehat{f}$ really exist?

	\item Can we replace $L^q(\RR)$ by a better class of functions?
\end{enumerate}

Goal: Find a class $\C$ of functions such that

\begin{enumerate}
	\item $g \in \C \Ra \widehat{g} \in \C$.

	\item $\int f \overline{g}$ makes sense for "many" $f$.
\end{enumerate}

\begin{dfn}
	The \textbf{Schwartz space} $S(\RR)$ on $\RR$ is space of smooth functions $f$ such that
	\[
		\sup_{x \in \RR} |x|^k |f^{(l)}(x)| < \infty \quad \forall k, l \geq 0
	\]
\end{dfn}

$S(\RR)$ is a vector space over $\CC$.

\par Put a metric on $S(\RR)$ as follows:\\
$\forall k, l \geq 0$, write $\|f\|_{k, l} = \sup_{x \in \RR} |x|^k |f^{(l)}(x)|$.
Define 
\[
	d(f, g) = \sum_{k, l \geq 0} \frac{1}{2^{k + l}} \frac{\|f - g\|_{k, l}}{1 + \|f - g\|_{k, l}}
\]

So a sequence of functions $(f_n)$ in $S(\RR)$ converges to f $\Lra \|f_n - f\|_{k, l} \to 0$ as $n \to \infty$.
Verify by yourself: $S(\RR)$ is complete.\\
Observations:
\begin{itemize}
	\item If $f \in S(\RR)$, then $f' \in S(\RR)$ and $x f(x) \in S(\RR)$.

	\item If $f \in S(\RR)$, then $\widehat{f} \in S(\RR)$.
		
		\begin{proofs}
			$\forall k, l \geq 0$, $\xi^k \widehat{f}^{(l)} (\xi)$ is the Fourier transform of $1/(2 \pi i)^k (\dv*{x})^k [(-2 \pi i x)^l f(x)] \in S(\RR)$.
			So $\xi^k \widehat{f}^{(l)} (\xi)$ is uniformly bounded.
			So $\widehat{f} \in S(\RR)$.
		\end{proofs}

	\item $f \mapsto \widehat{f}$ and $\widehat{f} \mapsto f$ are continuous in $S(\RR)$.
\end{itemize}

\begin{dfn}
	A \textbf{tempered distribution} is an element of $S(\RR)^*$.
	For any $\mu \in S(\RR)^*$, we define its Fourier transform $\widehat{\mu}$ by
	\[
		\widehat{\mu}(\widehat{\varphi}) = \mu(\varphi) \quad \forall \varphi \in S(\RR)
	\]
\end{dfn}

\begin{rem}
	$ $\par\nobreak\ignorespaces
	\begin{itemize}
		\item For $\mu$ being continuous, we need:\\
			$\varphi_n \to \varphi$ in $S(\RR)$ then $\mu(\varphi_n) \to \mu(\varphi)$.

		\item If we use the pairing notation 
			\[
				\ev{\widehat{\mu}, \widehat{\varphi}} = \ev{\mu, \varphi}
			\]
			It looks like the Parseval identity.
	\end{itemize}
\end{rem}

We will only talk about some examples.

\begin{exs}
	\begin{enumerate}
		\item[(a)] Let $f \in L^2(\RR)$.
			Define $\mu \in S(\RR)^*$ by 
			\[
				\mu(\varphi) = \int \varphi(x) \overline{f(x)} \dd{x}
			\]
			Check: $\mu$ is continuous.
			\[
				\widehat{\mu}(\widehat{\varphi}) = \mu(\varphi) = \int \varphi(x) \overline{f(x)} \dd{x} \stackrel{\text{Parseval}}{=} \int \widehat{\varphi}(\xi) \overline{\widehat{f}(\xi)} \dd{\xi}
			\]
			So 
			\[
				\widehat{\mu}(\cdot) = \int \cdot \overline{\widehat{f}(\xi)} \dd{\xi}
			\]
			$\mu \leftrightarrow f, \widehat{\mu} \leftrightarrow \widehat{f}$.
			This recovers the Fourier transform in $L^2$.

		\item[(b)] Similarly, if $f \in L^1(\RR)$ and define 
			\[
				\mu(\varphi) = \int \varphi(x) \overline{f(x)} \dd{x}
			\]
			Then $\widehat{\mu}$ can be identified with $\widehat{f}$.
			Need to verify
			\[
				\int \varphi(x) \overline{f(x)} \dd{x} = \int \widehat{\varphi}(\xi) \overline{\widehat{f}(\xi)} \dd{\xi}
			\]
			Just approximate $f$ by $f_n \in L^1(\RR) \cap L^2(\RR)$.
			
		\item[(c)] Consider 
			\[
				\mu(\varphi) = \varphi(0)
			\]
			Then $\mu \in S(\RR)^*$. 
			($\mu$ is the Dirac delta.)
			\[
				\widehat{\mu}(\widehat{\varphi}) = \mu(\varphi) = \varphi(0) \stackrel{\text{Inversion}}{=} \int \widehat{\varphi}(\xi) \dd{\xi}
			\]
			So $\widehat{\mu}$ is identified with the constant function 1.

		\item[(d)] Define 
			\[
				\mu(\varphi) = \int \varphi
			\]
			\[
				\widehat{\mu}(\widehat{\varphi}) = \int \varphi = \widehat{\varphi}(0)
			\]
			So $\widehat{\mu}$ is the Dirac delta.
	\end{enumerate}
\end{exs}

\newpage

\section{Homework Statements}

\begin{enumerate}
	\item If $f \in L^1(\RR^d)$ and $f \neq 0$, then
		\[
			f^*(x) \geq \frac{c}{|x|^d} \quad \text{for some }c > 0 \text{ and all }|x| \geq 1
		\]
		Thus $f^*$ is not integrable on $\RR^d$. 
		Moreover
		\[
			m(\{x: f^*(x) > \alpha\}) \leq \frac{c}{\alpha} \quad \text{for all }\alpha > 0
		\]
		And if $f$ is supported in the unit ball with $\|f\|_{L^1} = 1$ then
		\[
			m(\{x: f(x) > \alpha\}) \geq \frac{c'}{\alpha}
		\]
		for sufficiently small $\alpha$.

	\item If $f \in L^p(\RR^d)$ for some $p \in (1, \infty]$ then $f^* \in L^p(\RR^d)$.	

	\item
		\begin{enumerate}
			\item[(a)] There exists $F:[0, 1] \to \RR$ that is absolutely continuous and strictly increasing but $F'(x) = 0$ on a set of positive measure.

			\item[(b)] $F$ in $(a)$ can be chosen so that there is a measureable subset $E \subseteq [F(0), F(1)]$ with $m(E) = 0$ such that $F^{-1}(E)$ is not measurable.

			\item[(c)] However, for any increasing abtolutely continuous $F$, and $E$ a measurable subset of $[F(0), F(1)]$, the set $F^{-1}(E) \cap \{x: F'(x) > 0\}$ is measurable.
		\end{enumerate}

	\item Let $F$ be abtolutely continuous and increasing on $[a, b]$ with $F(a) = A$ and $F(b) = B$, and $f$ be integrable on $[A, B]$.
		Then $f(F(x)) F'(x)$ is measurable on $[a, b]$ and we have the change of variable formula: if $f$ is integrable on $[A, B]$, then so is $f(F(x)) F'(x)$ and
		\[
			\int_A^B f(y) \dd{y} = \int_a^b f(F(x)) F'(x) \dd{x}
		\]

	\item If $F$ and $G$ are absolutely continuous on $[a, b]$, then $FG$ is also absolutely continuous.

	\item If $X$ is Banach and possesses a Schauder basis, then $X$ is separable.
		Also the set $\{e_n\}$ is a Schauder basis for $\ell^p$.

	\item $(\ell^1)^* = \ell^\infty$.

	\item Let $A$ and $B$ be two nonempty, disjoint convex sets in a vector space $X$.
		Then there exists a linear functional $\Lambda$ such that $\Re(\Lambda x) \leq \Re(\Lambda y)$ for all $x \in A$ and $y \in B$.

	\item (Geometric Hahn-Banach) Let $X$ be a normed vector space and $A$, $B$ be two nonempty, disjoint convex sets in $X$.
		\begin{enumerate}
			\item[(a)] If $A$ is open, then there exists $\Lambda \in X^*$ such that $\Re(\Lambda x) < \Re(\Lambda y) \quad \forall x \in X, y \in Y$.

			\item[(b)] If $A$ is sequentially compact and $B$ is closed, then there exists $\Lambda \in X^*$ and $\alpha, \beta \in \RR$ such that
				\[
					\Re(\Lambda x) < \alpha < \beta < \Re(\Lambda y) \quad \forall x \in A, y \in B
				\]
		\end{enumerate}

	\item If $p_1$ and $p_2$ are gauges on $X$ a vector space over $\RR$, and $\Lambda \in L(X, \RR)$ satisfies
		\[
			\Lambda \leq p_1(x) + p_2(x) \quad \forall x \in X
		\]
		Then there exists $\Lambda_1, \Lambda_2 \in L(X, \RR)$ such that $\Lambda = \Lambda_1 + \Lambda_2$ and $\Lambda_1 x \leq p_x(x)$ and $\Lambda_2 x \leq p_2(x) \quad \forall x \in X$.

	\item (The Banach limit) There exists $\Lambda \in (\ell^\infty)^*$ such that
		\begin{enumerate}
			\item[(a)] If the sequence $x$ is nonnegative then $\Lambda x \geq 0$.

			\item[(b)] $\Lambda \bm{1} = 1$.

			\item[(c)] $\Lambda x = \Lambda (\tau x)$, where $\tau x = (x_2, x_3, ...)$.

			\item[(d)] $\|\Lambda\| = 1$.

			\item[(e)] $\Lambda x = \lim_{n \to \infty} x_n$ whenever the limit exists.

			\item[(f)]
				\[
					\liminf_{n \to \infty} x_n \leq \Lambda x \leq \limsup_{n \to \infty} x_n \quad \forall x \in \ell^\infty
				\]
		\end{enumerate}

	\item $(C^0([a, b]))^*$ is not separable. (The evaluation maps are not)

	\item 
		\begin{enumerate}
			\item[(a)] Any closed subspace of a reflexive space is reflexive.

			\item[(b)] A Banach space is reflexive if and only if its dual is reflexive.
		\end{enumerate}

	\item Let $1 \leq p < \infty$ and $q = p/(p - 1)$. 
		Then $\Phi: \ell^q \to (\ell^p)^*$ defined by
		\[
			\Phi(y)(x) = \sum_{j = 1}^\infty y_j x_j
		\]
		is an isometric linear isomorphism.
		If $T \in \B(\ell^p)$, define $\tilde{T} = \Phi^{-1} T^t \Phi: \ell^q \to \ell^q$ the transpose of $T$, then
		\[
			\sum_{j = 1}^\infty (\tilde{T} y)_j x_j = \sum_{j = 1}^\infty y_j (Tx)_j \quad \forall x \in \ell^p, y \in \ell^q
		\]

	\item Let $X, Y$ be banach, and $(T_n)$ a sequence in $\B(X, Y)$.
		Define $T x = \lim_{n \to \infty} T_n x$.
		Then $T \in \B(X, Y)$ and 
		\[
			\|T\| \leq \liminf_{n \to \infty} \|T_n\|
		\]

	\item Any two norms on $\CC^n$ are equivalent by Banach inverse mapping theorem.

	\item Open mapping theorem $\Lra$ closed graph theorem.

	\item Let $X$ be a Hilbert space.
		$B: X \times X \to \CC$ a function such that $B(x, y)$ is linear in $x$ and sesquilinear in $y$ and exists $M > 0$ such that
		\[
			|B(x, y)| \leq M\|x\| \|y\| \quad \forall x, y \in X
		\]
		Then there exists $T \in \B(X)$ such that $B(x, y) = \ev{T x, y} \quad \forall x, y \in X$ and $\|T\| = \sup\{B(x, y): \|x\|, \|y\| \leq 1\}$.

	\item Let $X$ be a Hilbert space and $T \in \B(X)$.
		Then $\|T^*T\| = \|T\|^2$.
		Moreover if $T$ is self-adjoint then $r(T) = \|T\|$.

	\item $V \in \B(L^2([0, 1]))$ defined by
		\[
			V f(x) = \int_0^x f(t) \dd{t} \quad \forall f \in L^2([0, 1])
		\]
		is compact and $\|V\| = 2/\pi$.

	\item $T \in \B(\ell^2)$ and write $(T x)_k = \sum_j \alpha_{kj} x_j$.
		Then
		\begin{enumerate}
			\item[(a)] $T^*$ satisfies $(T^* x)_k = \sum_j \overline{\alpha_{jk}} x_j$.

			\item[(b)] If $\sum_{k, j} |\alpha_{kj}|^2 < \infty$, then $T$ is compact.
		\end{enumerate}

	\item $T \in \B(X)$ is compact, self-adjoint and $X$ is Hilbert.
		If $\lambda \neq 0$ then the equation $(T - \lambda I) x = b$ is solvable if and only if $b$ is orthogonal to all solutions $y$ of $(T - \lambda I) y = 0$.

	\item Let $X$ be a Hilbert space and $(x_n)$ a sequence in $X$.
		Then $x_n \to x$ if and only if $x_n \ru x$ and $\|x_n\| \to \|x\|$.

	\item Let $(f_n)$ be a sequence in $C^0([a, b])$ and $f \in C^0([a, b])$.
		Then $f_n \ru f$ if and only if $f_n \to f$ pointwise and $(\|f_n\|)_n$ is uniformly bounded.

	\item The convergence theorems in measure theory should still hold for R-S integrals.

	\item (Schur's Theorem) Every weakly convergent sequence in $\ell^1$ also converges strongly.

	\item Every bounded linear functional attains its extremum in a closed bounded xonvex subset of a reflexive space.

	\item (Helly Selection Theorem) Let $X$ be a separable Banach space and $B^*$ the closed unit ball in $X^*$. 
		Then $B^*$ is weak$^*$-sequentially compact. 
		In particular $L^\infty([0, 1])$ is not separable.

	\item In a finite dimensional space, the weak topology is just the norm topology.

	\item Let $X$ be an infinite dimensional normed space.
		Then the closure of the unit sphere $S = \{x \in X: \|x\| = 1\}$ is the closed unit ball $B = \{x \in X: \|x\| \leq 1\}$.	

	\item Let $X, Y$ be Banach.
		Then $T: X \to Y$ is continuous w.r.t the norm topologies of $X$ and $Y$ if and only if $T: (X, \tau(X, X^*)) \to (Y, \tau(Y, Y^*))$ is continuous. (Closed graph theorem)

	\item If the closed unit ball of a Banach space has no extreme points, then the space cannot be isometrically linearly isomorphic to the dual of a Banach space.

	\item Let $f \in L^1([-\pi, \pi])$, and let $x_0 \in [-\pi, \pi]$.
		If $\lim_{h \to 0} [f(x_0 + h) + f(x_0 - h)]$ exists and is finite, then
		\[
			\sigma_N(f)(x_0) \to \frac{1}{2} \lim_{n \to 0} [f(x_0 + h) + f(x_0 - h)]
		\]
		since if $F_N$ is the $N$-th Fe\'jer kernel, then $F_N(x) = F_N(-x)$ and for $0 < \delta < \pi$, 
		\[
			\lim_{N \to \infty} \sup_{\delta < x < 2\pi - \delta} F_N(x) = 0
		\]
\end{enumerate}












\end{document}






